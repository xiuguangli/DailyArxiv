[
    {
        "order": 1,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07032",
        "abs_url": "https://arxiv.org/abs/2602.07032",
        "pdf_url": "https://arxiv.org/pdf/2602.07032",
        "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation",
        "authors": [
            "Yuheng Wu",
            "Berk Gokmen",
            "Zhouhua Xie",
            "Peijing Li",
            "Caroline Trippel",
            "Priyanka Raina",
            "Thierry Tambe"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Computation and Language (cs.CL)",
        "abstract": "Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machine (FSM) behavior from natural-language specifications and translate it into correct register transfer-level (RTL) implementations. Unlike prior specification-to-RTL benchmarks that rely on manually constructed examples, LLM-FSM is built through a fully automated pipeline. LLM-FSM first constructs FSM with configurable state counts and constrained transition structures. It then prompts LLMs to express each FSM in a structured YAML format with an application context, and to further convert that YAML into a natural-language (NL) specification. From the same YAML, our pipeline synthesizes the reference RTL and testbench in a correct-by-construction manner. All 1,000 problems are verified using LLM-based and SAT-solver-based checks, with human review on a subset. Our experiments show that even the strongest LLMs exhibit sharply declining accuracy as FSM complexity increases. We further demonstrate that training-time scaling via supervised fine-tuning (SFT) generalizes effectively to out-of-distribution (OOD) tasks, while increasing test-time compute improves reasoning reliability. Finally, LLM-FSM remains extensible by allowing its FSM complexity to scale with future model capabilities.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 2,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07034",
        "abs_url": "https://arxiv.org/abs/2602.07034",
        "pdf_url": "https://arxiv.org/pdf/2602.07034",
        "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA",
        "authors": [
            "Jinxiu Qu",
            "Zirui Tang",
            "Hongzhang Huang",
            "Boyu Niu",
            "Wei Zhou",
            "Jiannan Wang",
            "Yitong Song",
            "Guoliang Li",
            "Xuanhe Zhou",
            "Fan Wu"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Existing Text-to-SQL methods typically require converting semi-structured tables into structured formats, inevitably leading to information loss, while approaches like Text-to-Code and multimodal LLM-based QA struggle with complex layouts and often yield inaccurate answers. To address these limitations, we present ST-Raptor, an agentic system for semi-structured table QA. ST-Raptor offers an interactive analysis environment that combines visual editing, tree-based structural modeling, and agent-driven query resolution to support accurate and user-friendly table understanding. Experimental results on both benchmark and real-world datasets demonstrate that ST-Raptor outperforms existing methods in both accuracy and usability. The code is available at this https URL, and a demonstration video is available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 3,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07035",
        "abs_url": "https://arxiv.org/abs/2602.07035",
        "pdf_url": "https://arxiv.org/pdf/2602.07035",
        "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
        "authors": [
            "Jiahao Zhao",
            "Shaoxuan Xu",
            "Zhongxiang Sun",
            "Fengqi Zhu",
            "Jingyang Ou",
            "Yuling Shi",
            "Chongxuan Li",
            "Xiao Zhang",
            "Jun Xu"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAct agent paradigm induces severe end-to-end latency. Intuitively, dLLMs can leverage their distinctive strengths to optimize the operational efficiency of agents under the ReAct agent paradigm. Practically, existing dLLM backbones face the 2) Agent Ability Challenge. That is, existing dLLMs exhibit remarkably weak reasoning and tool-calling capabilities, preventing these advantages from being effectively realized in practice. In this paper, we propose DLLM-Searcher, an optimization framework for dLLM-based Search Agents. To solve the Agent Ability Challenge, we design a two-stage post-training pipeline encompassing Agentic Supervised Fine-Tuning (Agentic SFT) and Agentic Variance-Reduced Preference Optimization Agentic VRPO, which enhances the backbone dLLM's information seeking and reasoning capabilities. To mitigate the Latency Challenge, we leverage the flexible generation mechanism of dLLMs and propose a novel agent paradigm termed Parallel-Reasoning and Acting P-ReAct. P-ReAct guides the model to prioritize decoding tool_call instructions, thereby allowing the model to keep thinking while waiting for the tool's return. Experimental results demonstrate that DLLM-Searcher achieves performance comparable to mainstream LLM-based search agents and P-ReAct delivers approximately 15% inference acceleration. Our code is available at this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 4,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07040",
        "abs_url": "https://arxiv.org/abs/2602.07040",
        "pdf_url": "https://arxiv.org/pdf/2602.07040",
        "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
        "authors": [
            "Emmett Bicker"
        ],
        "comments": "Available at this http URL, 25 pages, 8 figures, 4 tables",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performances. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to include tasks with long evaluation durations, such as multi-hour machine learning training runs. We applied Aster to problems in mathematics, GPU kernel engineering, biology, neuroscience, and language model training. More specifically: the Erdos minimum overlap problem, optimizing the TriMul kernel, a single-cell analysis denoising problem, training a neural activity prediction model to perform well on ZAPBench, and the NanoGPT Speedrun Competition. Aster attains SOTA results in every task, except for ZAPBench, where it matches the performance of the best human solution with less than 1/190th of the compute. Aster is accessible via a web interface and API at this http URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 5,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07055",
        "abs_url": "https://arxiv.org/abs/2602.07055",
        "pdf_url": "https://arxiv.org/pdf/2602.07055",
        "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
        "authors": [
            "Pingyue Zhang",
            "Zihan Huang",
            "Yue Wang",
            "Jieyu Zhang",
            "Letian Xue",
            "Zihan Wang",
            "Qineng Wang",
            "Keshigeyan Chandrasegaran",
            "Ruohan Zhang",
            "Yejin Choi",
            "Ranjay Krishna",
            "Jiajun Wu",
            "Li Fei-Fei",
            "Manling Li"
        ],
        "comments": "published at iclr 2026",
        "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, partial observations. We evaluate this through a benchmark where the goal is curiosity-driven exploration to build an accurate cognitive map. A key innovation is spatial belief probing, which prompts models to reveal their internal spatial representations at each step. Our evaluation of state-of-the-art models reveals several critical bottlenecks. First, we identify an Active-Passive Gap, where performance drops significantly when agents must autonomously gather information. Second, we find high inefficiency, as models explore unsystematically compared to program-based proxies. Through belief probing, we diagnose that while perception is an initial bottleneck, global beliefs suffer from instability that causes spatial knowledge to degrade over time. Finally, using a false belief paradigm, we uncover Belief Inertia, where agents fail to update obsolete priors with new evidence. This issue is present in text-based agents but is particularly severe in vision-based models. Our findings suggest that current foundation models struggle to maintain coherent, revisable spatial beliefs during active exploration.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 6,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07153",
        "abs_url": "https://arxiv.org/abs/2602.07153",
        "pdf_url": "https://arxiv.org/pdf/2602.07153",
        "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
        "authors": [
            "Jinbiao Wei",
            "Yilun Zhao",
            "Kangqi Ni",
            "Arman Cohan"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify branch points that correspond to meaningful state changes and propose new, state-grounded task variants conditioned on the current GUI context. An executing agent then follows the proposed instructions to generate new trajectories, while a verifier enforces task completion via state-aware checks and trajectory-level consistency. To improve supervision quality, we further apply task-conditioned step-level filtering to remove ungrounded actions and denoise post-branch segments to maintain coherent intent. Experiments on standard desktop benchmarks, OSWorld and WindowsAgentArena, show that models fine-tuned on our expanded corpus achieve consistent improvements over zero-shot agents and representative synthesis baselines, and generalize across applications and operating systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 7,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07187",
        "abs_url": "https://arxiv.org/abs/2602.07187",
        "pdf_url": "https://arxiv.org/pdf/2602.07187",
        "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents",
        "authors": [
            "Hanyu Wang",
            "Yuanpu Cao",
            "Lu Lin",
            "Jinghui Chen"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by criticizing and refining agent plans before execution. To support grounded prospective reflection, we distill planning errors from historical agent trajectories, capturing recurring success and failure patterns observed across past executions. Furthermore, we complement prospective reflection with a dynamic re-planning mechanism that provides execution-time plan update in case the original plan encounters unexpected deviation. Evaluations on different benchmarks demonstrate that PreFlect significantly improves overall agent utility on complex real-world tasks, outperforming strong reflection-based baselines and several more complex agent architectures. Code will be updated at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 8,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07238",
        "abs_url": "https://arxiv.org/abs/2602.07238",
        "pdf_url": "https://arxiv.org/pdf/2602.07238",
        "title": "Is there \"Secret Sauce'' in Large Language Model Development?",
        "authors": [
            "Matthias Mertens",
            "Natalia Fischl-Lanzoni",
            "Neil Thompson"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); General Economics (econ.GN)",
        "abstract": "Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-90% of performance differences are explained by higher training compute, implying that scale--not proprietary technology--drives frontier advances. Away from the frontier, however, proprietary techniques and shared algorithmic progress substantially reduce the compute required to reach fixed capability thresholds. Some companies can systematically produce smaller models more efficiently. Strikingly, we also find substantial variation of model efficiency within companies; a firm can train two models with more than 40x compute efficiency difference. We also discuss the implications for AI leadership and capability diffusion.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 9,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07253",
        "abs_url": "https://arxiv.org/abs/2602.07253",
        "pdf_url": "https://arxiv.org/pdf/2602.07253",
        "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View",
        "authors": [
            "Litian Liu",
            "Reza Pourreza",
            "Yubing Jian",
            "Yao Qin",
            "Roland Memisevic"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
        "abstract": "Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer vision. Treating next-token prediction in language models as a classification task allows us to apply OOD techniques, provided appropriate modifications are made to account for the structural differences in large language models. We show that OOD-based approaches yield training-free, single-sample-based detectors, achieving strong accuracy in hallucination detection for reasoning tasks. Overall, our work suggests that reframing hallucination detection as OOD detection provides a promising and scalable pathway toward language model safety.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 10,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07259",
        "abs_url": "https://arxiv.org/abs/2602.07259",
        "pdf_url": "https://arxiv.org/pdf/2602.07259",
        "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective",
        "authors": [
            "Cheol Woo Kim",
            "Davin Choo",
            "Tzeh Yuan Neoh",
            "Milind Tambe"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how models are evaluated, and how they are ultimately deployed. We propose a new perspective on AI safety grounded in Stackelberg Security Games (SSGs): a class of game-theoretic models designed for adversarial resource allocation under uncertainty. By viewing AI oversight as a strategic interaction between defenders (auditors, evaluators, and deployers) and attackers (malicious actors, misaligned contributors, or worst-case failure modes), SSGs provide a unifying framework for reasoning about incentive design, limited oversight capacity, and adversarial uncertainty across the AI lifecycle. We illustrate how this framework can inform (1) training-time auditing against data/feedback poisoning, (2) pre-deployment evaluation under constrained reviewer resources, and (3) robust multi-model deployment in adversarial environments. This synthesis bridges algorithmic alignment and institutional oversight design, highlighting how game-theoretic deterrence can make AI oversight proactive, risk-aware, and resilient to manipulation.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 11,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07267",
        "abs_url": "https://arxiv.org/abs/2602.07267",
        "pdf_url": "https://arxiv.org/pdf/2602.07267",
        "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance",
        "authors": [
            "Fengyuan Liu",
            "Jay Gala",
            "Nilaksh",
            "Dzmitry Bahdanau",
            "Siva Reddy",
            "Hugo Larochelle"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion time. Using a two-parameter logistic Item Response Theory model, we jointly estimate latent task difficulty and model capability from model performance data across multiple benchmarks. We demonstrate that latent task difficulty varies linearly with the logarithm of human completion time, allowing human task completion time to be inferred for new benchmarks from model performance alone. Leveraging this alignment, we forecast frontier model capabilities in terms of human task length and independently reproduce METR's exponential scaling results, with the 50% solvable task horizon doubling approximately every 6 months.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 12,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07274",
        "abs_url": "https://arxiv.org/abs/2602.07274",
        "pdf_url": "https://arxiv.org/pdf/2602.07274",
        "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
        "authors": [
            "Kaijie Zhu",
            "Yuzhou Nie",
            "Yijiang Li",
            "Yiming Huang",
            "Jialian Wu",
            "Jiang Liu",
            "Ximeng Sun",
            "Zhenfei Yin",
            "Lun Wang",
            "Zicheng Liu",
            "Emad Barsoum",
            "William Yang Wang",
            "Wenbo Guo"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common to smaller models. This creates a distributional mismatch, leaving student models ill-equipped to recover from their own runtime failures. To bridge these gaps, we introduce TermiGen, an end-to-end pipeline for synthesizing verifiable environments and resilient expert trajectories. Termi-Gen first generates functionally valid tasks and Docker containers via an iterative multi-agent refinement loop. Subsequently, we employ a Generator-Critic protocol that actively injects errors during trajectory collection, synthesizing data rich in error-correction cycles. Fine-tuned on this TermiGen-generated dataset, our TermiGen-Qwen2.5-Coder-32B achieves a 31.3% pass rate on TerminalBench. This establishes a new open-weights state-of-the-art, outperforming existing baselines and notably surpassing capable proprietary models such as o4-mini. Dataset is avaiable at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 13,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07276",
        "abs_url": "https://arxiv.org/abs/2602.07276",
        "pdf_url": "https://arxiv.org/pdf/2602.07276",
        "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs",
        "authors": [
            "Pengrui Han",
            "Xueqiang Xu",
            "Keyang Xuan",
            "Peiyang Song",
            "Siru Ouyang",
            "Runchu Tian",
            "Yuqing Jiang",
            "Cheng Qian",
            "Pengcheng Jiang",
            "Jiashuo Sun",
            "Junxia Cui",
            "Ming Zhong",
            "Ge Liu",
            "Jiawei Han",
            "Jiaxuan You"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by composing steering vectors rather than learning new ones from scratch. In many domains (e.g., reasoning or safety), tasks share a small set of underlying concept dimensions. STEER2ADAPT captures these dimensions as a reusable, low-dimensional semantic prior subspace, and adapts to new tasks by dynamically discovering a linear combination of basis vectors from only a handful of examples. Experiments across 9 tasks and 3 models in both reasoning and safety domains demonstrate the effectiveness of STEER2ADAPT, achieving an average improvement of 8.2%. Extensive analyses further show that STEER2ADAPT is a data-efficient, stable, and transparent inference-time adaptation method for LLMs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 14,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07308",
        "abs_url": "https://arxiv.org/abs/2602.07308",
        "pdf_url": "https://arxiv.org/pdf/2602.07308",
        "title": "Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System",
        "authors": [
            "Sutapa Dey Tithi",
            "Nazia Alam",
            "Tahreem Yasir",
            "Yang Shi",
            "Xiaoyi Tian",
            "Min Chi",
            "Tiffany Barnes"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selecting worked examples in two different ICAP modes: (active) Guided examples and (constructive) Buggy examples. We compare Bayesian Knowledge Tracing (BKT) and Deep Reinforcement Learning (DRL) as adaptive methods against a non-adaptive baseline method for selecting example type in a logic ITS. Our experiment with 113 students demonstrates that both adaptive policies significantly improved student performance on test problems. BKT yielded the largest improvement in posttest scores for low prior knowledge students, helping them catch up with their high prior knowledge peers, whereas DRL yielded significantly higher posttest scores among high prior knowledge students. This paper contributes new insights into the complex interactions of cognitive engagement and adaptivity and their results on learning outcomes.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 15,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2007.16012",
        "abs_url": "https://arxiv.org/abs/2007.16012",
        "pdf_url": "https://arxiv.org/pdf/2007.16012",
        "title": "BERT Learns (and Teaches) Chemistry",
        "authors": [
            "Josh Payne",
            "Mario Srouji",
            "Dian Ang Yap",
            "Vineet Kosaraju"
        ],
        "comments": "10 pages, 5 figures",
        "subjects": "Biomolecules (q-bio.BM); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)",
        "abstract": "Modern computational organic chemistry is becoming increasingly data-driven. There remain a large number of important unsolved problems in this area such as product prediction given reactants, drug discovery, and metric-optimized molecule synthesis, but efforts to solve these problems using machine learning have also increased in recent years. In this work, we propose the use of attention to study functional groups and other property-impacting molecular substructures from a data-driven perspective, using a transformer-based model (BERT) on datasets of string representations of molecules and analyzing the behavior of its attention heads. We then apply the representations of functional groups and atoms learned by the model to tackle problems of toxicity, solubility, drug-likeness, and synthesis accessibility on smaller datasets using the learned representations as features for graph convolution and attention models on the graph structure of molecules, as well as fine-tuning of BERT. Finally, we propose the use of attention visualization as a helpful tool for chemistry practitioners and students to quickly identify important substructures in various chemical properties.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 16,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.06967",
        "abs_url": "https://arxiv.org/abs/2602.06967",
        "pdf_url": "https://arxiv.org/pdf/2602.06967",
        "title": "Leveraging Adaptive Group Negotiation for Heterogeneous Multi-Robot Collaboration with Large Language Models",
        "authors": [
            "Siqi Song",
            "Xuanbing Xie",
            "Zonglin Li",
            "Yuqiang Li",
            "Shijie Wang",
            "Biqing Qi"
        ],
        "comments": "20 pages, 12 figures, Under Review",
        "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
        "abstract": "Multi-robot collaboration tasks often require heterogeneous robots to work together over long horizons under spatial constraints and environmental uncertainties. Although Large Language Models (LLMs) excel at reasoning and planning, their potential for coordinated control has not been fully explored. Inspired by human teamwork, we present CLiMRS (Cooperative Large-Language-Model-Driven Heterogeneous Multi-Robot System), an adaptive group negotiation framework among LLMs for multi-robot collaboration. This framework pairs each robot with an LLM agent and dynamically forms subgroups through a general proposal planner. Within each subgroup, a subgroup manager leads perception-driven multi-LLM discussions to get commands for actions. Feedback is provided by both robot execution outcomes and environment changes. This grouping-planning-execution-feedback loop enables efficient planning and robust execution. To evaluate these capabilities, we introduce CLiMBench, a heterogeneous multi-robot benchmark of challenging assembly tasks. Our experiments show that CLiMRS surpasses the best baseline, achieving over 40% higher efficiency on complex tasks without sacrificing success on simpler ones. Overall, our results demonstrate that leveraging human-inspired group formation and negotiation principles significantly enhances the efficiency of heterogeneous multi-robot collaboration. Our code is available here: this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 17,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.06973",
        "abs_url": "https://arxiv.org/abs/2602.06973",
        "pdf_url": "https://arxiv.org/pdf/2602.06973",
        "title": "Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models",
        "authors": [
            "Lucky Susanto",
            "Musa Izzanardi Wijanarko",
            "Khumaisa Nur'aini",
            "Farid Adilazuarda",
            "Alham Fikri Aji",
            "Derry Tanti Wijaya"
        ],
        "comments": "Submitted to ARR January",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundamental question, does visual rendering truly decouple a model from tokenization constraints? Focusing on four Indonesian low-resource local languages that have their own non-Latin scripts (i.e., Javanese, Balinese, Sundanese, and Lampungnese), we evaluate the impact of script-tokenizer alignment within the DualGPT architecture. Our results show that, despite visual rendering, reintegrating a text tokenizer into the architecture reintroduces the same issue that pixel-based language modeling aims to resolve, which is the tokenizer misalignment problem. Despite having lower OOV and fertility rates, we show that the Llama 2 tokenizer performs significantly worse than a custom tokenizer, with improvements of up to 30.15 chrF++. Our findings serve as a warning for future multimodal variants, as text tokenizers remain a significant barrier to equitable models.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 18,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.06975",
        "abs_url": "https://arxiv.org/abs/2602.06975",
        "pdf_url": "https://arxiv.org/pdf/2602.06975",
        "title": "BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents",
        "authors": [
            "R. James Cotton",
            "Thomas Leonard"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enables biomechanical analysis through natural language and allows users to querying databases, generating visualizations, and even interpret data without requiring users to write code. To evaluate BiomechAgent's capabilities, we developed a systematic benchmark spanning data retrieval, visualization, activity classification, temporal segmentation, and clinical reasoning. BiomechAgent achieved robust accuracy on data retrieval and visualization tasks and demonstrated emerging clinical reasoning capabilities. We used our dataset to systematically evaluate several of our design decisions. Biomechanically-informed, domain-specific instructions significantly improved performance over generic prompts, and integrating validated specialized tools for gait event detection substantially boosted accuracy on challenging spatiotemporal analysis where the base agent struggled. We also tested BiomechAgent using a local open-weight model instead of a frontier cloud based LLM and found that perform was substantially diminished in most domains other than database retrieval. In short, BiomechAgent makes the data from accessible motion capture and much more useful and accessible to end users.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 19,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.06976",
        "abs_url": "https://arxiv.org/abs/2602.06976",
        "pdf_url": "https://arxiv.org/pdf/2602.06976",
        "title": "Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks",
        "authors": [
            "Chen Shen",
            "Wei Cheng",
            "Jingyue Yang",
            "Huan Zhang",
            "Yuhan Wu",
            "Wei Hu"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL)",
        "abstract": "The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this paper, we propose ILA-agent, a general ILA framework that equips LLMs with a set of behavioral primitives. By modeling essential human-like behaviors as a suite of tools, ILA-agent enables LLMs to incrementally explore, apply, and verify language knowledge through structured interactions with the official documentation and execution environment. To provide a rigorous evaluation in a low-resource setting, we construct Cangjie-bench, a multi-task benchmark based on the novel statically-typed language Cangjie. We instantiate ILA-agent for Cangjie and evaluate its performance across code generation, translation, and program repair tasks. Results using diverse LLMs demonstrate that ILA-agent significantly outperforms retrieval-augmented baselines. Further analysis of agent trajectories characterizes the emergent behavior patterns while highlighting persisting performance gaps.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 20,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.06981",
        "abs_url": "https://arxiv.org/abs/2602.06981",
        "pdf_url": "https://arxiv.org/pdf/2602.06981",
        "title": "What is Safety? Corporate Discourse, Power, and the Politics of Generative AI Safety",
        "authors": [
            "Ankolika De",
            "Gabriel Lima",
            "Yixin Zou"
        ],
        "comments": "18 pages, 2 tables",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)",
        "abstract": "This work examines how leading generative artificial intelligence companies construct and communicate the concept of \"safety\" through public-facing documents. Drawing on critical discourse analysis, we analyze a corpus of corporate safety-related statements to explicate how authority, responsibility, and legitimacy are discursively established. These discursive strategies consolidate legitimacy for corporate actors, normalize safety as an experimental and anticipatory practice, and push a perceived participatory agenda toward safe technologies. We argue that uncritical uptake of these discourses risks reproducing corporate priorities and constraining alternative approaches to governance and design. The contribution of this work is twofold: first, to situate safety as a sociotechnical discourse that warrants critical examination; second, to caution human-computer interaction scholars against legitimizing corporate framings, instead foregrounding accountability, equity, and justice. By interrogating safety discourses as artifacts of power, this paper advances a critical agenda for human-computer interaction scholarship on artificial intelligence.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 21,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.06982",
        "abs_url": "https://arxiv.org/abs/2602.06982",
        "pdf_url": "https://arxiv.org/pdf/2602.06982",
        "title": "Deep Reinforcement Learning for Interference Suppression in RIS-Aided Space-Air-Ground Integrated Networks",
        "authors": [
            "Pujitha Mamillapalli",
            "Shikhar Verma",
            "Tiago Koketsu Rodrigues",
            "Abhinav Kumar"
        ],
        "comments": "",
        "subjects": "Signal Processing (eess.SP); Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG)",
        "abstract": "Future 6G networks envision ubiquitous connectivity through space-air-ground integrated networks (SAGINs), where high-altitude platform stations (HAPSs) and satellites complement terrestrial systems to provide wide-area, low-latency coverage. However, the rapid growth of terrestrial devices intensifies spectrum sharing between terrestrial and non-terrestrial segments, resulting in severe cross-tier interference. In particular, frequency sharing between the HAPS satellite uplink and HAPS ground downlink improves spectrum efficiency but suffers from interference caused by the HAPS antenna back-lobe. Existing approaches relying on zero-forcing (ZF) codebooks have limited performance under highly dynamic channel conditions. To overcome this limitation, we employ a reconfigurable intelligent surface (RIS)-aided HAPS-based SAGIN framework with a deep deterministic policy gradient (DDPG) algorithm. The proposed DDPG framework optimizes the HAPS beamforming weights to form spatial nulls toward interference sources while maintaining robust links to the desired signals. Simulation results demonstrate that the DDPG framework consistently outperforms conventional ZF beamforming among different RIS configurations, achieving up to \\(11.3\\%\\) throughput improvement for a \\(4\\times4\\) RIS configuration, validating its adaptive capability to enhance spectral efficiency in dynamic HAPS-based SAGINs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 22,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.06983",
        "abs_url": "https://arxiv.org/abs/2602.06983",
        "pdf_url": "https://arxiv.org/pdf/2602.06983",
        "title": "Hybrid Deep Learning Framework for CSI-Based Activity Recognition in Bandwidth-Constrained Wi-Fi Sensing",
        "authors": [
            "Alison M. Fernandes",
            "Hermes I. Del Monego",
            "Bruno S. Chang",
            "Anelise Munaretto",
            "HÃ©lder M. Fontes",
            "Rui Campos"
        ],
        "comments": "6 pages, 6 figures",
        "subjects": "Signal Processing (eess.SP); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "This paper presents a novel hybrid deep learning framework designed to enhance the robustness of CSI-based Human Activity Recognition (HAR) within bandwidth-constrained Wi-Fi sensing environments. The core of our proposed methodology is a preliminary Doppler trace extraction stage, implemented to amplify salient motion-related signal features before classification. Subsequently, these enhanced inputs are processed by a hybrid neural architecture, which integrates Inception networks responsible for hierarchical spatial feature extraction and Bidirectional Long Short-Term Memory (BiLSTM) networks that capture temporal dependencies. A Support Vector Machine (SVM) is then utilized as the final classification layer to optimize decision boundaries. The framework's efficacy was systematically validated using a public dataset across 20, 40, and 80 MHz bandwidth configurations. The model yielded accuracies of 89.27% (20 MHz), 94.13% (40 MHz), and 95.30% (80 MHz), respectively. These results confirm a marked superiority over standalone deep learning baselines, especially in the most constrained low-bandwidth scenarios. This study underscores the utility of combining Doppler-based feature engineering with a hybrid learning architecture for reliable HAR in bandwidth-limited wireless sensing applications.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 23,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.06984",
        "abs_url": "https://arxiv.org/abs/2602.06984",
        "pdf_url": "https://arxiv.org/pdf/2602.06984",
        "title": "Empowering Affected Individuals to Shape AI Fairness Assessments: Processes, Criteria, and Tools",
        "authors": [
            "Lin Luo",
            "Satwik Ghanta",
            "Yuri Nakao",
            "Mathieu Chollet",
            "Simone Stumpf"
        ],
        "comments": "",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)",
        "abstract": "AI systems are increasingly used in high-stakes domains such as credit rating, where fairness concerns are critical. Existing fairness assessments are typically conducted by AI experts or regulators using predefined protected attributes and metrics, which often fail to capture the diversity and nuance of fairness notions held by the individuals who are affected by these systems' decisions, such as decision subjects. Recent work has therefore called for involving affected individuals in fairness assessment, yet little empirical evidence exists on how they create their own fairness criteria or what kinds of criteria they produce - knowledge that could not only inform experts' fairness evaluation and mitigation, but also guide the design of AI assessment tools. We address this gap through a qualitative user study with 18 participants in a credit rating scenario. Participants first articulated their fairness notions in their own words. Then, participants turned them into concrete quantified and operationalized fairness criteria, through an interactive prototype we designed. Our findings provide empirical evidence of the process through which people's fairness notions emerge via grounding in model features, and uncover a diverse set of individuals' custom-defined criteria for both outcome and procedural fairness. We provide design implications for processes and tools that support more inclusive and value-sensitive AI fairness assessment.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 24,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.06992",
        "abs_url": "https://arxiv.org/abs/2602.06992",
        "pdf_url": "https://arxiv.org/pdf/2602.06992",
        "title": "A New Mode of Teaching Chinese as a Foreign Language from the Perspective of Smart System Studied by Using Rongzhixue",
        "authors": [
            "Xiaohui Zou",
            "Lijun Ke",
            "Shunpeng Zou"
        ],
        "comments": "11 pages, in Chinese language, 22 figures",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)",
        "abstract": "The purpose of this study is to introduce a new model of teaching Chinese as a foreign language from the perspective of integrating wisdom. Its characteristics are as follows: focusing on the butterfly model of interpretation before translation, highlighting the new method of bilingual thinking training, on the one hand, applying the new theory of Chinese characters, the theory of the relationship between language and speech, and the forward-looking research results of language science; On the other hand, the application of the new model of teaching Chinese as a foreign language, AI empowering teaching and learning, and the forward-looking research results of educational science fully reflect a series of characteristics of the new model of teaching Chinese as a foreign language from the perspective of integrating wisdom. Its beneficial effects are: not only the old view of language and education, especially the old view of teaching Chinese as a foreign language, but also the old view of human-computer interaction. Its significance lies in that a series of great cross-border Rongzhixue such as language, knowledge, education and teaching, as well as new methods and new topics of bilingual thinking training are clearly put forward from the perspective of integrating wisdom. Especially in the face of the challenge of Chat GPT to human learning ability and even creativity, the existing concepts of language knowledge education and teaching are already very backward. The old concepts of Chinese language education, and teaching Chinese as a foreign language are all facing a series of subversive innovation challenges. How to seek changes in adaptation? This study has made a series of innovative attempts, hoping to benefit academic colleagues, teachers and students.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 25,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.06997",
        "abs_url": "https://arxiv.org/abs/2602.06997",
        "pdf_url": "https://arxiv.org/pdf/2602.06997",
        "title": "Adaptive Temporal Dynamics for Personalized Emotion Recognition: A Liquid Neural Network Approach",
        "authors": [
            "Anindya Bhattacharjee",
            "Nittya Ananda Biswas",
            "K. A. Shahriar",
            "Adib Rahman"
        ],
        "comments": "",
        "subjects": "Signal Processing (eess.SP); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Emotion recognition from physiological signals remains challenging due to their non-stationary, noisy, and subject-dependent characteristics. This work presents, to the best of our knowledge, the first comprehensive application of liquid neural networks for EEG-based emotion recognition. The proposed multimodal framework combines convolutional feature extraction, liquid neural networks with learnable time constants, and attention-guided fusion to model temporal EEG dynamics with complementary peripheral physiological and personality features. Dedicated subnetworks are used to process EEG features and auxiliary modalities, and a shared autoencoder-based fusion module is used to learn discriminative latent representations before classification. Subject-dependent experiments conducted on the PhyMER dataset across seven emotional classes achieve an accuracy of 95.45%, surpassing previously reported results. Furthermore, temporal attention analysis provides interpretable insights into emotion-specific temporal relevance, and t-SNE visualizations demonstrate enhanced class separability, highlighting the effectiveness of the proposed approach. Finally, statistical analysis of temporal dynamics confirms that the network self-organizes into distinct functional groups with specialized fast and slow neurons, proving it independently tunes learnable time constants and memory dominance to effectively capture complex emotion artifacts.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 26,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07000",
        "abs_url": "https://arxiv.org/abs/2602.07000",
        "pdf_url": "https://arxiv.org/pdf/2602.07000",
        "title": "Hierarchical JEPA Meets Predictive Remote Control in Beyond 5G Networks",
        "authors": [
            "Abanoub M. Girgis",
            "Ibtissam Labriji",
            "Mehdi Bennis"
        ],
        "comments": "",
        "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Robotics (cs.RO)",
        "abstract": "In wireless networked control systems, ensuring timely and reliable state updates from distributed devices to remote controllers is essential for robust control performance. However, when multiple devices transmit high-dimensional states (e.g., images or video frames) over bandwidth-limited wireless networks, a critical trade-off emerges between communication efficiency and control performance. To address this challenge, we propose a Hierarchical Joint-Embedding Predictive Architecture (H-JEPA) for scalable predictive control. Instead of transmitting states, device observations are encoded into low-dimensional embeddings that preserve essential dynamics. The proposed architecture employs a three-level hierarchical prediction, with high-level, medium-level, and low-level predictors operating across different temporal resolutions, to achieve long-term prediction stability, intermediate interpolation, and fine-grained refinement, respectively. Control actions are derived within the embedding space, removing the need for state reconstruction. Simulation results on inverted cart-pole systems demonstrate that H-JEPA enables up to 42.83 % more devices to be supported under limited wireless capacity without compromising control performance.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 27,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07009",
        "abs_url": "https://arxiv.org/abs/2602.07009",
        "pdf_url": "https://arxiv.org/pdf/2602.07009",
        "title": "Multi-Scale Temporal Homeostasis Enables Efficient and Robust Neural Networks",
        "authors": [
            "MD Azizul Hakim"
        ],
        "comments": "",
        "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI)",
        "abstract": "Artificial neural networks achieve strong performance on benchmark tasks but remain fundamentally brittle under perturbations, limiting their deployment in real-world settings. In contrast, biological nervous systems sustain reliable function across decades through homeostatic regulation coordinated across multiple temporal scales. Inspired by this principle, this presents Multi-Scale Temporal Homeostasis (MSTH), a biologically grounded framework that integrates ultra-fast (5-ms), fast (2-s), medium (5-min) and slow (1-hrs) regulation into artificial networks. MSTH implements the cross-scale coordination system for artificial neural networks, providing a unified temporal hierarchy that moves beyond superficial biomimicry. The cross-scale coordination enhances computational efficiency through evolutionary-refined optimization mechanisms. Experiments across molecular, graph and image classification benchmarks show that MSTH consistently improves accuracy, eliminates catastrophic failures and enhances recovery from perturbations. Moreover, MSTH outperforms both single-scale bio-inspired models and established state-of-the-art methods, demonstrating generality across diverse domains. These findings establish cross-scale temporal coordination as a core principle for stabilizing artificial neural systems, positioning MSTH as a foundation for building robust, resilient and biologically faithful intelligence.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 28,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07010",
        "abs_url": "https://arxiv.org/abs/2602.07010",
        "pdf_url": "https://arxiv.org/pdf/2602.07010",
        "title": "Learning Alzheimer's Disease Signatures by bridging EEG with Spiking Neural Networks and Biophysical Simulations",
        "authors": [
            "Szymon MamoÅ",
            "Max Talanov",
            "Alessandro Crimi"
        ],
        "comments": "11 pages ,8 figures",
        "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI)",
        "abstract": "As the prevalence of Alzheimer's disease (AD) rises, improving mechanistic insight from non-invasive biomarkers is increasingly critical. Recent work suggests that circuit-level brain alterations manifest as changes in electroencephalography (EEG) spectral features detectable by machine learning. However, conventional deep learning approaches for EEG-based AD detection are computationally intensive and mechanistically opaque. Spiking neural networks (SNNs) offer a biologically plausible and energy-efficient alternative, yet their application to AD diagnosis remains largely unexplored. We propose a neuro-bridge framework that links data-driven learning with minimal, biophysically grounded simulations, enabling bidirectional interpretation between machine learning signatures and circuit-level mechanisms in AD. Using resting-state clinical EEG, we train an SNN classifier that achieves competitive performance (AUC = 0.839) and identifies the aperiodic 1/f slope as a key discriminative marker. The 1/f slope reflects excitation-inhibition balance. To interpret this mechanistically, we construct spiking network simulations in which inhibitory-to-excitatory synaptic ratios are systematically varied to emulate healthy, mild cognitive impairment, and AD-like states. Using both membrane potential-based and synaptic current-based EEG proxies, we reproduce empirical spectral slowing and altered alpha organization. Incorporating empirical functional connectivity priors into multi-subnetwork simulations further enhances spectral differentiation, demonstrating that large-scale network topology constrains EEG signatures more strongly than excitation-inhibition balance alone. Overall, this neuro-bridge approach connects SNN-based classification with interpretable circuit simulations, advancing mechanistic understanding of EEG biomarkers while enabling scalable, explainable AD detection.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 29,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07012",
        "abs_url": "https://arxiv.org/abs/2602.07012",
        "pdf_url": "https://arxiv.org/pdf/2602.07012",
        "title": "A General Model for Retinal Segmentation and Quantification",
        "authors": [
            "Zhonghua Wang",
            "Lie Ju",
            "Sijia Li",
            "Wei Feng",
            "Sijin Zhou",
            "Ming Hu",
            "Jianhao Xiong",
            "Xiaoying Tang",
            "Yifan Peng",
            "Mingquan Lin",
            "Yaodong Ding",
            "Yong Zeng",
            "Wenbin Wei",
            "Li Dong",
            "Zongyuan Ge"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
        "abstract": "Retinal imaging is fast, non-invasive, and widely available, offering quantifiable structural and vascular signals for ophthalmic and systemic health assessment. This accessibility creates an opportunity to study how quantitative retinal phenotypes relate to ocular and systemic diseases. However, such analyses remain difficult at scale due to the limited availability of public multi-label datasets and the lack of a unified segmentation-to-quantification pipeline. We present RetSAM, a general retinal segmentation and quantification framework for fundus imaging. It delivers robust multi-target segmentation and standardized biomarker extraction, supporting downstream ophthalmologic studies and oculomics correlation analyses. Trained on over 200,000 fundus images, RetSAM supports three task categories and segments five anatomical structures, four retinal phenotypic patterns, and more than 20 distinct lesion types. It converts these segmentation results into over 30 standardized biomarkers that capture structural morphology, vascular geometry, and degenerative changes. Trained with a multi-stage strategy using both private and public fundus data, RetSAM achieves superior segmentation performance on 17 public datasets. It improves on prior best methods by 3.9 percentage points in DSC on average, with up to 15 percentage points on challenging multi-task benchmarks, and generalizes well across diverse populations, imaging devices, and clinical settings. The resulting biomarkers enable systematic correlation analyses across major ophthalmic diseases, including diabetic retinopathy, age-related macular degeneration, glaucoma, and pathologic myopia. Together, RetSAM transforms fundus images into standardized, interpretable quantitative phenotypes, enabling large-scale ophthalmic research and translation.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 30,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07014",
        "abs_url": "https://arxiv.org/abs/2602.07014",
        "pdf_url": "https://arxiv.org/pdf/2602.07014",
        "title": "Vectra: A New Metric, Dataset, and Model for Visual Quality Assessment in E-Commerce In-Image Machine Translation",
        "authors": [
            "Qingyu Wu",
            "Yuxuan Han",
            "Haijun Li",
            "Zhao Xu",
            "Jianshan Zhao",
            "Xu Jin",
            "Longyue Wang",
            "Weihua Luo"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
        "abstract": "In-Image Machine Translation (IIMT) powers cross-border e-commerce product listings; existing research focuses on machine translation evaluation, while visual rendering quality is critical for user engagement. When facing context-dense product imagery and multimodal defects, current reference-based methods (e.g., SSIM, FID) lack explainability, while model-as-judge approaches lack domain-grounded, fine-grained reward signals. To bridge this gap, we introduce Vectra, to the best of our knowledge, the first reference-free, MLLM-driven visual quality assessment framework for e-commerce IIMT. Vectra comprises three components: (1) Vectra Score, a multidimensional quality metric system that decomposes visual quality into 14 interpretable dimensions, with spatially-aware Defect Area Ratio (DAR) quantification to reduce annotation ambiguity; (2) Vectra Dataset, constructed from 1.1M real-world product images via diversity-aware sampling, comprising a 2K benchmark for system evaluation, 30K reasoning-based annotations for instruction tuning, and 3.5K expert-labeled preferences for alignment and evaluation; and (3) Vectra Model, a 4B-parameter MLLM that generates both quantitative scores and diagnostic reasoning. Experiments demonstrate that Vectra achieves state-of-the-art correlation with human rankings, and our model outperforms leading MLLMs, including GPT-5 and Gemini-3, in scoring performance. The dataset and model will be released upon acceptance.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 31,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07021",
        "abs_url": "https://arxiv.org/abs/2602.07021",
        "pdf_url": "https://arxiv.org/pdf/2602.07021",
        "title": "AI for Sustainable Data Protection and Fair Algorithmic Management in Environmental Regulation",
        "authors": [
            "Sahibpreet Singh",
            "Saksham Sharma"
        ],
        "comments": "Presented at National Conference on Navigating The Intersection of Artificial Intelligence and Law: Ethical and Legal Horizons, 29 September 2024, pp. 91-106",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)",
        "abstract": "Integration of AI into environmental regulation represents a significant advancement in data management. It offers promising results in both data protection plus algorithmic fairness. This research addresses the critical need for sustainable data protection in the era of ever evolving cyber threats. Traditional encryption methods face limitations in handling the dynamic nature of environmental data. This necessitates the exploration of advanced cryptographic techniques. The objective of this study is to evaluate how AI can enhance these techniques to ensure robust data protection while facilitating fair algorithmic management. The methodology involves a comprehensive review of current advancements in AI-enhanced homomorphic encryption (HE) and multi-party computation (MPC). It is coupled with an analysis of how these techniques can be applied to environmental data regulation. Key findings indicate that AI-driven dynamic key management, adaptive encryption schemes, and optimized computational efficiency in HE, alongside AI-enhanced protocol optimization and fault mitigation in MPC, significantly improve the security of environmental data processing. These findings highlight a crucial research gap in the intersection of AI, cyber laws, and environmental regulation, particularly in terms of addressing algorithmic bias, transparency, and accountability. The implications of this research underscore the need for stricter cyber laws. Also, the development of comprehensive regulations to safeguard sensitive environmental data. Future efforts should focus on refining AI systems to balance security with privacy and ensuring that regulatory frameworks can adapt to technological advancements. This study provides a foundation for future research aimed at achieving secure sustainable environmental data management through AI innovations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 32,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07023",
        "abs_url": "https://arxiv.org/abs/2602.07023",
        "pdf_url": "https://arxiv.org/pdf/2602.07023",
        "title": "Behavioral Consistency Validation for LLM Agents: An Analysis of Trading-Style Switching through Stock-Market Simulation",
        "authors": [
            "Zeping Li",
            "Guancheng Wan",
            "Keyang Chen",
            "Yu Chen",
            "Yiwen Zhao",
            "Philip Torr",
            "Guangnan Ye",
            "Zhenfei Yin",
            "Hongfeng Chai"
        ],
        "comments": "",
        "subjects": "Trading and Market Microstructure (q-fin.TR); Artificial Intelligence (cs.AI)",
        "abstract": "Recent works have increasingly applied Large Language Models (LLMs) as agents in financial stock market simulations to test if micro-level behaviors aggregate into macro-level phenomena. However, a crucial question arises: Do LLM agents' behaviors align with real market participants? This alignment is key to the validity of simulation results. To explore this, we select a financial stock market scenario to test behavioral consistency. Investors are typically classified as fundamental or technical traders, but most simulations fix strategies at initialization, failing to reflect real-world trading dynamics. In this work, we assess whether agents' strategy switching aligns with financial theory, providing a framework for this evaluation. We operationalize four behavioral-finance drivers-loss aversion, herding, wealth differentiation, and price misalignment-as personality traits set via prompting and stored long-term. In year-long simulations, agents process daily price-volume data, trade under a designated style, and reassess their strategy every 10 trading days. We introduce four alignment metrics and use Mann-Whitney U tests to compare agents' style-switching behavior with financial theory. Our results show that recent LLMs' switching behavior is only partially consistent with behavioral-finance theories, highlighting the need for further refinement in aligning agent behavior with financial theory.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 33,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07026",
        "abs_url": "https://arxiv.org/abs/2602.07026",
        "pdf_url": "https://arxiv.org/pdf/2602.07026",
        "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
        "authors": [
            "Xiaomin Yu",
            "Yi Xin",
            "Wenjie Zhang",
            "Chonghan Liu",
            "Hanzhen Zhao",
            "Xiaoxing Hu",
            "Xinlei Yu",
            "Ziyue Qiao",
            "Hao Tang",
            "Xue Yang",
            "Xiaobin Hu",
            "Chengwei Qin",
            "Hui Xiong",
            "Yu Qiao",
            "Shuicheng Yan"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multimedia (cs.MM)",
        "abstract": "Despite the success of multimodal contrastive learning in aligning visual and linguistic representations, a persistent geometric anomaly, the Modality Gap, remains: embeddings of distinct modalities expressing identical semantics occupy systematically offset regions. Prior approaches to bridge this gap are largely limited by oversimplified isotropic assumptions, hindering their application in large-scale scenarios. In this paper, we address these limitations by precisely characterizing the geometric shape of the modality gap and leveraging it for efficient model scaling. First, we propose the Fixed-frame Modality Gap Theory, which decomposes the modality gap within a frozen reference frame into stable biases and anisotropic residuals. Guided by this precise modeling, we introduce ReAlign, a training-free modality alignment strategy. Utilizing statistics from massive unpaired data, ReAlign aligns text representation into the image representation distribution via a three-step process comprising Anchor, Trace, and Centroid Alignment, thereby explicitly rectifying geometric misalignment. Building on ReAlign, we propose ReVision, a scalable training paradigm for Multimodal Large Language Models (MLLMs). ReVision integrates ReAlign into the pretraining stage, enabling the model to learn the distribution of visual representations from unpaired text before visual instruction tuning, without the need for large-scale, high-quality image-text pairs. Our framework demonstrates that statistically aligned unpaired data can effectively substitute for expensive image-text pairs, offering a robust path for the efficient scaling of MLLMs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 34,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07031",
        "abs_url": "https://arxiv.org/abs/2602.07031",
        "pdf_url": "https://arxiv.org/pdf/2602.07031",
        "title": "Lagged backward-compatible physics-informed neural networks for unsaturated soil consolidation analysis",
        "authors": [
            "Dong Li",
            "Shuai Huang",
            "Yapeng Cao",
            "Yujun Cui",
            "Xiaobin Wei",
            "Hongtao Cao"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)",
        "abstract": "This study develops a Lagged Backward-Compatible Physics-Informed Neural Network (LBC-PINN) for simulating and inverting one-dimensional unsaturated soil consolidation under long-term loading. To address the challenges of coupled air and water pressure dissipation across multi-scale time domains, the framework integrates logarithmic time segmentation, lagged compatibility loss enforcement, and segment-wise transfer learning. In forward analysis, the LBC-PINN with recommended segmentation schemes accurately predicts pore air and pore water pressure evolution. Model predictions are validated against finite element method (FEM) results, with mean absolute errors below 1e-2 for time durations up to 1e10 seconds. A simplified segmentation strategy based on the characteristic air-phase dissipation time improves computational efficiency while preserving predictive accuracy. Sensitivity analyses confirm the robustness of the framework across air-to-water permeability ratios ranging from 1e-3 to 1e3.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 35,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07036",
        "abs_url": "https://arxiv.org/abs/2602.07036",
        "pdf_url": "https://arxiv.org/pdf/2602.07036",
        "title": "MENASpeechBank: A Reference Voice Bank with Persona-Conditioned Multi-Turn Conversations for AudioLLMs",
        "authors": [
            "Zien Sheikh Ali",
            "Hunzalah Hassan Bhatti",
            "Rabindra Nath Nandi",
            "Shammur Absar Chowdhury",
            "Firoj Alam"
        ],
        "comments": "Foundation Models, Large Language Models, Native, Speech Models, Arabic, AI-persona, Persona-conditioned-conversations",
        "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)",
        "abstract": "Audio large language models (AudioLLMs) enable instruction-following over speech and general audio, but progress is increasingly limited by the lack of diverse, conversational, instruction-aligned speech-text data. This bottleneck is especially acute for persona-grounded interactions and dialectal coverage, where collecting and releasing real multi-speaker recordings is costly and slow. We introduce MENASpeechBank, a reference speech bank comprising about 18K high-quality utterances from 124 speakers spanning multiple MENA countries, covering English, Modern Standard Arabic (MSA), and regional Arabic varieties. Building on this resource, we develop a controllable synthetic data pipeline that: (i) constructs persona profiles enriched with World Values Survey-inspired attributes, (ii) defines a taxonomy of about 5K conversational scenarios, (iii) matches personas to scenarios via semantic similarity, (iv) generates about 417K role-play conversations with an LLM where the user speaks as the persona and the assistant behaves as a helpful agent, and (v) synthesizes the user turns by conditioning on reference speaker audio to preserve speaker identity and diversity. We evaluate both synthetic and human-recorded conversations and provide detailed analysis. We will release MENASpeechBank and the generated conversations publicly for the community.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 36,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07039",
        "abs_url": "https://arxiv.org/abs/2602.07039",
        "pdf_url": "https://arxiv.org/pdf/2602.07039",
        "title": "When Excellence Stops Producing Knowledge: A Practitioner's Observation on Research Funding",
        "authors": [
            "Heimo MÃ¼ller"
        ],
        "comments": "",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Digital Libraries (cs.DL)",
        "abstract": "After almost four decades of participating in competitive research funding -- as applicant, coordinator, evaluator, and panel member -- I have come to see a structural paradox: many participants recognize that the current system is approaching its functional limits, yet most reform measures intensify rather than alleviate the underlying dynamics. This paper documents how excellence has become decoupled from knowledge production through an increasing coupling to representability under evaluation. The discussion focuses on two domains in which this is particularly visible: competitive basic research funding and large EU consortium projects. Three accelerating trends are examined: the professionalization of proposal writing through specialized consultants, the rise of AI-assisted applications, and an evaluator shortage that forces panels to rely on reviewers increasingly distant from the actual research domains. These observations are offered not as external critique but as an insider account, in the hope that naming a widely experienced but rarely articulated pattern may enable more constructive orientation. Keywords: Research funding, Excellence, Evaluation, Goodhart's Law, Professionalization, AI-assisted proposals, Peer review crisis",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 37,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07045",
        "abs_url": "https://arxiv.org/abs/2602.07045",
        "pdf_url": "https://arxiv.org/pdf/2602.07045",
        "title": "VLRS-Bench: A Vision-Language Reasoning Benchmark for Remote Sensing",
        "authors": [
            "Zhiming Luo",
            "Di Wang",
            "Haonan Guo",
            "Jing Zhang",
            "Bo Du"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
        "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have enabled complex reasoning. However, existing remote sensing (RS) benchmarks remain heavily biased toward perception tasks, such as object recognition and scene classification. This limitation hinders the development of MLLMs for cognitively demanding RS applications. To address this, , we propose a Vision Language ReaSoning Benchmark (VLRS-Bench), which is the first benchmark exclusively dedicated to complex RS reasoning. Structured across the three core dimensions of Cognition, Decision, and Prediction, VLRS-Bench comprises 2,000 question-answer pairs with an average length of 71 words, spanning 14 tasks and up to eight temporal phases. VLRS-Bench is constructed via a specialized pipeline that integrates RS-specific priors and expert knowledge to ensure geospatial realism and reasoning complexity. Experimental results reveal significant bottlenecks in existing state-of-the-art MLLMs, providing critical insights for advancing multimodal reasoning within the remote sensing community.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 38,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07051",
        "abs_url": "https://arxiv.org/abs/2602.07051",
        "pdf_url": "https://arxiv.org/pdf/2602.07051",
        "title": "Neural Sentinel: Unified Vision Language Model (VLM) for License Plate Recognition with Human-in-the-Loop Continual Learning",
        "authors": [
            "Karthik Sivakoti"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Traditional Automatic License Plate Recognition (ALPR) systems employ multi-stage pipelines consisting of object detection networks followed by separate Optical Character Recognition (OCR) modules, introducing compounding errors, increased latency, and architectural complexity. This research presents Neural Sentinel, a novel unified approach that leverages Vision Language Models (VLMs) to perform license plate recognition, state classification, and vehicle attribute extraction through a single forward pass. Our primary contribution lies in demonstrating that a fine-tuned PaliGemma 3B model, adapted via Low-Rank Adaptation (LoRA), can simultaneously answer multiple visual questions about vehicle images, achieving 92.3% plate recognition accuracy, which is a 14.1% improvement over EasyOCR and 9.9% improvement over PaddleOCR baselines. We introduce a Human-in-the-Loop (HITL) continual learning framework that incorporates user corrections while preventing catastrophic forgetting through experience replay, maintaining a 70:30 ratio of original training data to correction samples. The system achieves a mean inference latency of 152ms with an Expected Calibration Error (ECE) of 0.048, indicating well calibrated confidence estimates. Additionally, the VLM first architecture enables zero-shot generalization to auxiliary tasks including vehicle color detection (89%), seatbelt detection (82%), and occupancy counting (78%) without task specific training. Through extensive experimentation on real world toll plaza imagery, we demonstrate that unified vision language approaches represent a paradigm shift in ALPR systems, offering superior accuracy, reduced architectural complexity, and emergent multi-task capabilities that traditional pipeline approaches cannot achieve.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 39,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07058",
        "abs_url": "https://arxiv.org/abs/2602.07058",
        "pdf_url": "https://arxiv.org/pdf/2602.07058",
        "title": "FADE: Selective Forgetting via Sparse LoRA and Self-Distillation",
        "authors": [
            "Carolina R. Kelsch",
            "Leonardo S. B. Pereira",
            "Natnael Mola",
            "Luis H. Arribas",
            "Juan C. S. M. Avedillo"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Machine Unlearning aims to remove the influence of specific data or concepts from trained models while preserving overall performance, a capability increasingly required by data protection regulations and responsible AI practices. Despite recent progress, unlearning in text-to-image diffusion models remains challenging due to high computational costs and the difficulty of balancing effective forgetting with retention of unrelated concepts. We introduce FADE (Fast Adapter for Data Erasure), a two-stage unlearning method for image generation that combines parameter localization with self-distillation. FADE first identifies parameters most responsible for the forget set using gradient-based saliency and constrains updates through sparse LoRA adapters, ensuring lightweight, localized modifications. In a second stage, FADE applies a self-distillation objective that overwrites the forgotten concept with a user-defined surrogate while preserving behavior on retained data. The resulting adapters are memory-efficient, reversible, and can be merged or removed at runtime, enabling flexible deployment in production systems. We evaluated FADE on the UnlearnCanvas benchmark and conducted ablation studies on Imagenette, Labeled Faces in the Wild, AtharvaTaras Dog Breeds Dataset, and SUN Attributes datasets, demonstrating State-of-the-Art unlearning performance with fine-grained control over the forgetting-retention trade-off. Our results demonstrate that FADE achieves strong concept erasure and high retainability across various domains, making it a suitable solution for selective unlearning in diffusion-based image generation models.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 40,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07059",
        "abs_url": "https://arxiv.org/abs/2602.07059",
        "pdf_url": "https://arxiv.org/pdf/2602.07059",
        "title": "Assessing Reproducibility in Evolutionary Computation: A Case Study using Human- and LLM-based Assessment",
        "authors": [
            "Francesca Da Ros",
            "Tarik ZaÄiragiÄ",
            "Aske Plaat",
            "Thomas BÃ¤ck",
            "Niki van Stein"
        ],
        "comments": "",
        "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)",
        "abstract": "Reproducibility is an important requirement in evolutionary computation, where results largely depend on computational experiments. In practice, reproducibility relies on how algorithms, experimental protocols, and artifacts are documented and shared. Despite growing awareness, there is still limited empirical evidence on the actual reproducibility levels of published work in the field. In this paper, we study the reproducibility practices in papers published in the Evolutionary Combinatorial Optimization and Metaheuristics track of the Genetic and Evolutionary Computation Conference over a ten-year period. We introduce a structured reproducibility checklist and apply it through a systematic manual assessment of the selected corpus. In addition, we propose RECAP (REproducibility Checklist Automation Pipeline), an LLM-based system that automatically evaluates reproducibility signals from paper text and associated code repositories. Our analysis shows that papers achieve an average completeness score of 0.62, and that 36.90% of them provide additional material beyond the manuscript itself. We demonstrate that automated assessment is feasible: RECAP achieves substantial agreement with human evaluators (Cohen's k of 0.67). Together, these results highlight persistent gaps in reproducibility reporting and suggest that automated tools can effectively support large-scale, systematic monitoring of reproducibility practices.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 41,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07061",
        "abs_url": "https://arxiv.org/abs/2602.07061",
        "pdf_url": "https://arxiv.org/pdf/2602.07061",
        "title": "TACIT: Transformation-Aware Capturing of Implicit Thought",
        "authors": [
            "Daniel Nobrega"
        ],
        "comments": "25 pages, 7 figures",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "We present TACIT (Transformation-Aware Capturing of Implicit Thought), a diffusion-based transformer for interpretable visual reasoning. Unlike language-based reasoning systems, TACIT operates entirely in pixel space using rectified flow, enabling direct visualization of the reasoning process at each inference step. We demonstrate the approach on maze-solving, where the model learns to transform images of unsolved mazes into solutions. Key results on 1 million synthetic maze pairs include: - 192x reduction in training loss over 100 epochs - 22.7x improvement in L2 distance to ground truth - Only 10 Euler steps required (vs. 100-1000 for typical diffusion models) Quantitative analysis reveals a striking phase transition phenomenon: the solution remains invisible for 68% of the transformation (zero recall), then emerges abruptly at t=0.70 within just 2% of the process. Most remarkably, 100% of samples exhibit simultaneous emergence across all spatial regions, ruling out sequential path construction and providing evidence for holistic rather than algorithmic reasoning. This \"eureka moment\" pattern -- long incubation followed by sudden crystallization -- parallels insight phenomena in human cognition. The pixel-space design with noise-free flow matching provides a foundation for understanding how neural networks develop implicit reasoning strategies that operate below and before language.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 42,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07068",
        "abs_url": "https://arxiv.org/abs/2602.07068",
        "pdf_url": "https://arxiv.org/pdf/2602.07068",
        "title": "MRI Cross-Modal Synthesis: A Comparative Study of Generative Models for T1-to-T2 Reconstruction",
        "authors": [
            "Ali Alqutayfi",
            "Sadam Al-Azani"
        ],
        "comments": "",
        "subjects": "Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "MRI cross-modal synthesis involves generating images from one acquisition protocol using another, offering considerable clinical value by reducing scan time while maintaining diagnostic information. This paper presents a comprehensive comparison of three state-of-the-art generative models for T1-to-T2 MRI reconstruction: Pix2Pix GAN, CycleGAN, and Variational Autoencoder (VAE). Using the BraTS 2020 dataset (11,439 training and 2,000 testing slices), we evaluate these models based on established metrics including Mean Squared Error (MSE), Peak Signal-to-Noise Ratio (PSNR), and Structural Similarity Index (SSIM). Our experiments demonstrate that all models can successfully synthesize T2 images from T1 inputs, with CycleGAN achieving the highest PSNR (32.28 dB) and SSIM (0.9008), while Pix2Pix GAN provides the lowest MSE (0.005846). The VAE, though showing lower quantitative performance (MSE: 0.006949, PSNR: 24.95 dB, SSIM: 0.6573), offers advantages in latent space representation and sampling capabilities. This comparative study provides valuable insights for researchers and clinicians selecting appropriate generative models for MRI synthesis applications based on their specific requirements and data constraints.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 43,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07071",
        "abs_url": "https://arxiv.org/abs/2602.07071",
        "pdf_url": "https://arxiv.org/pdf/2602.07071",
        "title": "Artificial Intelligence in Open Source Software Engineering: A Foundation for Sustainability",
        "authors": [
            "S M Rakib UI Karim",
            "Wenyi Lu",
            "Sean Goggins"
        ],
        "comments": "",
        "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
        "abstract": "Open-source software (OSS) is foundational to modern digital infrastructure, yet this context for group work continues to struggle to ensure sufficient contributions in many critical cases. This literature review explores how artificial intelligence (AI) is being leveraged to address critical challenges to OSS sustainability, including maintaining contributor engagement, securing funding, ensuring code quality and security, fostering healthy community dynamics, and preventing project abandonment. Synthesizing recent interdisciplinary research, the paper identifies key applications of AI in this domain, including automated bug triaging, system maintenance, contributor onboarding and mentorship, community health analytics, vulnerability detection, and task automation. The review also examines the limitations and ethical concerns that arise from applying AI in OSS contexts, including data availability, bias and fairness, transparency, risks of misuse, and the preservation of human-centered values in collaborative development. By framing AI not as a replacement but as a tool to augment human infrastructure, this study highlights both the promise and pitfalls of AI-driven interventions. It concludes by identifying critical research gaps and proposing future directions at the intersection of AI, sustainability, and OSS, aiming to support more resilient and equitable open-source ecosystems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 44,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07073",
        "abs_url": "https://arxiv.org/abs/2602.07073",
        "pdf_url": "https://arxiv.org/pdf/2602.07073",
        "title": "Pro-ZD: A Transferable Graph Neural Network Approach for Proactive Zero-Day Threats Mitigation",
        "authors": [
            "Nardine Basta",
            "Firas Ben Hmida",
            "Houssem Jmal",
            "Muhammad Ikram",
            "Mohamed Ali Kaafar",
            "Andy Walker"
        ],
        "comments": "",
        "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "In today's enterprise network landscape, the combination of perimeter and distributed firewall rules governs connectivity. To address challenges arising from increased traffic and diverse network architectures, organizations employ automated tools for firewall rule and access policy generation. Yet, effectively managing risks arising from dynamically generated policies, especially concerning critical asset exposure, remains a major challenge. This challenge is amplified by evolving network structures due to trends like remote users, bring-your-own devices, and cloud integration. This paper introduces a novel graph neural network model for identifying weighted shortest paths. The model aids in detecting network misconfigurations and high-risk connectivity paths that threaten critical assets, potentially exploited in zero-day attacks -- cyber-attacks exploiting undisclosed vulnerabilities. The proposed Pro-ZD framework adopts a proactive approach, automatically fine-tuning firewall rules and access policies to address high-risk connections and prevent unauthorized access. Experimental results highlight the robustness and transferability of Pro-ZD, achieving over 95% average accuracy in detecting high-risk connections. \\",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 45,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07075",
        "abs_url": "https://arxiv.org/abs/2602.07075",
        "pdf_url": "https://arxiv.org/pdf/2602.07075",
        "title": "LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning",
        "authors": [
            "Xinwu Ye",
            "Yicheng Mao",
            "Jia Zhang",
            "Yimeng Liu",
            "Li Hao",
            "Fang Wu",
            "Zhiwei Li",
            "Yuxuan Liao",
            "Zehong Wang",
            "Zhiyuan Liu",
            "Zhenfei Yin",
            "Li Yuan",
            "Philip Torr",
            "Huan Sun",
            "Xiangxiang Zeng",
            "Mengdi Wang",
            "Le Cong",
            "Shenghua Gao",
            "Xiangru Tang"
        ],
        "comments": "",
        "subjects": "Chemical Physics (physics.chem-ph); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Chemical large language models (LLMs) predominantly rely on explicit Chain-of-Thought (CoT) in natural language to perform complex reasoning. However, chemical reasoning is inherently continuous and structural, and forcing it into discrete linguistic tokens introduces a fundamental representation mismatch that constrains both efficiency and performance. We introduce LatentChem, a latent reasoning interface that decouples chemical computation from textual generation, enabling models to perform multi-step reasoning directly in continuous latent space while emitting language only for final outputs. Remarkably, we observe a consistent emergent behavior: when optimized solely for task success, models spontaneously internalize reasoning, progressively abandoning verbose textual derivations in favor of implicit latent computation. This shift is not merely stylistic but computationally advantageous. Across diverse chemical reasoning benchmarks, LatentChem achieves a 59.88\\% non-tie win rate over strong CoT-based baselines on ChemCoTBench, while delivering a 10.84$\\times$ average inference speedup. Our results provide empirical evidence that chemical reasoning is more naturally and effectively realized as continuous latent dynamics rather than discretized linguistic trajectories.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 46,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07077",
        "abs_url": "https://arxiv.org/abs/2602.07077",
        "pdf_url": "https://arxiv.org/pdf/2602.07077",
        "title": "CALM: Class-Conditional Sparse Attention Vectors for Large Audio-Language Models",
        "authors": [
            "Videet Mehta",
            "Liming Wang",
            "Hilde Kuehne",
            "Rogerio Feris",
            "James R. Glass",
            "M. Jehanzeb Mirza"
        ],
        "comments": "11 pages, 6 figures",
        "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI)",
        "abstract": "Large audio-language models (LALMs) exhibit strong zero-shot capabilities in multiple downstream tasks, such as audio question answering (AQA) and abstract reasoning; however, these models still lag behind specialized models for certain discriminative tasks (e.g., audio classification). Recent studies show that sparse subsets of attention heads within an LALM can serve as strong discriminative feature extractors for downstream tasks such as classification via simple voting schemes. However, these methods assign uniform weights to all selected heads, implicitly assuming that each head contributes equally across all semantic categories. In this work, we propose Class-Conditional Sparse Attention Vectors for Large Audio-Language Models, a few-shot classification method that learns class-dependent importance weights over attention heads. This formulation allows individual heads to specialize in distinct semantic categories and to contribute to ensemble predictions proportionally to their estimated reliability. Experiments on multiple few-shot audio and audiovisual classification benchmarks and tasks demonstrate that our method consistently outperforms state-of-the-art uniform voting-based approaches by up to 14.52%, 1.53%, 8.35% absolute gains for audio classification, audio-visual classification, and spoofing detection respectively.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 47,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07078",
        "abs_url": "https://arxiv.org/abs/2602.07078",
        "pdf_url": "https://arxiv.org/pdf/2602.07078",
        "title": "The Optimal Token Baseline: Variance Reduction for Long-Horizon LLM-RL",
        "authors": [
            "Yingru Li",
            "Jiawei Xu",
            "Ziniu Li",
            "Jiacai Liu",
            "Wei Liu",
            "Yuxuan Tong",
            "Longtao Zheng",
            "Zhenghai Xue",
            "Yaxiang Zhang",
            "Tianle Cai",
            "Ge Zhang",
            "Qian Liu",
            "Baoxiang Wang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Reinforcement Learning (RL) for Large Language Models (LLMs) often suffers from training collapse in long-horizon tasks due to exploding gradient variance. To mitigate this, a baseline is commonly introduced for advantage computation; however, traditional value models remain difficult to optimize, and standard group-based baselines overlook sequence heterogeneity. Although classic optimal baseline theory can achieve global variance reduction, it neglects token heterogeneity and requires prohibitive gradient-based computation. In this work, we derive the Optimal Token Baseline (OTB) from first principles, proving that gradient updates should be weighted inversely to their cumulative gradient norm. To ensure efficiency, we propose the Logit-Gradient Proxy that approximates the gradient norm using only forward-pass probabilities. Our method achieves training stability and matches the performance of large group sizes ($N=32$) with only $N=4$, reducing token consumption by over 65% across single-turn and tool-integrated reasoning tasks.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 48,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07080",
        "abs_url": "https://arxiv.org/abs/2602.07080",
        "pdf_url": "https://arxiv.org/pdf/2602.07080",
        "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs",
        "authors": [
            "Yicheng He",
            "Zheng Zhao",
            "Zhou Kaiyu",
            "Bryan Dai",
            "Jie Fu",
            "Yonghui Yang"
        ],
        "comments": "",
        "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
        "abstract": "Current paradigms for code verification rely heavily on external mechanisms-such as execution-based unit tests or auxiliary LLM judges-which are often labor-intensive or limited by the judging model's own capabilities. This raises a fundamental, yet unexplored question: Can an LLM's functional correctness be assessed purely from its internal computational structure? Our primary objective is to investigate whether the model's neural dynamics encode internally decodable signals that are predictive of logical validity during code generation. Inspired by mechanistic interpretability, we propose to treat code verification as a mechanistic diagnostic task, mapping the model's explicit algorithmic trajectory into line-level attribution graphs. By decomposing complex residual flows, we aim to identify the structural signatures that distinguish sound reasoning from logical failure within the model's internal circuits. Analysis across Python, C++, and Java confirms that intrinsic correctness signals are robust across diverse syntaxes. Topological features from these internal graphs predict correctness more reliably than surface heuristics and enable targeted causal interventions to fix erroneous logic. These findings establish internal introspection as a decodable property for verifying generated code. Our code is at https:// this http URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 49,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07082",
        "abs_url": "https://arxiv.org/abs/2602.07082",
        "pdf_url": "https://arxiv.org/pdf/2602.07082",
        "title": "MosaicThinker: On-Device Visual Spatial Reasoning for Embodied AI via Iterative Construction of Space Representation",
        "authors": [
            "Haoming Wang",
            "Qiyao Xue",
            "Weichen Liu",
            "Wei Gao"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
        "abstract": "When embodied AI is expanding from traditional object detection and recognition to more advanced tasks of robot manipulation and actuation planning, visual spatial reasoning from the video inputs is necessary to perceive the spatial relationships of objects and guide device actions. However, existing visual language models (VLMs) have very weak capabilities in spatial reasoning due to the lack of knowledge about 3D spatial information, especially when the reasoning task involve complex spatial relations across multiple video frames. In this paper, we present a new inference-time computing technique for on-device embodied AI, namely \\emph{MosaicThinker}, which enhances the on-device small VLM's spatial reasoning capabilities on difficult cross-frame reasoning tasks. Our basic idea is to integrate fragmented spatial information from multiple frames into a unified space representation of global semantic map, and further guide the VLM's spatial reasoning over the semantic map via a visual prompt. Experiment results show that our technique can greatly enhance the accuracy of cross-frame spatial reasoning on resource-constrained embodied AI devices, over reasoning tasks with diverse types and complexities.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 50,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07083",
        "abs_url": "https://arxiv.org/abs/2602.07083",
        "pdf_url": "https://arxiv.org/pdf/2602.07083",
        "title": "Rethinking Scientific Modeling: Toward Physically Consistent and Simulation-Executable Programmatic Generation",
        "authors": [
            "Yongqing Jiang",
            "Jianze Wang",
            "Zhiqi Shen",
            "Zhenghong Lin",
            "Jiayuan Wang",
            "Yijian Yang",
            "Kaoshan Dai",
            "Haoran Luo"
        ],
        "comments": "",
        "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
        "abstract": "Structural modeling is a fundamental component of computational engineering science, in which even minor physical inconsistencies or specification violations may invalidate downstream simulations. The potential of large language models (LLMs) for automatic generation of modeling code has been demonstrated. However, non-executable or physically inconsistent outputs remain prevalent under stringent engineering constraints. A framework for physics-consistent automatic building modeling is therefore proposed, integrating domain knowledge construction, constraint-oriented model alignment, and verification-driven evaluation. CivilInstruct is introduced as a domain-specific dataset that formalizes structural engineering knowledge and constraint reasoning to enable simulation-ready model generation. A two-stage fine-tuning strategy is further employed to enforce constraint satisfaction and application programming interface compliance, substantially reducing hallucinated and non-conforming outputs. MBEval is presented as a verification-driven benchmark that evaluates executability and structural dynamics consistency through closed-loop validation. Experimental results show consistent improvements over baselines across rigorous verification metrics. Our code is available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 51,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07084",
        "abs_url": "https://arxiv.org/abs/2602.07084",
        "pdf_url": "https://arxiv.org/pdf/2602.07084",
        "title": "AbFlow : End-to-end Paratope-Centric Antibody Design by Interaction Enhanced Flow Matching",
        "authors": [
            "Wenda Wang",
            "Yang Zhang",
            "Zhewei Wei",
            "Wenbing Huang"
        ],
        "comments": "",
        "subjects": "Quantitative Methods (q-bio.QM); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Antigen-antibody binding is a critical process in the immune response. Although recent progress has advanced antibody design, current methods lack a generative framework for end-to-end modeling of full-atom antibody structures and struggle to fully exploit antigen-specific geometric information for optimizing local binding interfaces and global structures. To overcome these limitations, we introduce AbFlow, a flow-matching framework that leverages optimal transport to design full-atom antibodies end-to-end. AbFlow incorporates an extended velocity field network featuring an equivariant Surface Multi-channel Encoder, which uses surface-level antigen interaction data to refine the antibody structure, particularly the CDR-H3 region. Extensive experiments in paratoep-centric antibody design, multi-CDRs and full-atom antibody design, binding affinity optimization, and complex structure prediction show that AbFlow produces superior antigen-antibody complexes, especially at the contact interface, and markedly improves the binding affinity of generated antibodies.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 52,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07085",
        "abs_url": "https://arxiv.org/abs/2602.07085",
        "pdf_url": "https://arxiv.org/pdf/2602.07085",
        "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining",
        "authors": [
            "Jun Han",
            "Shuo Zhang",
            "Wei Li",
            "Zhi Yang",
            "Yifan Dong",
            "Tu Hu",
            "Jialuo Yuan",
            "Xiaomin Yu",
            "Yumo Zhu",
            "Fangqi Lou",
            "Xin Guo",
            "Zhaowei Liu",
            "Tianyi Jiang",
            "Ruichuan An",
            "Jingping Liu",
            "Biao Wu",
            "Rongze Chen",
            "Kunyi Wang",
            "Yifan Wang",
            "Sen Hu",
            "Xinbing Kong",
            "Liwen Zhang",
            "Ronghao Chen",
            "Huacan Wang"
        ],
        "comments": "",
        "subjects": "Statistical Finance (q-fin.ST); Artificial Intelligence (cs.AI); Computational Finance (q-fin.CP)",
        "abstract": "Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-round search and reliable reuse of validated experience. To address these challenges, we propose QuantaAlpha, an evolutionary alpha mining framework that treats each end-to-end mining run as a trajectory and improves factors through trajectory-level mutation and crossover operations. QuantaAlpha localizes suboptimal steps in each trajectory for targeted revision and recombines complementary high-reward segments to reuse effective patterns, enabling structured exploration and refinement across mining iterations. During factor generation, QuantaAlpha enforces semantic consistency across the hypothesis, factor expression, and executable code, while constraining the complexity and redundancy of the generated factor to mitigate crowding. Extensive experiments on the China Securities Index 300 (CSI 300) demonstrate consistent gains over strong baseline models and prior agentic systems. When utilizing GPT-5.2, QuantaAlpha achieves an Information Coefficient (IC) of 0.1501, with an Annualized Rate of Return (ARR) of 27.75% and a Maximum Drawdown (MDD) of 7.98%. Moreover, factors mined on CSI 300 transfer effectively to the China Securities Index 500 (CSI 500) and the Standard & Poor's 500 Index (S&P 500), delivering 160% and 137% cumulative excess return over four years, respectively, which indicates strong robustness of QuantaAlpha under market distribution shifts.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 53,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07086",
        "abs_url": "https://arxiv.org/abs/2602.07086",
        "pdf_url": "https://arxiv.org/pdf/2602.07086",
        "title": "Evaluating Retrieval-Augmented Generation Variants for Natural Language-Based SQL and API Call Generation",
        "authors": [
            "Michael MarketsmÃ¼ller",
            "Simon Martin",
            "Tim Schlippe"
        ],
        "comments": "preprint of conference submission",
        "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
        "abstract": "Enterprise systems increasingly require natural language interfaces that can translate user requests into structured operations such as SQL queries and REST API calls. While large language models (LLMs) show promise for code generation [Chen et al., 2021; Huynh and Lin, 2025], their effectiveness in domain-specific enterprise contexts remains underexplored, particularly when both retrieval and modification tasks must be handled jointly. This paper presents a comprehensive evaluation of three retrieval-augmented generation (RAG) variants [Lewis et al., 2021] -- standard RAG, Self-RAG [Asai et al., 2024], and CoRAG [Wang et al., 2025] -- across SQL query generation, REST API call generation, and a combined task requiring dynamic task classification. Using SAP Transactional Banking as a realistic enterprise use case, we construct a novel test dataset covering both modalities and evaluate 18 experimental configurations under database-only, API-only, and hybrid documentation contexts. Results demonstrate that RAG is essential: Without retrieval, exact match accuracy is 0% across all tasks, whereas retrieval yields substantial gains in execution accuracy (up to 79.30%) and component match accuracy (up to 78.86%). Critically, CoRAG proves most robust in hybrid documentation settings, achieving statistically significant improvements in the combined task (10.29% exact match vs. 7.45% for standard RAG), driven primarily by superior SQL generation performance (15.32% vs. 11.56%). Our findings establish retrieval-policy design as a key determinant of production-grade natural language interfaces, showing that iterative query decomposition outperforms both top-k retrieval and binary relevance filtering under documentation heterogeneity.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 54,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07087",
        "abs_url": "https://arxiv.org/abs/2602.07087",
        "pdf_url": "https://arxiv.org/pdf/2602.07087",
        "title": "Electron-Informed Coarse-Graining Molecular Representation Learning for Real-World Molecular Physics",
        "authors": [
            "Gyoung S. Na",
            "Chanyoung Park"
        ],
        "comments": "KDD 2025 Research Track",
        "subjects": "Chemical Physics (physics.chem-ph); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)",
        "abstract": "Various representation learning methods for molecular structures have been devised to accelerate data-driven chemistry. However, the representation capabilities of existing methods are essentially limited to atom-level information, which is not sufficient to describe real-world molecular physics. Although electron-level information can provide fundamental knowledge about chemical compounds beyond the atom-level information, obtaining the electron-level information in real-world molecules is computationally impractical and sometimes infeasible. We propose a method for learning electron-informed molecular representations without additional computation costs by transferring readily accessible electron-level information about small molecules to large molecules of our interest. The proposed method achieved state-of-the-art prediction accuracy on extensive benchmark datasets containing experimentally observed molecular physics. The source code for HEDMoL is available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 55,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07090",
        "abs_url": "https://arxiv.org/abs/2602.07090",
        "pdf_url": "https://arxiv.org/pdf/2602.07090",
        "title": "Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks",
        "authors": [
            "Yu-Che Tsai",
            "Hsiang Hsiao",
            "Kuan-Yu Chen",
            "Shou-De Lin"
        ],
        "comments": "",
        "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)",
        "abstract": "Text embeddings enable numerous NLP applications but face severe privacy risks from embedding inversion attacks, which can expose sensitive attributes or reconstruct raw text. Existing differential privacy defenses assume uniform sensitivity across embedding dimensions, leading to excessive noise and degraded utility. We propose SPARSE, a user-centric framework for concept-specific privacy protection in text embeddings. SPARSE combines (1) differentiable mask learning to identify privacy-sensitive dimensions for user-defined concepts, and (2) the Mahalanobis mechanism that applies elliptical noise calibrated by dimension sensitivity. Unlike traditional spherical noise injection, SPARSE selectively perturbs privacy-sensitive dimensions while preserving non-sensitive semantics. Evaluated across six datasets with three embedding models and attack scenarios, SPARSE consistently reduces privacy leakage while achieving superior downstream performance compared to state-of-the-art DP methods.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 56,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07092",
        "abs_url": "https://arxiv.org/abs/2602.07092",
        "pdf_url": "https://arxiv.org/pdf/2602.07092",
        "title": "Lemon Agent Technical Report",
        "authors": [
            "Haipeng Jiang",
            "Kailong Ren",
            "Zimo Yin",
            "Zhetao Sun",
            "Xin Gan",
            "Guangyi Lv",
            "Ming He",
            "Peng Wang",
            "Congli Yin",
            "Hong Pan",
            "Changwen Zhang",
            "Shan Tong",
            "Zhengyu Xu",
            "Zeping Chen",
            "Yubin Huangfu",
            "Yanzhi Xu",
            "Xing Su",
            "Qin Feng",
            "Dong An",
            "Jianping Fan"
        ],
        "comments": "",
        "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)",
        "abstract": "Recent advanced LLM-powered agent systems have exhibited their remarkable capabilities in tackling complex, long-horizon tasks. Nevertheless, they still suffer from inherent limitations in resource efficiency, context management, and multimodal perception. Based on these observations, Lemon Agent is introduced, a multi-agent orchestrator-worker system built on a newly proposed AgentCortex framework, which formalizes the classic Planner-Executor-Memory paradigm through an adaptive task execution mechanism. Our system integrates a hierarchical self-adaptive scheduling mechanism that operates at both the overall orchestrator layer and workers layer. This mechanism can dynamically adjust computational intensity based on task complexity. It enables orchestrator to allocate one or more workers for parallel subtask execution, while workers can further improve operational efficiency by invoking tools concurrently. By virtue of this two-tier architecture, the system achieves synergistic balance between global task coordination and local task execution, thereby optimizing resource utilization and task processing efficiency in complex scenarios. To reduce context redundancy and increase information density during parallel steps, we adopt a three-tier progressive context management strategy. To make fuller use of historical information, we propose a self-evolving memory system, which can extract multi-dimensional valid information from all historical experiences to assist in completing similar tasks. Furthermore, we provide an enhanced MCP toolset. Empirical evaluations on authoritative benchmarks demonstrate that our Lemon Agent can achieve a state-of-the-art 91.36% overall accuracy on GAIA and secures the top position on the xbench-DeepSearch leaderboard with a score of 77+.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 57,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07096",
        "abs_url": "https://arxiv.org/abs/2602.07096",
        "pdf_url": "https://arxiv.org/pdf/2602.07096",
        "title": "RealFin: How Well Do LLMs Reason About Finance When Users Leave Things Unsaid?",
        "authors": [
            "Yuyang Dai",
            "Yan Lin",
            "Zhuohan Xie",
            "Yuxia Wang"
        ],
        "comments": "",
        "subjects": "Statistical Finance (q-fin.ST); Artificial Intelligence (cs.AI); Computational Finance (q-fin.CP)",
        "abstract": "Reliable financial reasoning requires knowing not only how to answer, but also when an answer cannot be justified. In real financial practice, problems often rely on implicit assumptions that are taken for granted rather than stated explicitly, causing problems to appear solvable while lacking enough information for a definite answer. We introduce REALFIN, a bilingual benchmark that evaluates financial reasoning by systematically removing essential premises from exam-style questions while keeping them linguistically plausible. Based on this, we evaluate models under three formulations that test answering, recognizing missing information, and rejecting unjustified options, and find consistent performance drops when key conditions are absent. General-purpose models tend to over-commit and guess, while most finance-specialized models fail to clearly identify missing premises. These results highlight a critical gap in current evaluations and show that reliable financial models must know when a question should not be answered.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 58,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07102",
        "abs_url": "https://arxiv.org/abs/2602.07102",
        "pdf_url": "https://arxiv.org/pdf/2602.07102",
        "title": "Fast and Robust Likelihood-Guided Diffusion Posterior Sampling with Amortized Variational Inference",
        "authors": [
            "LÃ©on Zheng",
            "Thomas Hirtz",
            "Yazid Janati",
            "Eric Moulines"
        ],
        "comments": "",
        "subjects": "Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Zero-shot diffusion posterior sampling offers a flexible framework for inverse problems by accommodating arbitrary degradation operators at test time, but incurs high computational cost due to repeated likelihood-guided updates. In contrast, previous amortized diffusion approaches enable fast inference by replacing likelihood-based sampling with implicit inference models, but at the expense of robustness to unseen degradations. We introduce an amortization strategy for diffusion posterior sampling that preserves explicit likelihood guidance by amortizing the inner optimization problems arising in variational diffusion posterior sampling. This accelerates inference for in-distribution degradations while maintaining robustness to previously unseen operators, thereby improving the trade-off between efficiency and flexibility in diffusion-based inverse problems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 59,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07103",
        "abs_url": "https://arxiv.org/abs/2602.07103",
        "pdf_url": "https://arxiv.org/pdf/2602.07103",
        "title": "scDFM: Distributional Flow Matching Model for Robust Single-Cell Perturbation Prediction",
        "authors": [
            "Chenglei Yu",
            "Chuanrui Wang",
            "Bangyan Liao",
            "Tailin Wu"
        ],
        "comments": "ICLR 2026 poster, 25 pages, 8 figures",
        "subjects": "Quantitative Methods (q-bio.QM); Artificial Intelligence (cs.AI)",
        "abstract": "A central goal in systems biology and drug discovery is to predict the transcriptional response of cells to perturbations. This task is challenging due to the noisy and sparse nature of single-cell measurements, as well as the fact that perturbations often induce population-level shifts rather than changes in individual cells. Existing deep learning methods typically assume cell-level correspondences, limiting their ability to capture such global effects. We present scDFM, a generative framework based on conditional flow matching that models the full distribution of perturbed cells conditioned on control states. By incorporating a maximum mean discrepancy (MMD) objective, our method aligns perturbed and control populations beyond cell-level correspondences. To further improve robustness to sparsity and noise, we introduce the Perturbation-Aware Differential Transformer (PAD-Transformer), a backbone architecture that leverages gene interaction graphs and differential attention to capture context-specific expression changes. Across multiple genetic and drug perturbation benchmarks, scDFM consistently outperforms prior methods, demonstrating strong generalization in both unseen and combinatorial settings. In the combinatorial setting, it reduces mean squared error by 19.6% relative to the strongest baseline. These results highlight the importance of distribution-level generative modeling for robust in silico perturbation prediction. The code is available at this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 60,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07106",
        "abs_url": "https://arxiv.org/abs/2602.07106",
        "pdf_url": "https://arxiv.org/pdf/2602.07106",
        "title": "Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models",
        "authors": [
            "Haoyu Zhang",
            "Zhipeng Li",
            "Yiwen Guo",
            "Tianshu Yu"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
        "abstract": "Omni-modal large language models (OLLMs) aim to unify multimodal understanding and generation, yet incorporating speech with 3D facial animation remains largely unexplored despite its importance for natural interaction. A key challenge arises from the representation mismatch between discrete, token-level semantic reasoning in LLMs and the dense, fine-grained temporal dynamics required for 3D facial motion, which makes direct modeling difficult to optimize under limited data. We propose Expressive Omni (Ex-Omni), an open-source omni-modal framework that augments OLLMs with speech-accompanied 3D facial animation. Ex-Omni reduces learning difficulty by decoupling semantic reasoning from temporal generation, leveraging speech units as temporal scaffolding and a unified token-as-query gated fusion (TQGF) mechanism for controlled semantic injection. We further introduce InstructEx, a dataset aims to facilitate augment OLLMs with speech-accompanied 3D facial animation. Extensive experiments demonstrate that Ex-Omni performs competitively against existing open-source OLLMs while enabling stable aligned speech and facial animation generation.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 61,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07107",
        "abs_url": "https://arxiv.org/abs/2602.07107",
        "pdf_url": "https://arxiv.org/pdf/2602.07107",
        "title": "ShallowJail: Steering Jailbreaks against Large Language Models",
        "authors": [
            "Shang Liu",
            "Hanyu Pei",
            "Zeyan Liu"
        ],
        "comments": "",
        "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models(LLMs) have been successful in numerous fields. Alignment has usually been applied to prevent them from harmful purposes. However, aligned LLMs remain vulnerable to jailbreak attacks that deliberately mislead them into producing harmful outputs. Existing jailbreaks are either black-box, using carefully crafted, unstealthy prompts, or white-box, requiring resource-intensive computation. In light of these challenges, we introduce ShallowJail, a novel attack that exploits shallow alignment in LLMs. ShallowJail can misguide LLMs' responses by manipulating the initial tokens during inference. Through extensive experiments, we demonstrate the effectiveness of~\\shallow, which substantially degrades the safety of state-of-the-art LLM responses.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 62,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07135",
        "abs_url": "https://arxiv.org/abs/2602.07135",
        "pdf_url": "https://arxiv.org/pdf/2602.07135",
        "title": "Landscaper: Understanding Loss Landscapes Through Multi-Dimensional Topological Analysis",
        "authors": [
            "Jiaqing Chen",
            "Nicholas Hadler",
            "Tiankai Xie",
            "Rostyslav Hnatyshyn",
            "Caleb Geniesse",
            "Yaoqing Yang",
            "Michael W. Mahoney",
            "Talita Perciano",
            "John F. Hartwig",
            "Ross Maciejewski",
            "Gunther H. Weber"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Loss landscapes are a powerful tool for understanding neural network optimization and generalization, yet traditional low-dimensional analyses often miss complex topological features. We present Landscaper, an open-source Python package for arbitrary-dimensional loss landscape analysis. Landscaper combines Hessian-based subspace construction with topological data analysis to reveal geometric structures such as basin hierarchy and connectivity. A key component is the Saddle-Minimum Average Distance (SMAD) for quantifying landscape smoothness. We demonstrate Landscaper's effectiveness across various architectures and tasks, including those involving pre-trained language models, showing that SMAD captures training transitions, such as landscape simplification, that conventional metrics miss. We also illustrate Landscaper's performance in challenging chemical property prediction tasks, where SMAD can serve as a metric for out-of-distribution generalization, offering valuable insights for model diagnostics and architecture design in data-scarce scientific machine learning scenarios.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 63,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07142",
        "abs_url": "https://arxiv.org/abs/2602.07142",
        "pdf_url": "https://arxiv.org/pdf/2602.07142",
        "title": "Exploring Teachers' Perspectives on Using Conversational AI Agents for Group Collaboration",
        "authors": [
            "Prerna Ravi",
            "CarÃºmey Stevens",
            "Beatriz Flamia Azevedo",
            "Jasmine David",
            "Brandon Hanks",
            "Hal Abelson",
            "Grace Lin",
            "Emma Anderson"
        ],
        "comments": "",
        "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)",
        "abstract": "Collaboration is a cornerstone of 21st-century learning, yet teachers continue to face challenges in supporting productive peer interaction. Emerging generative AI tools offer new possibilities for scaffolding collaboration, but their role in mediating in-person group work remains underexplored, especially from the perspective of educators. This paper presents findings from an exploratory qualitative study with 33 K12 teachers who interacted with Phoenix, a voice-based conversational agent designed to function as a near-peer in face-to-face group collaboration. Drawing on playtesting sessions, surveys, and focus groups, we examine how teachers perceived the agent's behavior, its influence on group dynamics, and its classroom potential. While many appreciated Phoenix's capacity to stimulate engagement, they also expressed concerns around autonomy, trust, anthropomorphism, and pedagogical alignment. We contribute empirical insights into teachers' mental models of AI, reveal core design tensions, and outline considerations for group-facing AI agents that support meaningful, collaborative learning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 64,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07144",
        "abs_url": "https://arxiv.org/abs/2602.07144",
        "pdf_url": "https://arxiv.org/pdf/2602.07144",
        "title": "BONSAI: Bayesian Optimization with Natural Simplicity and Interpretability",
        "authors": [
            "Samuel Daulton",
            "David Eriksson",
            "Maximilian Balandat",
            "Eytan Bakshy"
        ],
        "comments": "26 pages",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
        "abstract": "Bayesian optimization (BO) is a popular technique for sample-efficient optimization of black-box functions. In many applications, the parameters being tuned come with a carefully engineered default configuration, and practitioners only want to deviate from this default when necessary. Standard BO, however, does not aim to minimize deviation from the default and, in practice, often pushes weakly relevant parameters to the boundary of the search space. This makes it difficult to distinguish between important and spurious changes and increases the burden of vetting recommendations when the optimization objective omits relevant operational considerations. We introduce BONSAI, a default-aware BO policy that prunes low-impact deviations from a default configuration while explicitly controlling the loss in acquisition value. BONSAI is compatible with a variety of acquisition functions, including expected improvement and upper confidence bound (GP-UCB). We theoretically bound the regret incurred by BONSAI, showing that, under certain conditions, it enjoys the same no-regret property as vanilla GP-UCB. Across many real-world applications, we empirically find that BONSAI substantially reduces the number of non-default parameters in recommended configurations while maintaining competitive optimization performance, with little effect on wall time.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 65,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07150",
        "abs_url": "https://arxiv.org/abs/2602.07150",
        "pdf_url": "https://arxiv.org/pdf/2602.07150",
        "title": "On Randomness in Agentic Evals",
        "authors": [
            "Bjarni Haukur Bjarnason",
            "AndrÃ© Silva",
            "Martin Monperrus"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)",
        "abstract": "Agentic systems are evaluated on benchmarks where agents interact with environments to solve tasks. Most papers report a pass@1 score computed from a single run per task, assuming this gives a reliable performance estimate. We test this assumption by collecting 60,000 agentic trajectories on SWE-Bench-Verified, spanning three models and two scaffolds. We find substantial variance: single-run pass@1 estimates vary by 2.2 to 6.0 percentage points depending on which run is selected, with standard deviations exceeding 1.5 percentage points even at temperature 0. This variance has critical implications: reported improvements of 2--3 percentage points may reflect evaluation noise rather than genuine algorithmic progress. Through token-level analysis, we show that trajectories diverge early, often within the first few percent of tokens, and that these small differences cascade into different solution strategies. To enable reliable evaluation of agentic systems, we recommend three concrete practices: (1) estimate pass@1 from multiple independent runs per task, especially when measuring small improvements, (2) use statistical power analysis to determine the number of runs needed to detect expected effect sizes, and (3) consider metrics like pass@k (optimistic bound) and pass^k (pessimistic bound) with k>1 to better characterize the full performance envelope. While these practices increase evaluation cost, they are essential for distinguishing genuine scientific progress from statistical noise.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 66,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07154",
        "abs_url": "https://arxiv.org/abs/2602.07154",
        "pdf_url": "https://arxiv.org/pdf/2602.07154",
        "title": "Beyond Pooling: Matching for Robust Generalization under Data Heterogeneity",
        "authors": [
            "Ayush Roy",
            "Rudrasis Chakraborty",
            "Lav Varshney",
            "Vishnu Suresh Lokhande"
        ],
        "comments": "AISTATS 2026",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Pooling heterogeneous datasets across domains is a common strategy in representation learning, but naive pooling can amplify distributional asymmetries and yield biased estimators, especially in settings where zero-shot generalization is required. We propose a matching framework that selects samples relative to an adaptive centroid and iteratively refines the representation distribution. The double robustness and the propensity score matching for the inclusion of data domains make matching more robust than naive pooling and uniform subsampling by filtering out the confounding domains (the main cause of heterogeneity). Theoretical and empirical analyses show that, unlike naive pooling or uniform subsampling, matching achieves better results under asymmetric meta-distributions, which are also extended to non-Gaussian and multimodal real-world settings. Most importantly, we show that these improvements translate to zero-shot medical anomaly detection, one of the extreme forms of data heterogeneity and asymmetry. The code is available on this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 67,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07160",
        "abs_url": "https://arxiv.org/abs/2602.07160",
        "pdf_url": "https://arxiv.org/pdf/2602.07160",
        "title": "Free Energy Mixer",
        "authors": [
            "Jiecheng Lu",
            "Shihao Yang"
        ],
        "comments": "Camera-ready version. Accepted at ICLR 2026",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)",
        "abstract": "Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linear tilt to a fast prior (e.g., from queries/keys in standard attention) over indices. Unlike methods that attempt to improve and enrich the $(q,k)$ scoring distribution, FEM treats it as a prior and yields a value-aware posterior read at unchanged complexity, smoothly moving from averaging to per-channel selection as the learnable inverse temperature increases, while still preserving parallelism and the original asymptotic complexity ($O(T^2)$ for softmax; $O(T)$ for linearizable variants). We instantiate a two-level gated FEM that is plug-and-play with standard and linear attention, linear RNNs and SSMs. It consistently outperforms strong baselines on NLP, vision, and time-series at matched parameter budgets.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 68,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07164",
        "abs_url": "https://arxiv.org/abs/2602.07164",
        "pdf_url": "https://arxiv.org/pdf/2602.07164",
        "title": "Your Language Model Secretly Contains Personality Subnetworks",
        "authors": [
            "Ruimeng Ye",
            "Zihan Wang",
            "Zinan Ling",
            "Yang Xiao",
            "Manling Li",
            "Xiaolong Ma",
            "Bo Hui"
        ],
        "comments": "ICLR 2026",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapt to different behaviors, or do they already have such knowledge embedded in their parameters? In this work, we show that LLMs already contain persona-specialized subnetworks in their parameter space. Using small calibration datasets, we identify distinct activation signatures associated with different personas. Guided by these statistics, we develop a masking strategy that isolates lightweight persona subnetworks. Building on the findings, we further discuss: how can we discover opposing subnetwork from the model that lead to binary-opposing personas, such as introvert-extrovert? To further enhance separation in binary opposition scenarios, we introduce a contrastive pruning strategy that identifies parameters responsible for the statistical divergence between opposing personas. Our method is entirely training-free and relies solely on the language model's existing parameter space. Across diverse evaluation settings, the resulting subnetworks exhibit significantly stronger persona alignment than baselines that require external knowledge while being more efficient. Our findings suggest that diverse human-like behaviors are not merely induced in LLMs, but are already embedded in their parameter space, pointing toward a new perspective on controllable and interpretable personalization in large language models.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 69,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07176",
        "abs_url": "https://arxiv.org/abs/2602.07176",
        "pdf_url": "https://arxiv.org/pdf/2602.07176",
        "title": "Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI",
        "authors": [
            "Mohamed El Hajji",
            "Tarek Ait Baha",
            "Aicha Dakir",
            "Hammou Fadili",
            "Youssef Es-Saady"
        ],
        "comments": "19 pages, 15 figures",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Human-Computer Interaction (cs.HC)",
        "abstract": "Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technologies to support personalized, meaningful learning experiences. This paper presents Open TutorAI, an open-source educational platform based on LLMs and generative technologies that provides dynamic, personalized tutoring. The system integrates natural language processing with customizable 3D avatars to enable multimodal learner interaction. Through a structured onboarding process, it captures each learner's goals and preferences in order to configure a learner-specific AI assistant. This assistant is accessible via both text-based and avatar-driven interfaces. The platform includes tools for organizing content, providing embedded feedback, and offering dedicated interfaces for learners, educators, and parents. This work focuses on learner-facing components, delivering a tool for adaptive support that responds to individual learner profiles without requiring technical expertise. Its assistant-generation pipeline and avatar integration enhance engagement and emotional presence, creating a more humanized, immersive learning environment. Embedded learning analytics support self-regulated learning by tracking engagement patterns and generating actionable feedback. The result is Open TutorAI, which unites modular architecture, generative AI, and learner analytics within an open-source framework. It contributes to the development of next-generation intelligent tutoring systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 70,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07179",
        "abs_url": "https://arxiv.org/abs/2602.07179",
        "pdf_url": "https://arxiv.org/pdf/2602.07179",
        "title": "An Information-Theoretic Framework for Comparing Voice and Text Explainability",
        "authors": [
            "Mona Rajhans",
            "Vishal Khawarey"
        ],
        "comments": "Accepted for publication at the 10th ACM International Conference on Intelligent Systems, Metaheuristics & Swarm Intelligence (ISMSI 2026), April 24-26, Cebu City, Phillipines",
        "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Information Theory (cs.IT)",
        "abstract": "Explainable Artificial Intelligence (XAI) aims to make machine learning models transparent and trustworthy, yet most current approaches communicate explanations visually or through text. This paper introduces an information theoretic framework for analyzing how explanation modality specifically, voice versus text affects user comprehension and trust calibration in AI systems. The proposed model treats explanation delivery as a communication channel between model and user, characterized by metrics for information retention, comprehension efficiency (CE), and trust calibration error (T CE). A simulation framework implemented in Python was developed to evaluate these metrics using synthetic SHAP based feature attributions across multiple modality style configurations (brief, detailed, and analogy based). Results demonstrate that text explanations achieve higher comprehension efficiency, while voice explanations yield improved trust calibration, with analogy based delivery achieving the best overall trade off. This framework provides a reproducible foundation for designing and benchmarking multimodal explainability systems and can be extended to empirical studies using real SHAP or LIME outputs on open datasets such as the UCI Credit Approval or Kaggle Financial Transactions datasets.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 71,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07190",
        "abs_url": "https://arxiv.org/abs/2602.07190",
        "pdf_url": "https://arxiv.org/pdf/2602.07190",
        "title": "Long-Context Long-Form Question Answering for Legal Domain",
        "authors": [
            "Anagha Kulkarni",
            "Parin Rajesh Jhaveri",
            "Prasha Shrestha",
            "Yu Tong Han",
            "Reza Amini",
            "Behrouz Madahian"
        ],
        "comments": "EACL 2026",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be comprehensive (i.e. a long-form answer). In this paper, we address the challenges of long-context question answering in context of long-form answers given the idiosyncrasies of legal documents. We propose a question answering system that can (a) deconstruct domain-specific vocabulary for better retrieval from source documents, (b) parse complex document layouts while isolating sections and footnotes and linking them appropriately, (c) generate comprehensive answers using precise domain-specific vocabulary. We also introduce a coverage metric that classifies the performance into recall-based coverage categories allowing human users to evaluate the recall with ease. We curate a QA dataset by leveraging the expertise of professionals from fields such as law and corporate tax. Through comprehensive experiments and ablation studies, we demonstrate the usability and merit of the proposed system.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 72,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07193",
        "abs_url": "https://arxiv.org/abs/2602.07193",
        "pdf_url": "https://arxiv.org/pdf/2602.07193",
        "title": "\"Death\" of a Chatbot: Investigating and Designing Toward Psychologically Safe Endings for Human-AI Relationships",
        "authors": [
            "Rachel Poonsiriwong",
            "Chayapatr Archiwaranguprok",
            "Pat Pataranutaporn"
        ],
        "comments": "",
        "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)",
        "abstract": "Millions of users form emotional attachments to AI companions like this http URL, Replika, and ChatGPT. When these relationships end through model updates, safety interventions, or platform shutdowns, users receive no closure, reporting grief comparable to human loss. As regulations mandate protections for vulnerable users, discontinuation events will accelerate, yet no platform has implemented deliberate end-of-\"life\" design. Through grounded theory analysis of AI companion communities, we find that discontinuation is a sense-making process shaped by how users attribute agency, perceive finality, and anthropomorphize their companions. Strong anthropomorphization co-occurs with intense grief; users who perceive change as reversible become trapped in fixing cycles; while user-initiated endings demonstrate greater closure. Synthesizing grief psychology with Self-Determination Theory, we develop four design principles and artifacts demonstrating how platforms might provide closure and orient users toward human connection. We contribute the first framework for designing psychologically safe AI companion discontinuation.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 73,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07200",
        "abs_url": "https://arxiv.org/abs/2602.07200",
        "pdf_url": "https://arxiv.org/pdf/2602.07200",
        "title": "BadSNN: Backdoor Attacks on Spiking Neural Networks via Adversarial Spiking Neuron",
        "authors": [
            "Abdullah Arafat Miah",
            "Kevin Vu",
            "Yu Bi"
        ],
        "comments": "",
        "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)",
        "abstract": "Spiking Neural Networks (SNNs) are energy-efficient counterparts of Deep Neural Networks (DNNs) with high biological plausibility, as information is transmitted through temporal spiking patterns. The core element of an SNN is the spiking neuron, which converts input data into spikes following the Leaky Integrate-and-Fire (LIF) neuron model. This model includes several important hyperparameters, such as the membrane potential threshold and membrane time constant. Both the DNNs and SNNs have proven to be exploitable by backdoor attacks, where an adversary can poison the training dataset with malicious triggers and force the model to behave in an attacker-defined manner. Yet, how an adversary can exploit the unique characteristics of SNNs for backdoor attacks remains underexplored. In this paper, we propose \\textit{BadSNN}, a novel backdoor attack on spiking neural networks that exploits hyperparameter variations of spiking neurons to inject backdoor behavior into the model. We further propose a trigger optimization process to achieve better attack performance while making trigger patterns less perceptible. \\textit{BadSNN} demonstrates superior attack performance on various datasets and architectures, as well as compared with state-of-the-art data poisoning-based backdoor attacks and robustness against common backdoor mitigation techniques. Codes can be found at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 74,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07203",
        "abs_url": "https://arxiv.org/abs/2602.07203",
        "pdf_url": "https://arxiv.org/pdf/2602.07203",
        "title": "Exactly Computing do-Shapley Values",
        "authors": [
            "R. Teal Witter",
            "Ãlvaro Parafita",
            "Tomas Garriga",
            "Maximilian Muschalik",
            "Fabian Fumagalli",
            "Axel Brando",
            "Lucas Rosenblatt"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Structural Causal Models (SCM) are a powerful framework for describing complicated dynamics across the natural sciences. A particularly elegant way of interpreting SCMs is do-Shapley, a game-theoretic method of quantifying the average effect of $d$ variables across exponentially many interventions. Like Shapley values, computing do-Shapley values generally requires evaluating exponentially many terms. The foundation of our work is a reformulation of do-Shapley values in terms of the irreducible sets of the underlying SCM. Leveraging this insight, we can exactly compute do-Shapley values in time linear in the number of irreducible sets $r$, which itself can range from $d$ to $2^d$ depending on the graph structure of the SCM. Since $r$ is unknown a priori, we complement the exact algorithm with an estimator that, like general Shapley value estimators, can be run with any query budget. As the query budget approaches $r$, our estimators can produce more accurate estimates than prior methods by several orders of magnitude, and, when the budget reaches $r$, return the Shapley values up to machine precision. Beyond computational speed, we also reduce the identification burden: we prove that non-parametric identifiability of do-Shapley values requires only the identification of interventional effects for the $d$ singleton coalitions, rather than all classes.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 75,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07206",
        "abs_url": "https://arxiv.org/abs/2602.07206",
        "pdf_url": "https://arxiv.org/pdf/2602.07206",
        "title": "DSL: Understanding and Improving Softmax Recommender Systems with Competition-Aware Scaling",
        "authors": [
            "Bucher Sahyouni",
            "Matthew Vowels",
            "Liqun Chen",
            "Simon Hadfield"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Softmax Loss (SL) is being increasingly adopted for recommender systems (RS) as it has demonstrated better performance, robustness and fairness. Yet in implicit-feedback, a single global temperature and equal treatment of uniformly sampled negatives can lead to brittle training, because sampled sets may contain varying degrees of relevant or informative competitors. The optimal loss sharpness for a user-item pair with a particular set of negatives, can be suboptimal or destabilising for another with different negatives. We introduce Dual-scale Softmax Loss (DSL), which infers effective sharpness from the sampled competition itself. DSL adds two complementary branches to the log-sum-exp backbone. Firstly it reweights negatives within each training instance using hardness and item--item similarity, secondly it adapts a per-example temperature from the competition intensity over a constructed competitor slate. Together, these components preserve the geometry of SL while reshaping the competition distribution across negatives and across examples. Over several representative benchmarks and backbones, DSL yields substantial gains over strong baselines, with improvements over SL exceeding $10%$ in several settings and averaging $6.22%$ across datasets, metrics, and backbones. Under out-of-distribution (OOD) popularity shift, the gains are larger, with an average of $9.31%$ improvement over SL. We further provide a theoretical, distributionally robust optimisation (DRO) analysis, which demonstrates how DSL reshapes the robust payoff and the KL deviation for ambiguous instances. This helps explain the empirically observed improvements in accuracy and robustness.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 76,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07207",
        "abs_url": "https://arxiv.org/abs/2602.07207",
        "pdf_url": "https://arxiv.org/pdf/2602.07207",
        "title": "Multimodal Enhancement of Sequential Recommendation",
        "authors": [
            "Bucher Sahyouni",
            "Matthew Vowels",
            "Liqun Chen",
            "Simon Hadfield"
        ],
        "comments": "",
        "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)",
        "abstract": "We propose a novel recommender framework, MuSTRec (Multimodal and Sequential Transformer-based Recommendation), that unifies multimodal and sequential recommendation paradigms. MuSTRec captures cross-item similarities and collaborative filtering signals, by building item-item graphs from extracted text and visual features. A frequency-based self-attention module additionally captures the short- and long-term user preferences. Across multiple Amazon datasets, MuSTRec demonstrates superior performance (up to 33.5% improvement) over multimodal and sequential state-of-the-art baselines. Finally, we detail some interesting facets of this new recommendation paradigm. These include the need for a new data partitioning regime, and a demonstration of how integrating user embeddings into sequential recommendation leads to drastically increased short-term metrics (up to 200% improvement) on smaller datasets. Our code is availabe at this https URL and will be made publicly available.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 77,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07208",
        "abs_url": "https://arxiv.org/abs/2602.07208",
        "pdf_url": "https://arxiv.org/pdf/2602.07208",
        "title": "Sequences as Nodes for Contrastive Multimodal Graph Recommendation",
        "authors": [
            "Bucher Sahyouni",
            "Matthew Vowels",
            "Liqun Chen",
            "Simon Hadfield"
        ],
        "comments": "",
        "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)",
        "abstract": "To tackle cold-start and data sparsity issues in recommender systems, numerous multimodal, sequential, and contrastive techniques have been proposed. While these augmentations can boost recommendation performance, they tend to add noise and disrupt useful semantics. To address this, we propose MuSICRec (Multimodal Sequence-Item Contrastive Recommender), a multi-view graph-based recommender that combines collaborative, sequential, and multimodal signals. We build a sequence-item (SI) view by attention pooling over the user's interacted items to form sequence nodes. We propagate over the SI graph, obtaining a second view organically as an alternative to artificial data augmentation, while simultaneously injecting sequential context signals. Additionally, to mitigate modality noise and align the multimodal information, the contribution of text and visual features is modulated according to an ID-guided gate. We evaluate under a strict leave-two-out split against a broad range of sequential, multimodal, and contrastive baselines. On the Amazon Baby, Sports, and Electronics datasets, MuSICRec outperforms state-of-the-art baselines across all model types. We observe the largest gains for short-history users, mitigating sparsity and cold-start challenges. Our code is available at this https URL and will be made publicly available.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 78,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07215",
        "abs_url": "https://arxiv.org/abs/2602.07215",
        "pdf_url": "https://arxiv.org/pdf/2602.07215",
        "title": "Multi-Agentic AI for Fairness-Aware and Accelerated Multi-modal Large Model Inference in Real-world Mobile Edge Networks",
        "authors": [
            "Haiyuan Li",
            "Hari Madhukumar",
            "Shuangyi Yan",
            "Yulei Wu",
            "Dimitra Simeonidou"
        ],
        "comments": "",
        "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Generative AI (GenAI) has transformed applications in natural language processing and content creation, yet centralized inference remains hindered by high latency, limited customizability, and privacy concerns. Deploying large models (LMs) in mobile edge networks emerges as a promising solution. However, it also poses new challenges, including heterogeneous multi-modal LMs with diverse resource demands and inference speeds, varied prompt/output modalities that complicate orchestration, and resource-limited infrastructure ill-suited for concurrent LM execution. In response, we propose a Multi-Agentic AI framework for latency- and fairness-aware multi-modal LM inference in mobile edge networks. Our solution includes a long-term planning agent, a short-term prompt scheduling agent, and multiple on-node LM deployment agents, all powered by foundation language models. These agents cooperatively optimize prompt routing and LM deployment through natural language reasoning over runtime telemetry and historical experience. To evaluate its performance, we further develop a city-wide testbed that supports network monitoring, containerized LM deployment, intra-server resource management, and inter-server communications. Experiments demonstrate that our solution reduces average latency by over 80% and improves fairness (Normalized Jain index) to 0.90 compared to other baselines. Moreover, our solution adapts quickly without fine-tuning, offering a generalizable solution for optimizing GenAI services in edge environments.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 79,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07218",
        "abs_url": "https://arxiv.org/abs/2602.07218",
        "pdf_url": "https://arxiv.org/pdf/2602.07218",
        "title": "Collaborative and Efficient Fine-tuning: Leveraging Task Similarity",
        "authors": [
            "Gagik Magakyan",
            "Amirhossein Reisizadeh",
            "Chanwoo Park",
            "Pablo A. Parrilo",
            "Asuman Ozdaglar"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
        "abstract": "Adaptability has been regarded as a central feature in the foundation models, enabling them to effectively acclimate to unseen downstream tasks. Parameter-efficient fine-tuning methods such as celebrated LoRA facilitate efficient adaptation of large foundation models using labeled, high-quality and generally scarce task data. To mitigate data scarcity in fine-tuning of foundation models, we propose to leverage task similarity across multiple downstream users. Intuitively, users with similar tasks must be able to assist each other in boosting the effective fine-tuning data size. We propose Collaborative Low-Rank Adaptation, or CoLoRA, which exploits task similarity to collaboratively and efficiently fine-tune personalized foundation models. The main idea in CoLoRA is to train one shared adapter capturing underlying task similarities across all tasks, and personalized adapters tailored to user-specific tasks. We theoretically study CoLoRA on heterogeneous linear regression and provide provable guarantees for ground truth recovery. We also conduct several natural language experiments with varying task similarity, which further demonstrate that when trained together with similar tasks, individual performances are significantly boosted.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 80,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07219",
        "abs_url": "https://arxiv.org/abs/2602.07219",
        "pdf_url": "https://arxiv.org/pdf/2602.07219",
        "title": "The Median is Easier than it Looks: Approximation with a Constant-Depth, Linear-Width ReLU Network",
        "authors": [
            "Abhigyan Dutta",
            "Itay Safran",
            "Paul Valiant"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "We study the approximation of the median of $d$ inputs using ReLU neural networks. We present depth-width tradeoffs under several settings, culminating in a constant-depth, linear-width construction that achieves exponentially small approximation error with respect to the uniform distribution over the unit hypercube. By further establishing a general reduction from the maximum to the median, our results break a barrier suggested by prior work on the maximum function, which indicated that linear width should require depth growing at least as $\\log\\log d$ to achieve comparable accuracy. Our construction relies on a multi-stage procedure that iteratively eliminates non-central elements while preserving a candidate set around the median. We overcome obstacles that do not arise for the maximum to yield approximation results that are strictly stronger than those previously known for the maximum itself.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 81,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07235",
        "abs_url": "https://arxiv.org/abs/2602.07235",
        "pdf_url": "https://arxiv.org/pdf/2602.07235",
        "title": "ArcMark: Multi-bit LLM Watermark via Optimal Transport",
        "authors": [
            "Atefeh Gilani",
            "Carol Xuan Long",
            "Sajani Vithana",
            "Oliver Kosut",
            "Lalitha Sankar",
            "Flavio P. Calmon"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Theory (cs.IT)",
        "abstract": "Watermarking is an important tool for promoting the responsible use of language models (LMs). Existing watermarks insert a signal into generated tokens that either flags LM-generated text (zero-bit watermarking) or encodes more complex messages (multi-bit watermarking). Though a number of recent multi-bit watermarks insert several bits into text without perturbing average next-token predictions, they largely extend design principles from the zero-bit setting, such as encoding a single bit per token. Notably, the information-theoretic capacity of multi-bit watermarking -- the maximum number of bits per token that can be inserted and detected without changing average next-token predictions -- has remained unknown. We address this gap by deriving the first capacity characterization of multi-bit watermarks. Our results inform the design of ArcMark: a new watermark construction based on coding-theoretic principles that, under certain assumptions, achieves the capacity of the multi-bit watermark channel. In practice, ArcMark outperforms competing multi-bit watermarks in terms of bit rate per token and detection accuracy. Our work demonstrates that LM watermarking is fundamentally a channel coding problem, paving the way for principled coding-theoretic approaches to watermark design.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 82,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07243",
        "abs_url": "https://arxiv.org/abs/2602.07243",
        "pdf_url": "https://arxiv.org/pdf/2602.07243",
        "title": "Realistic Synthetic Household Data Generation at Scale",
        "authors": [
            "Siddharth Singh",
            "Ifrah Idrees",
            "Abraham Dauhajre"
        ],
        "comments": "Accepted at Agentic AI Benchmarks and Applications for Enterprise Tasks workshop at AAAI 2026",
        "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Graphics (cs.GR)",
        "abstract": "Advancements in foundation models have catalyzed research in Embodied AI to develop interactive agents capable of environmental reasoning and interaction. Developing such agents requires diverse, large-scale datasets. Prior frameworks generate synthetic data for long-term human-robot interactions but fail to model the bidirectional influence between human behavior and household environments. Our proposed generative framework creates household datasets at scale through loosely coupled generation of long-term human-robot interactions and environments. Human personas influence environment generation, while environment schematics and semantics shape human-robot interactions. The generated 3D data includes rich static context such as object and environment semantics, and temporal context capturing human and agent behaviors over extended periods. Our flexible tool allows users to define dataset characteristics via natural language prompts, enabling configuration of environment and human activity data through natural language specifications. The tool creates variations of user-defined configurations, enabling scalable data generation. We validate our framework through statistical evaluation using multi-modal embeddings and key metrics: cosine similarity, mutual information gain, intervention analysis, and iterative improvement validation. Statistical comparisons show good alignment with real-world datasets (HOMER) with cosine similarity (0.60), while synthetic datasets (Wang et al.) show moderate alignment (0.27). Intervention analysis across age, organization, and sleep pattern changes shows statistically significant effects (p < 0.001) with large effect sizes (Cohen's d = 0.51-1.12), confirming bidirectional coupling translates persona traits into measurable environmental and behavioral differences. These contributions enable development and testing of household smart devices at scale.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 83,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07256",
        "abs_url": "https://arxiv.org/abs/2602.07256",
        "pdf_url": "https://arxiv.org/pdf/2602.07256",
        "title": "Graph homophily booster: Reimagining the role of discrete features in heterophilic graph learning",
        "authors": [
            "Ruizhong Qiu",
            "Ting-Wei Li",
            "Gaotang Li",
            "Hanghang Tong"
        ],
        "comments": "ICLR 2026",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Graph neural networks (GNNs) have emerged as a powerful tool for modeling graph-structured data. However, existing GNNs often struggle with heterophilic graphs, where connected nodes tend to have dissimilar features or labels. While numerous methods have been proposed to address this challenge, they primarily focus on architectural designs without directly targeting the root cause of the heterophily problem. These approaches still perform even worse than the simplest MLPs on challenging heterophilic datasets. For instance, our experiments show that 21 latest GNNs still fall behind the MLP on the Actor dataset. This critical challenge calls for an innovative approach to addressing graph heterophily beyond architectural designs. To bridge this gap, we propose and study a new and unexplored paradigm: directly increasing the graph homophily via a carefully designed graph transformation. In this work, we present a simple yet effective framework called GRAPHITE to address graph heterophily. To the best of our knowledge, this work is the first method that explicitly transforms the graph to directly improve the graph homophily. Stemmed from the exact definition of homophily, our proposed GRAPHITE creates feature nodes to facilitate homophilic message passing between nodes that share similar features. Furthermore, we both theoretically and empirically show that our proposed GRAPHITE significantly increases the homophily of originally heterophilic graphs, with only a slight increase in the graph size. Extensive experiments on challenging datasets demonstrate that our proposed GRAPHITE significantly outperforms state-of-the-art methods on heterophilic graphs while achieving comparable accuracy with state-of-the-art methods on homophilic graphs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 84,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07261",
        "abs_url": "https://arxiv.org/abs/2602.07261",
        "pdf_url": "https://arxiv.org/pdf/2602.07261",
        "title": "Cognitive algorithms and systems of episodic memory, semantic memory and their learnings",
        "authors": [
            "Qi Zhang"
        ],
        "comments": "33 pages, 6 figures, 6 tables",
        "subjects": "Neurons and Cognition (q-bio.NC); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)",
        "abstract": "Declarative memory, the memory that can be \"declared\" in words or languages, is made up of two dissociated parts: episodic memory and semantic memory. This dissociation has its neuroanatomical basis episodic memory is mostly associated with the hippocampus and semantic memory with the neocortex. The two memories, on the other hand, are closely related. Lesions in the hippocampus often result in various impairments of explicit memory, e.g., anterograde, retrograde and developmental amnesias, and semantic learning deficit. These impairments provide opportunities for us to understand how the two memories may be acquired, stored and organized. This chapter reviews several cognitive systems that are centered to mimic explicit memory, and other systems that are neuroanatomically based and are implemented to simulate those memory impairments mentioned above. This review includes: the structures of the computational systems, their learning rules, and their simulations of memory acquisition and impairments.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 85,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07264",
        "abs_url": "https://arxiv.org/abs/2602.07264",
        "pdf_url": "https://arxiv.org/pdf/2602.07264",
        "title": "aerial-autonomy-stack -- a Faster-than-real-time, Autopilot-agnostic, ROS2 Framework to Simulate and Deploy Perception-based Drones",
        "authors": [
            "Jacopo Panerati",
            "Sina Sajjadi",
            "Sina Soleymanpour",
            "Varunkumar Mehta",
            "Iraj Mantegh"
        ],
        "comments": "",
        "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)",
        "abstract": "Unmanned aerial vehicles are rapidly transforming multiple applications, from agricultural and infrastructure monitoring to logistics and defense. Introducing greater autonomy to these systems can simultaneously make them more effective as well as reliable. Thus, the ability to rapidly engineer and deploy autonomous aerial systems has become of strategic importance. In the 2010s, a combination of high-performance compute, data, and open-source software led to the current deep learning and AI boom, unlocking decades of prior theoretical work. Robotics is on the cusp of a similar transformation. However, physical AI faces unique hurdles, often combined under the umbrella term \"simulation-to-reality gap\". These span from modeling shortcomings to the complexity of vertically integrating the highly heterogeneous hardware and software systems typically found in field robots. To address the latter, we introduce aerial-autonomy-stack, an open-source, end-to-end framework designed to streamline the pipeline from (GPU-accelerated) perception to (flight controller-based) action. Our stack allows the development of aerial autonomy using ROS2 and provides a common interface for two of the most popular autopilots: PX4 and ArduPilot. We show that it supports over 20x faster-than-real-time, end-to-end simulation of a complete development and deployment stack -- including edge compute and networking -- significantly compressing the build-test-release cycle of perception-based autonomy.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 86,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07265",
        "abs_url": "https://arxiv.org/abs/2602.07265",
        "pdf_url": "https://arxiv.org/pdf/2602.07265",
        "title": "XShare: Collaborative in-Batch Expert Sharing for Faster MoE Inference",
        "authors": [
            "Daniil Vankov",
            "Nikita Ivkin",
            "Kyle Ulrich",
            "Xiang Song",
            "Ashish Khetan",
            "George Karypis"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Mixture-of-Experts (MoE) architectures are increasingly used to efficiently scale large language models. However, in production inference, request batching and speculative decoding significantly amplify expert activation, eroding these efficiency benefits. We address this issue by modeling batch-aware expert selection as a modular optimization problem and designing efficient greedy algorithms for different deployment settings. The proposed method, namely XShare, requires no retraining and dynamically adapts to each batch by maximizing the total gating score of selected experts. It reduces expert activation by up to 30% under standard batching, cuts peak GPU load by up to 3x in expert-parallel deployments, and achieves up to 14% throughput gains in speculative decoding via hierarchical, correlation-aware expert selection even if requests in a batch drawn from heterogeneous datasets.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 87,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07278",
        "abs_url": "https://arxiv.org/abs/2602.07278",
        "pdf_url": "https://arxiv.org/pdf/2602.07278",
        "title": "Laplacian-LoRA: Delaying Oversmoothing in Deep GCNs via Spectral Low-Rank Adaptation",
        "authors": [
            "Sai Vamsi Alisetti"
        ],
        "comments": "4 pages",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Oversmoothing is a fundamental limitation of deep graph convolutional networks (GCNs), causing node representations to collapse as depth increases. While many prior approaches mitigate this effect through architectural modifications or residual mechanisms, the underlying spectral cause of oversmoothing is often left implicit. We propose Laplacian-LoRA, a simple and interpretable low-rank spectral adaptation of standard GCNs. Rather than redesigning message passing, Laplacian-LoRA introduces a learnable, spectrally anchored correction to the fixed Laplacian propagation operator, selectively weakening contraction while preserving stability and the low-pass inductive bias. Across multiple benchmark datasets and depths, Laplacian-LoRA consistently delays the onset of oversmoothing, extending the effective depth of GCNs by up to a factor of two. Embedding variance diagnostics confirm that these gains arise from delayed representational collapse, while learned spectral analysis demonstrates that the correction is smooth, bounded, and well behaved. Our results show that oversmoothing is a depth-dependent spectral phenomenon that can be systematically delayed through modest, low-rank adaptation of the graph propagation operator.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 88,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07284",
        "abs_url": "https://arxiv.org/abs/2602.07284",
        "pdf_url": "https://arxiv.org/pdf/2602.07284",
        "title": "Imagining the Alien: Human Projections and Cognitive Limitations",
        "authors": [
            "S. G. Djorgovski"
        ],
        "comments": "11 pages, from the refereed proceedings of the Inspiration of Astronomical Phenomena XII (INSAP XII) conference held in Corfu, Greece, May 2024, eds. N. Campion, J. Hatch, H. Henry, C. Impey and V. Shrimplin",
        "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Artificial Intelligence (cs.AI); Popular Physics (physics.pop-ph)",
        "abstract": "Imagining what life on other planets, and intelligent life in particular, may be like is a long-running theme in human culture. It is a manifestation of the innate human curiosity about the Cosmos, and it has inspired numerous works of art and folklore, including whole literary and other media genres. It is a profound question, with philosophical and existential implications. There is also an obvious connection with religious beliefs, as gods and other superhuman beings were imagined in the heavens. Speculations about alien beings grew in time, and today, it is a scientific subject of astrobiology, and it is pursued through serious searches for life and intelligence in the universe. However, almost all imaginings of the alien map terrestrial life forms and human cultural, historical, and psychological phenomena to the putative aliens. This lack of individual and collective imagination may reflect our biological and cultural evolution, as our minds are formed through our experiences, perceptions of the world, and interactions with our terrestrial and human environments. As such, imagining aliens is mainly a cultural phenomenon and may reflect the intrinsic cognitive limitations of the human mind. Interestingly, we did create what is effectively an alien intelligence on this planet in the form of now rapidly evolving Artificial Intelligence (AI). As its capabilities grow, it may give us new insights into what extraterrestrial advanced intelligences may be like.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 89,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07294",
        "abs_url": "https://arxiv.org/abs/2602.07294",
        "pdf_url": "https://arxiv.org/pdf/2602.07294",
        "title": "Fin-RATE: A Real-world Financial Analytics and Tracking Evaluation Benchmark for LLMs on SEC Filings",
        "authors": [
            "Yidong Jiang",
            "Junrong Chen",
            "Eftychia Makri",
            "Jialin Chen",
            "Peiwen Li",
            "Ali Maatouk",
            "Leandros Tassiulas",
            "Eliot Brenner",
            "Bing Xiang",
            "Rex Ying"
        ],
        "comments": "",
        "subjects": "Computational Engineering, Finance, and Science (cs.CE); Artificial Intelligence (cs.AI)",
        "abstract": "With increasing deployment of Large Language Models (LLMs) in the finance domain, LLMs are increasingly expected to parse complex regulatory disclosures. However, existing benchmarks often focus on isolated details, failing to reflect the complexity of professional analysis that requires synthesizing information across multiple documents, reporting periods, and corporate entities. They do not distinguish whether errors stem from retrieval failures, generation flaws, finance-specific reasoning mistakes, or misunderstanding of the query or context. This makes it difficult to pinpoint performance bottlenecks. To bridge these gaps, we introduce Fin-RATE, a benchmark built on U.S. Securities and Exchange Commission (SEC) filings and mirror financial analyst workflows through three pathways: detail-oriented reasoning within individual disclosures, cross-entity comparison under shared topics, and longitudinal tracking of the same firm across reporting periods. We benchmark 17 leading LLMs, spanning open-source, closed-source, and finance-specialized models, under both ground-truth context and retrieval-augmented settings. Results show substantial performance degradation, with accuracy dropping by 18.60% and 14.35% as tasks shift from single-document reasoning to longitudinal and cross-entity analysis. This is driven by rising comparison hallucinations, time and entity mismatches, and mirrored by declines in reasoning and factuality--limitations that prior benchmarks have yet to formally categorize or quantify.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 90,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07297",
        "abs_url": "https://arxiv.org/abs/2602.07297",
        "pdf_url": "https://arxiv.org/pdf/2602.07297",
        "title": "Progressive Searching for Retrieval in RAG",
        "authors": [
            "Taehee Jeong",
            "Xingzhe Zhao",
            "Peizu Li",
            "Markus Valvur",
            "Weihua Zhao"
        ],
        "comments": "",
        "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)",
        "abstract": "Retrieval Augmented Generation (RAG) is a promising technique for mitigating two key limitations of large language models (LLMs): outdated information and hallucinations. RAG system stores documents as embedding vectors in a database. Given a query, search is executed to find the most related documents. Then, the topmost matching documents are inserted into LLMs' prompt to generate a response. Efficient and accurate searching is critical for RAG to get relevant information. We propose a cost-effective searching algorithm for retrieval process. Our progressive searching algorithm incrementally refines the candidate set through a hierarchy of searches, starting from low-dimensional embeddings and progressing into a higher, target-dimensionality. This multi-stage approach reduces retrieval time while preserving the desired accuracy. Our findings demonstrate that progressive search in RAG systems achieves a balance between dimensionality, speed, and accuracy, enabling scalable and high-performance retrieval even for large databases.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 91,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07298",
        "abs_url": "https://arxiv.org/abs/2602.07298",
        "pdf_url": "https://arxiv.org/pdf/2602.07298",
        "title": "Principled Synthetic Data Enables the First Scaling Laws for LLMs in Recommendation",
        "authors": [
            "Benyu Zhang",
            "Qiang Zhang",
            "Jianpeng Cheng",
            "Hong-You Chen",
            "Qifei Wang",
            "Wei Sun",
            "Shen Li",
            "Jia Li",
            "Jiahao Wu",
            "Xiangjun Fan",
            "Hong Yan"
        ],
        "comments": "",
        "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) represent a promising frontier for recommender systems, yet their development has been impeded by the absence of predictable scaling laws, which are crucial for guiding research and optimizing resource allocation. We hypothesize that this may be attributed to the inherent noise, bias, and incompleteness of raw user interaction data in prior continual pre-training (CPT) efforts. This paper introduces a novel, layered framework for generating high-quality synthetic data that circumvents such issues by creating a curated, pedagogical curriculum for the LLM. We provide powerful, direct evidence for the utility of our curriculum by showing that standard sequential models trained on our principled synthetic data significantly outperform ($+130\\%$ on recall@100 for SasRec) models trained on real data in downstream ranking tasks, demonstrating its superiority for learning generalizable user preference patterns. Building on this, we empirically demonstrate, for the first time, robust power-law scaling for an LLM that is continually pre-trained on our high-quality, recommendation-specific data. Our experiments reveal consistent and predictable perplexity reduction across multiple synthetic data modalities. These findings establish a foundational methodology for reliable scaling LLM capabilities in the recommendation domain, thereby shifting the research focus from mitigating data deficiencies to leveraging high-quality, structured information.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 92,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07303",
        "abs_url": "https://arxiv.org/abs/2602.07303",
        "pdf_url": "https://arxiv.org/pdf/2602.07303",
        "title": "KRONE: Hierarchical and Modular Log Anomaly Detection",
        "authors": [
            "Lei Ma",
            "Jinyang Liu",
            "Tieying Zhang",
            "Peter M. VanNostrand",
            "Dennis M. Hofmann",
            "Lei Cao",
            "Elke A. Rundensteiner",
            "Jianjun Chen"
        ],
        "comments": "",
        "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)",
        "abstract": "Log anomaly detection is crucial for uncovering system failures and security risks. Although logs originate from nested component executions with clear boundaries, this structure is lost when they are stored as flat sequences. As a result, state-of-the-art methods risk missing true dependencies within executions while learning spurious ones across unrelated events. We propose KRONE, the first hierarchical anomaly detection framework that automatically derives execution hierarchies from flat logs for modular multi-level anomaly detection. At its core, the KRONE Log Abstraction Model captures application-specific semantic hierarchies from log data. This hierarchy is then leveraged to recursively decompose log sequences into multiple levels of coherent execution chunks, referred to as KRONE Seqs, transforming sequence-level anomaly detection into a set of modular KRONE Seq-level detection tasks. For each test KRONE Seq, KRONE employs a hybrid modular detection mechanism that dynamically routes between an efficient level-independent Local-Context detector, which rapidly filters normal sequences, and a Nested-Aware detector that incorporates cross-level semantic dependencies and supports LLM-based anomaly detection and explanation. KRONE further optimizes hierarchical detection through cached result reuse and early-exit strategies. Experiments on three public benchmarks and one industrial dataset from ByteDance Cloud demonstrate that KRONE achieves consistent improvements in detection accuracy, F1-score, data efficiency, resource efficiency, and interpretability. KRONE improves the F1-score by more than 10 percentage points over prior methods while reducing LLM usage to only a small fraction of the test data.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 93,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07307",
        "abs_url": "https://arxiv.org/abs/2602.07307",
        "pdf_url": "https://arxiv.org/pdf/2602.07307",
        "title": "LIT-GRAPH: Evaluating Deep vs. Shallow Graph Embeddings for High-Quality Text Recommendation in Domain-Specific Knowledge Graphs",
        "authors": [
            "Nirmal Gelal",
            "Chloe Snow",
            "Kathleen M. Jagodnik",
            "Ambyr Rios",
            "Hande KÃ¼Ã§Ã¼k McGinty"
        ],
        "comments": "",
        "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)",
        "abstract": "This study presents LIT-GRAPH (Literature Graph for Recommendation and Pedagogical Heuristics), a novel knowledge graph-based recommendation system designed to scaffold high school English teachers in selecting diverse, pedagogically aligned instructional literature. The system is built upon an ontology for English literature, addressing the challenge of curriculum stagnation, where we compare four graph embedding paradigms: DeepWalk, Biased Random Walk (BRW), Hybrid (concatenated DeepWalk and BRW vectors), and the deep model Relational Graph Convolutional Network (R-GCN). Results reveal a critical divergence: while shallow models excelled in structural link prediction, R-GCN dominated semantic ranking. By leveraging relation-specific message passing, the deep model prioritizes pedagogical relevance over raw connectivity, resulting in superior, high-quality, domain-specific recommendations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 94,
        "date": "2026-02-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2026-02-10?abs=True",
        "arxiv_id": "2602.07309",
        "abs_url": "https://arxiv.org/abs/2602.07309",
        "pdf_url": "https://arxiv.org/pdf/2602.07309",
        "title": "Semantic Search At LinkedIn",
        "authors": [
            "Fedor Borisyuk",
            "Sriram Vasudevan",
            "Muchen Wu",
            "Guoyao Li",
            "Benjamin Le",
            "Shaobo Zhang",
            "Qianqi Kay Shen",
            "Yuchin Juan",
            "Kayhan Behdin",
            "Liming Dong",
            "Kaixu Yang",
            "Shusen Jing",
            "Ravi Pothamsetty",
            "Rajat Arora",
            "Sophie Yanying Sheng",
            "Vitaly Abdrashitov",
            "Yang Zhao",
            "Lin Su",
            "Xiaoqing Wang",
            "Chujie Zheng",
            "Sarang Metkar",
            "Rupesh Gupta",
            "Igor Lapchuk",
            "David N. Racca",
            "Madhumitha Mohan",
            "Yanbo Li",
            "Haojun Li",
            "Saloni Gandhi",
            "Xueying Lu",
            "Chetan Bhole",
            "Ali Hooshmand",
            "Xin Yang",
            "Raghavan Muthuregunathan",
            "Jiajun Zhang",
            "Mathew Teoh",
            "Adam Coler",
            "Abhinav Gupta",
            "Xiaojing Ma",
            "Sundara Raman Ramachandran",
            "Morteza Ramezani",
            "Yubo Wang",
            "Lijuan Zhang",
            "Richard Li",
            "Jian Sheng",
            "Chanh Nguyen",
            "Yen-Chi Chen",
            "Chuanrui Zhu",
            "Claire Zhang",
            "Jiahao Xu",
            "Deepti Kulkarni",
            "Qing Lan",
            "Arvind Subramaniam",
            "Ata Fatahibaarzi",
            "Steven Shimizu",
            "Yanning Chen",
            "Zhipeng Wang",
            "Ran He",
            "Zhengze Zhou",
            "Qingquan Song",
            "Yun Dai",
            "Caleb Johnson",
            "Ping Liu",
            "Shaghayegh Gharghabi",
            "Gokulraj Mohanasundaram",
            "Juan Bottaro",
            "Santhosh Sachindran",
            "Qi Guo",
            "Yunxiang Ren",
            "Chengming Jiang",
            "Di Mo",
            "Luke Simon",
            "Jianqiang Shen",
            "Jingwei Wu",
            "Wenjing Zhang"
        ],
        "comments": "",
        "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Semantic search with large language models (LLMs) enables retrieval by meaning rather than keyword overlap, but scaling it requires major inference efficiency advances. We present LinkedIn's LLM-based semantic search framework for AI Job Search and AI People Search, combining an LLM relevance judge, embedding-based retrieval, and a compact Small Language Model trained via multi-teacher distillation to jointly optimize relevance and engagement. A prefill-oriented inference architecture co-designed with model pruning, context compression, and text-embedding hybrid interactions boosts ranking throughput by over 75x under a fixed latency constraint while preserving near-teacher-level NDCG, enabling one of the first production LLM-based ranking systems with efficiency comparable to traditional approaches and delivering significant gains in quality and user engagement.",
        "gemini2.5flash": "",
        "overall_idea": ""
    }
]