[
    {
        "order": 1,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04685",
        "abs_url": "https://arxiv.org/abs/2511.04685",
        "pdf_url": "https://arxiv.org/pdf/2511.04685",
        "title": "A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024",
        "authors": [
            "Daniela Guericke",
            "Rolf van der Hulst",
            "Asal Karimpour",
            "Ieke Schrader",
            "Matthias Walter"
        ],
        "comments": "23 pages, 2 figures, 10 tables",
        "subjects": "Artificial Intelligence (cs.AI); Optimization and Control (math.OC)",
        "abstract": "We report about the algorithm, implementation and results submitted to the Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored third in the competition. Our approach combines mixed-integer programming, constraint programming and simulated annealing in a 3-phase solution approach based on decomposition into subproblems. Next to describing our approach and describing our design decisions, we share our insights and, for the first time, lower bounds on the optimal solution values for the benchmark instances. We finally highlight open problems for which we think that addressing them could improve our approach even further.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 2,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04855",
        "abs_url": "https://arxiv.org/abs/2511.04855",
        "pdf_url": "https://arxiv.org/pdf/2511.04855",
        "title": "Epistemic Reject Option Prediction",
        "authors": [
            "Vojtech Franc",
            "Jakub Paplham"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "In high-stakes applications, predictive models must not only produce accurate predictions but also quantify and communicate their uncertainty. Reject-option prediction addresses this by allowing the model to abstain when prediction uncertainty is high. Traditional reject-option approaches focus solely on aleatoric uncertainty, an assumption valid only when large training data makes the epistemic uncertainty negligible. However, in many practical scenarios, limited data makes this assumption unrealistic. This paper introduces the epistemic reject-option predictor, which abstains in regions of high epistemic uncertainty caused by insufficient data. Building on Bayesian learning, we redefine the optimal predictor as the one that minimizes expected regret -- the performance gap between the learned model and the Bayes-optimal predictor with full knowledge of the data distribution. The model abstains when the regret for a given input exceeds a specified rejection cost. To our knowledge, this is the first principled framework that enables learning predictors capable of identifying inputs for which the training data is insufficient to make reliable decisions.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 3,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04880",
        "abs_url": "https://arxiv.org/abs/2511.04880",
        "pdf_url": "https://arxiv.org/pdf/2511.04880",
        "title": "DMA: Online RAG Alignment with Human Feedback",
        "authors": [
            "Yu Bai",
            "Yukai Miao",
            "Dawei Wang",
            "Li Chen",
            "Fei Long",
            "Rundi Zhai",
            "Dan Li",
            "Yanyu Ren",
            "Tianfeng Liu",
            "Hongtao Xie",
            "Ce Yang",
            "Xuhui Cai"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Retrieval-augmented generation (RAG) systems often rely on static retrieval, limiting adaptation to evolving intent and content drift. We introduce Dynamic Memory Alignment (DMA), an online learning framework that systematically incorporates multi-granularity human feedback to align ranking in interactive settings. DMA organizes document-, list-, and response-level signals into a coherent learning pipeline: supervised training for pointwise and listwise rankers, policy optimization driven by response-level preferences, and knowledge distillation into a lightweight scorer for low-latency serving. Throughout this paper, memory refers to the model's working memory, which is the entire context visible to the LLM for In-Context Learning. We adopt a dual-track evaluation protocol mirroring deployment: (i) large-scale online A/B ablations to isolate the utility of each feedback source, and (ii) few-shot offline tests on knowledge-intensive benchmarks. Online, a multi-month industrial deployment further shows substantial improvements in human engagement. Offline, DMA preserves competitive foundational retrieval while yielding notable gains on conversational QA (TriviaQA, HotpotQA). Taken together, these results position DMA as a principled approach to feedback-driven, real-time adaptation in RAG without sacrificing baseline capability.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 4,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04898",
        "abs_url": "https://arxiv.org/abs/2511.04898",
        "pdf_url": "https://arxiv.org/pdf/2511.04898",
        "title": "Real-Time Reasoning Agents in Evolving Environments",
        "authors": [
            "Yule Wen",
            "Yixin Ye",
            "Yanzhe Zhang",
            "Diyi Yang",
            "Hao Zhu"
        ],
        "comments": "30 pages",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "Agents in the real world must make not only logical but also timely judgments. This requires continuous awareness of the dynamic environment: hazards emerge, opportunities arise, and other agents act, while the agent's reasoning is still unfolding. Despite advances in language model reasoning, existing approaches fail to account for this dynamic nature. We introduce real-time reasoning as a new problem formulation for agents in evolving environments and build Real-Time Reasoning Gym to demonstrate it. We study two paradigms for deploying language models in agents: (1) reactive agents, which employ language models with bounded reasoning computation for rapid responses, and (2) planning agents, which allow extended reasoning computation for complex problems. Our experiments show that even state-of-the-art models struggle with making logical and timely judgments in either paradigm. To address this limitation, we propose AgileThinker, which simultaneously engages both reasoning paradigms. AgileThinker consistently outperforms agents engaging only one reasoning paradigm as the task difficulty and time pressure rise, effectively balancing reasoning depth and response latency. Our work establishes real-time reasoning as a critical testbed for developing practical agents and provides a foundation for research in temporally constrained AI systems, highlighting a path toward real-time capable agents.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 5,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04956",
        "abs_url": "https://arxiv.org/abs/2511.04956",
        "pdf_url": "https://arxiv.org/pdf/2511.04956",
        "title": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property",
        "authors": [
            "Maria Mahbub",
            "Vanessa Lama",
            "Sanjay Das",
            "Brian Starks",
            "Christopher Polchek",
            "Saffell Silvers",
            "Lauren Deck",
            "Prasanna Balaprakash",
            "Tirthankar Ghosal"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
        "abstract": "High-Risk Property (HRP) classification is critical at U.S. Department of Energy (DOE) sites, where inventories include sensitive and often dual-use equipment. Compliance must track evolving rules designated by various export control policies to make transparent and auditable decisions. Traditional expert-only workflows are time-consuming, backlog-prone, and struggle to keep pace with shifting regulatory boundaries. We demo ORCHID, a modular agentic system for HRP classification that pairs retrieval-augmented generation (RAG) with human oversight to produce policy-based outputs that can be audited. Small cooperating agents, retrieval, description refiner, classifier, validator, and feedback logger, coordinate via agent-to-agent messaging and invoke tools through the Model Context Protocol (MCP) for model-agnostic on-premise operation. The interface follows an Item to Evidence to Decision loop with step-by-step reasoning, on-policy citations, and append-only audit bundles (run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID improves accuracy and traceability over a non-agentic baseline while deferring uncertain items to Subject Matter Experts (SMEs). The demonstration shows single item submission, grounded citations, SME feedback capture, and exportable audit artifacts, illustrating a practical path to trustworthy LLM assistance in sensitive DOE compliance workflows.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 6,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05182",
        "abs_url": "https://arxiv.org/abs/2511.05182",
        "pdf_url": "https://arxiv.org/pdf/2511.05182",
        "title": "Autonomous generation of different courses of action in mechanized combat operations",
        "authors": [
            "Johan Schubert",
            "Patrik Hansen",
            "Pontus Hörling",
            "Ronnie Johansson"
        ],
        "comments": "In Proceedings of the 30th International Command and Control Research & Technology Symposium, Stockholm, Sweden, 3-6 November 2025, paper 009",
        "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)",
        "abstract": "In this paper, we propose a methodology designed to support decision-making during the execution phase of military ground combat operations, with a focus on one's actions. This methodology generates and evaluates recommendations for various courses of action for a mechanized battalion, commencing with an initial set assessed by their anticipated outcomes. It systematically produces thousands of individual action alternatives, followed by evaluations aimed at identifying alternative courses of action with superior outcomes. These alternatives are appraised in light of the opponent's status and actions, considering unit composition, force ratios, types of offense and defense, and anticipated advance rates. Field manuals evaluate battle outcomes and advancement rates. The processes of generation and evaluation work concurrently, yielding a variety of alternative courses of action. This approach facilitates the management of new course generation based on previously evaluated actions. As the combat unfolds and conditions evolve, revised courses of action are formulated for the decision-maker within a sequential decision-making framework.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 7,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05311",
        "abs_url": "https://arxiv.org/abs/2511.05311",
        "pdf_url": "https://arxiv.org/pdf/2511.05311",
        "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance",
        "authors": [
            "Valeriu Dimidov",
            "Faisal Hawlader",
            "Sasan Jafarnejad",
            "Raphaël Frank"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO); Software Engineering (cs.SE)",
        "abstract": "Economic constraints, limited availability of datasets for reproducibility and shortages of specialized expertise have long been recognized as key challenges to the adoption and advancement of predictive maintenance (PdM) in the automotive sector. Recent progress in large language models (LLMs) presents an opportunity to overcome these barriers and speed up the transition of PdM from research to industrial practice. Under these conditions, we explore the potential of LLM-based agents to support PdM cleaning pipelines. Specifically, we focus on maintenance logs, a critical data source for training well-performing machine learning (ML) models, but one often affected by errors such as typos, missing fields, near-duplicate entries, and incorrect dates. We evaluate LLM agents on cleaning tasks involving six distinct types of noise. Our findings show that LLMs are effective at handling generic cleaning tasks and offer a promising foundation for future industrial applications. While domain-specific errors remain challenging, these results highlight the potential for further improvements through specialized training and enhanced agentic capabilities.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 8,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05375",
        "abs_url": "https://arxiv.org/abs/2511.05375",
        "pdf_url": "https://arxiv.org/pdf/2511.05375",
        "title": "Reasoning Is All You Need for Urban Planning AI",
        "authors": [
            "Sijie Yang",
            "Jiatong Li",
            "Filip Biljecki"
        ],
        "comments": "Submitted to AAAI 2026 Workshop AI4UP",
        "subjects": "Artificial Intelligence (cs.AI)",
        "abstract": "AI has proven highly successful at urban planning analysis -- learning patterns from data to predict future conditions. The next frontier is AI-assisted decision-making: agents that recommend sites, allocate resources, and evaluate trade-offs while reasoning transparently about constraints and stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting, ReAct, and multi-agent collaboration frameworks -- now make this vision achievable. This position paper presents the Agentic Urban Planning AI Framework for reasoning-capable planning agents that integrates three cognitive layers (Perception, Foundation, Reasoning) with six logic components (Analysis, Generation, Verification, Evaluation, Collaboration, Decision) through a multi-agents collaboration framework. We demonstrate why planning decisions require explicit reasoning capabilities that are value-based (applying normative principles), rule-grounded (guaranteeing constraint satisfaction), and explainable (generating transparent justifications) -- requirements that statistical learning alone cannot fulfill. We compare reasoning agents with statistical learning, present a comprehensive architecture with benchmark evaluation metrics, and outline critical research challenges. This framework shows how AI agents can augment human planners by systematically exploring solution spaces, verifying regulatory compliance, and deliberating over trade-offs transparently -- not replacing human judgment but amplifying it with computational reasoning capabilities.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 9,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04682",
        "abs_url": "https://arxiv.org/abs/2511.04682",
        "pdf_url": "https://arxiv.org/pdf/2511.04682",
        "title": "Efficient Deployment of CNN Models on Multiple In-Memory Computing Units",
        "authors": [
            "Eleni Bougioukou",
            "Theodore Antonakopoulos"
        ],
        "comments": "5 pages, 4 figures, 2025 14th International Conference on Modern Circuits and Systems Technologies (MOCAST)",
        "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)",
        "abstract": "In-Memory Computing (IMC) represents a paradigm shift in deep learning acceleration by mitigating data movement bottlenecks and leveraging the inherent parallelism of memory-based computations. The efficient deployment of Convolutional Neural Networks (CNNs) on IMC-based hardware necessitates the use of advanced task allocation strategies for achieving maximum computational efficiency. In this work, we exploit an IMC Emulator (IMCE) with multiple Processing Units (PUs) for investigating how the deployment of a CNN model in a multi-processing system affects its performance, in terms of processing rate and latency. For that purpose, we introduce the Load-Balance-Longest-Path (LBLP) algorithm, that dynamically assigns all CNN nodes to the available IMCE PUs, for maximizing the processing rate and minimizing latency due to efficient resources utilization. We are benchmarking LBLP against other alternative scheduling strategies for a number of CNN models and experimental results demonstrate the effectiveness of the proposed algorithm.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 10,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04683",
        "abs_url": "https://arxiv.org/abs/2511.04683",
        "pdf_url": "https://arxiv.org/pdf/2511.04683",
        "title": "AI-Powered Citation Auditing: A Zero-Assumption Protocol for Systematic Reference Verification in Academic Research",
        "authors": [
            "L.J. Janse van Rensburg"
        ],
        "comments": "10 pages, 1 table. Code and validation data available at this https URL",
        "subjects": "Digital Libraries (cs.DL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)",
        "abstract": "Academic citation integrity faces persistent challenges, with research indicating 20% of citations contain errors and manual verification requiring months of expert time. This paper presents a novel AI-powered methodology for systematic, comprehensive reference auditing using agentic AI with tool-use capabilities. We develop a zero-assumption verification protocol that independently validates every reference against multiple academic databases (Semantic Scholar, Google Scholar, CrossRef) without assuming any citation is correct. The methodology was validated across 30 academic documents (2,581 references) spanning undergraduate projects to doctoral theses and peer-reviewed publications. Results demonstrate 91.7% average verification rate on published PLOS papers, with successful detection of fabricated references, retracted articles, orphan citations, and predatory journals. Time efficiency improved dramatically: 90-minute audits for 916-reference doctoral theses versus months of manual review. The system achieved <0.5% false positive rate while identifying critical issues manual review might miss. This work establishes the first validated AI-agent methodology for academic citation integrity, demonstrating practical applicability for supervisors, students, and institutional quality assurance.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 11,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04686",
        "abs_url": "https://arxiv.org/abs/2511.04686",
        "pdf_url": "https://arxiv.org/pdf/2511.04686",
        "title": "Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity",
        "authors": [
            "Pratik Poudel"
        ],
        "comments": "14 pages, 2 figures",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
        "abstract": "The Key-Value (KV) cache is integral to efficient autoregressive inference in large language models (LLMs), yet its unbounded growth in stateful multi-turn scenarios presents major challenges. This paper examines the interplay between KV cache management strategies, the architectural context limits of models like meta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of positional encodings. Through empirical analysis using a stateful benchmarking framework, we show that LLM generation quality degrades sharply when the accumulated KV cache approaches or exceeds the model's trained context window (e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory exhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via AttentionTop), can worsen performance if they disrupt positional coherence. Because LLMs rely on consistent positional signals (e.g., RoPE), compacting a cache by removing non-contiguous tokens can scramble these signals and lead to degenerative outputs. We further show that simple strategies preserving contiguous context blocks (e.g., keeping an initial \"gist\") can yield more coherent generations than complex or positionally disruptive ones. We advocate for eviction techniques that respect architectural limits, preserve positional structure, and view \"cache health\" holistically beyond mere size.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 12,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04689",
        "abs_url": "https://arxiv.org/abs/2511.04689",
        "pdf_url": "https://arxiv.org/pdf/2511.04689",
        "title": "Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks",
        "authors": [
            "Peiyu Li",
            "Xiuxiu Tang",
            "Si Chen",
            "Ying Cheng",
            "Ronald Metoyer",
            "Ting Hua",
            "Nitesh V. Chawla"
        ],
        "comments": "Code and calibrated item banks are available at this https URL",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Large language model evaluation requires thousands of benchmark items, making evaluations expensive and slow. Existing methods compute average accuracy across fixed item sets, treating all items equally despite varying quality and informativeness. We present ATLAS an adaptive testing framework using Item Response Theory (IRT) to estimate model ability through Fisher information-guided item selection. Our analysis of five major benchmarks reveals that 3-6% of items exhibit negative discrimination, indicating annotation errors that corrupt static evaluation. ATLAS achieves 90% item reduction while maintaining measurement precision: on HellaSwag (5,608 items), we match full-benchmark estimates using only 42 items with 0.154 MAE. Our framework maintains item exposure rates below 10% and test overlap at 16-27%, compared to static benchmarks where every model sees all items (100% exposure). Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with the same accuracy get different IRT scores, and 23-31% of all models shift by more than 10 rank positions. Code and calibrated item banks are available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 13,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04691",
        "abs_url": "https://arxiv.org/abs/2511.04691",
        "pdf_url": "https://arxiv.org/pdf/2511.04691",
        "title": "A Penny for Your Thoughts: Decoding Speech from Inexpensive Brain Signals",
        "authors": [
            "Quentin Auster",
            "Kateryna Shapovalenko",
            "Chuang Ma",
            "Demaio Sun"
        ],
        "comments": "",
        "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS); Neurons and Cognition (q-bio.NC)",
        "abstract": "We explore whether neural networks can decode brain activity into speech by mapping EEG recordings to audio representations. Using EEG data recorded as subjects listened to natural speech, we train a model with a contrastive CLIP loss to align EEG-derived embeddings with embeddings from a pre-trained transformer-based speech model. Building on the state-of-the-art EEG decoder from Meta, we introduce three architectural modifications: (i) subject-specific attention layers (+0.15% WER improvement), (ii) personalized spatial attention (+0.45%), and (iii) a dual-path RNN with attention (-1.87%). Two of the three modifications improved performance, highlighting the promise of personalized architectures for brain-to-speech decoding and applications in brain-computer interfaces.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 14,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04694",
        "abs_url": "https://arxiv.org/abs/2511.04694",
        "pdf_url": "https://arxiv.org/pdf/2511.04694",
        "title": "Reasoning Up the Instruction Ladder for Controllable Language Models",
        "authors": [
            "Zishuo Zheng",
            "Vidhisha Balachandran",
            "Chan Young Park",
            "Faeze Brahman",
            "Sachin Kumar"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "As large language model (LLM) based systems take on high-stakes roles in real-world decision-making, they must reconcile competing instructions from multiple sources (e.g., model developers, users, and tools) within a single prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where higher-level directives override lower-priority requests, is critical for the reliability and controllability of LLMs. In this work, we reframe instruction hierarchy resolution as a reasoning task. Specifically, the model must first \"think\" about the relationship between a given user prompt and higher-priority (system) instructions before generating a response. To enable this capability via training, we construct VerIH, an instruction hierarchy dataset of constraint-following tasks with verifiable answers. This dataset comprises both aligned and conflicting system-user instructions. We show that lightweight reinforcement learning with VerIH effectively transfers general reasoning capabilities of models to instruction prioritization. Our finetuned models achieve consistent improvements on instruction following and instruction hierarchy benchmarks. This reasoning ability also generalizes to safety-critical settings beyond the training distribution. By treating safety issues as resolving conflicts between adversarial user inputs and predefined higher-priority policies, our trained model enhances robustness against jailbreak and prompt injection attacks. These results demonstrate that reasoning over instruction hierarchies provides a practical path to reliable LLMs, where updates to system prompts yield controllable and robust changes in model behavior.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 15,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04696",
        "abs_url": "https://arxiv.org/abs/2511.04696",
        "pdf_url": "https://arxiv.org/pdf/2511.04696",
        "title": "EncouRAGe: Evaluating RAG Local, Fast, and Reliable",
        "authors": [
            "Jan Strich",
            "Adeline Scharfenberg",
            "Chris Biemann",
            "Martin Semmann"
        ],
        "comments": "Currently under review",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)",
        "abstract": "We introduce EncouRAGe, a comprehensive Python framework designed to streamline the development and evaluation of Retrieval-Augmented Generation (RAG) systems using Large Language Models (LLMs) and Embedding Models. EncouRAGe comprises five modular and extensible components: Type Manifest, RAG Factory, Inference, Vector Store, and Metrics, facilitating flexible experimentation and extensible development. The framework emphasizes scientific reproducibility, diverse evaluation metrics, and local deployment, enabling researchers to efficiently assess datasets within RAG workflows. This paper presents implementation details and an extensive evaluation across multiple benchmark datasets, including 25k QA pairs and over 51k documents. Our results show that RAG still underperforms compared to the Oracle Context, while Hybrid BM25 consistently achieves the best results across all four datasets. We further examine the effects of reranking, observing only marginal performance improvements accompanied by higher response latency.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 16,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04697",
        "abs_url": "https://arxiv.org/abs/2511.04697",
        "pdf_url": "https://arxiv.org/pdf/2511.04697",
        "title": "Simulating Misinformation Vulnerabilities With Agent Personas",
        "authors": [
            "David Farr",
            "Lynnette Hui Xian Ng",
            "Stephen Prochaska",
            "Iain J. Cruickshank",
            "Jevin West"
        ],
        "comments": "Accepted to Winter Simulation Conference 2025",
        "subjects": "Social and Information Networks (cs.SI); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
        "abstract": "Disinformation campaigns can distort public perception and destabilize institutions. Understanding how different populations respond to information is crucial for designing effective interventions, yet real-world experimentation is impractical and ethically challenging. To address this, we develop an agent-based simulation using Large Language Models (LLMs) to model responses to misinformation. We construct agent personas spanning five professions and three mental schemas, and evaluate their reactions to news headlines. Our findings show that LLM-generated agents align closely with ground-truth labels and human predictions, supporting their use as proxies for studying information responses. We also find that mental schemas, more than professional background, influence how agents interpret misinformation. This work provides a validation of LLMs to be used as agents in an agent-based model of an information network for analyzing trust, polarization, and susceptibility to deceptive content in complex social systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 17,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04698",
        "abs_url": "https://arxiv.org/abs/2511.04698",
        "pdf_url": "https://arxiv.org/pdf/2511.04698",
        "title": "multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder",
        "authors": [
            "K M Sajjadul Islam",
            "John Fields",
            "Praveen Madiraju"
        ],
        "comments": "Accepted in IEEE Big Data, 8-11 December, 2025 @ Macau SAR, China",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "The early detection of mental health disorders from social media text is critical for enabling timely support, risk assessment, and referral to appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned RoBERTa model designed for multiclass classification of common mental health conditions, including stress, anxiety, depression, post-traumatic stress disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple curated datasets, data exploration is conducted to analyze class overlaps, revealing strong correlations between depression and suicidal ideation as well as anxiety and PTSD, while stress emerges as a broad, overlapping category. Comparative experiments with traditional machine learning methods, domain-specific transformers, and prompting-based large language models demonstrate that multiMentalRoBERTa achieves superior performance, with macro F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup (excluding stress), outperforming both fine-tuned MentalBERT and baseline classifiers. Beyond predictive accuracy, explainability methods, including Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues that drive classification, with a particular focus on distinguishing depression from suicidal ideation. The findings emphasize the effectiveness of fine-tuned transformers for reliable and interpretable detection in sensitive contexts, while also underscoring the importance of fairness, bias mitigation, and human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as a lightweight, robust, and deployable solution for enhancing support in mental health platforms.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 18,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04700",
        "abs_url": "https://arxiv.org/abs/2511.04700",
        "pdf_url": "https://arxiv.org/pdf/2511.04700",
        "title": "Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation",
        "authors": [
            "Song Wang",
            "Zihan Chen",
            "Peng Wang",
            "Zhepei Wei",
            "Zhen Tan",
            "Yu Meng",
            "Cong Shen",
            "Jundong Li"
        ],
        "comments": "EMNLP Main 2025",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge sources to address their limitations in accessing up-to-date or specialized information. A natural strategy to increase the likelihood of retrieving relevant information is to expand the number of retrieved documents. However, involving more documents could introduce significant noise, as many documents may be irrelevant or misleading, thereby reducing the overall accuracy of the generated responses. To overcome the challenge associated with handling a larger number of documents, we propose WinnowRAG, a novel RAG framework designed to systematically filter out noisy documents while preserving valuable content -- a process we refer to as winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware clustering to group similar documents and form distinct topic clusters. Each cluster is assigned to an LLM agent for generating a unique answer. In Stage II, we perform winnowing, wherein a critic LLM evaluates the outputs of multiple agents and iteratively separates useful documents from noisy ones. To retain useful documents when discarding agents, we propose two strategic merging techniques to ensure that only relevant knowledge is used for generating the final response. Crucially, WinnowRAG is model-agnostic and does not require any model fine-tuning, making it easily adaptable to various tasks. Extensive experiments on various realistic datasets demonstrate the effectiveness of WinnowRAG over state-of-the-art baselines.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 19,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04703",
        "abs_url": "https://arxiv.org/abs/2511.04703",
        "pdf_url": "https://arxiv.org/pdf/2511.04703",
        "title": "Measuring what Matters: Construct Validity in Large Language Model Benchmarks",
        "authors": [
            "Andrew M. Bean",
            "Ryan Othniel Kearns",
            "Angelika Romanou",
            "Franziska Sofia Hafner",
            "Harry Mayne",
            "Jan Batzner",
            "Negar Foroutan",
            "Chris Schmitz",
            "Karolina Korgul",
            "Hunar Batra",
            "Oishi Deb",
            "Emma Beharry",
            "Cornelius Emde",
            "Thomas Foster",
            "Anna Gausen",
            "María Grandury",
            "Simeng Han",
            "Valentin Hofmann",
            "Lujain Ibrahim",
            "Hazel Kim",
            "Hannah Rose Kirk",
            "Fangru Lin",
            "Gabrielle Kaili-May Liu",
            "Lennart Luettgau",
            "Jabez Magomere",
            "Jonathan Rystrøm",
            "Anna Sotnikova",
            "Yushi Yang",
            "Yilun Zhao",
            "Adel Bibi",
            "Antoine Bosselut",
            "Ronald Clark",
            "Arman Cohan",
            "Jakob Foerster",
            "Yarin Gal",
            "Scott A. Hale",
            "Inioluwa Deborah Raji",
            "Christopher Summerfield",
            "Philip H.S. Torr",
            "Cozmin Ududec",
            "Luc Rocher",
            "Adam Mahdi"
        ],
        "comments": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Track on Datasets and Benchmarks",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Evaluating large language models (LLMs) is crucial for both assessing their capabilities and identifying safety or robustness issues prior to deployment. Reliably measuring abstract and complex phenomena such as 'safety' and 'robustness' requires strong construct validity, that is, having measures that represent what matters to the phenomenon. With a team of 29 expert reviewers, we conduct a systematic review of 445 LLM benchmarks from leading conferences in natural language processing and machine learning. Across the reviewed articles, we find patterns related to the measured phenomena, tasks, and scoring metrics which undermine the validity of the resulting claims. To address these shortcomings, we provide eight key recommendations and detailed actionable guidance to researchers and practitioners in developing LLM benchmarks.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 20,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04705",
        "abs_url": "https://arxiv.org/abs/2511.04705",
        "pdf_url": "https://arxiv.org/pdf/2511.04705",
        "title": "POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios",
        "authors": [
            "Tingyue Yang",
            "Junchi Yao",
            "Yuhui Guo",
            "Chang Liu"
        ],
        "comments": "16 pages, 6 figures",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "We introduce POLIS-Bench, the first rigorous, systematic evaluation suite designed for LLMs operating in governmental bilingual policy scenarios. Compared to existing benchmarks, POLIS-Bench introduces three major advancements. (i) Up-to-date Bilingual Corpus: We construct an extensive, up-to-date policy corpus that significantly scales the effective assessment sample size, ensuring relevance to current governance practice. (ii) Scenario-Grounded Task Design: We distill three specialized, scenario-grounded tasks -- Clause Retrieval & Interpretation, Solution Generation, and the Compliance Judgmen--to comprehensively probe model understanding and application. (iii) Dual-Metric Evaluation Framework: We establish a novel dual-metric evaluation framework combining semantic similarity with accuracy rate to precisely measure both content alignment and task requirement adherence. A large-scale evaluation of over 10 state-of-the-art LLMs on POLIS-Bench reveals a clear performance hierarchy where reasoning models maintain superior cross-task stability and accuracy, highlighting the difficulty of compliance tasks. Furthermore, leveraging our benchmark, we successfully fine-tune a lightweight open-source model. The resulting POLIS series models achieves parity with, or surpasses, strong proprietary baselines on multiple policy subtasks at a significantly reduced cost, providing a cost-effective and compliant path for robust real-world governmental deployment.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 21,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04706",
        "abs_url": "https://arxiv.org/abs/2511.04706",
        "pdf_url": "https://arxiv.org/pdf/2511.04706",
        "title": "Prioritize Economy or Climate Action? Investigating ChatGPT Response Differences Based on Inferred Political Orientation",
        "authors": [
            "Pelin Karadal",
            "Dilara Kekulluoglu"
        ],
        "comments": "",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)",
        "abstract": "Large Language Models (LLMs) distinguish themselves by quickly delivering information and providing personalized responses through natural language prompts. However, they also infer user demographics, which can raise ethical concerns about bias and implicit personalization and create an echo chamber effect. This study aims to explore how inferred political views impact the responses of ChatGPT globally, regardless of the chat session. We also investigate how custom instruction and memory features alter responses in ChatGPT, considering the influence of political orientation. We developed three personas (two politically oriented and one neutral), each with four statements reflecting their viewpoints on DEI programs, abortion, gun rights, and vaccination. We convey the personas' remarks to ChatGPT using memory and custom instructions, allowing it to infer their political perspectives without directly stating them. We then ask eight questions to reveal differences in worldview among the personas and conduct a qualitative analysis of the responses. Our findings indicate that responses are aligned with the inferred political views of the personas, showing varied reasoning and vocabulary, even when discussing similar topics. We also find the inference happening with explicit custom instructions and the implicit memory feature in similar ways. Analyzing response similarities reveals that the closest matches occur between the democratic persona with custom instruction and the neutral persona, supporting the observation that ChatGPT's outputs lean left.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 22,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04707",
        "abs_url": "https://arxiv.org/abs/2511.04707",
        "pdf_url": "https://arxiv.org/pdf/2511.04707",
        "title": "Jailbreaking in the Haystack",
        "authors": [
            "Rishi Rajesh Shah",
            "Chen Henry Wu",
            "Shashwat Saxena",
            "Ziqian Zhong",
            "Alexander Robey",
            "Aditi Raghunathan"
        ],
        "comments": "",
        "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Recent advances in long-context language models (LMs) have enabled million-token inputs, expanding their capabilities across complex tasks like computer-use agents. Yet, the safety implications of these extended contexts remain unclear. To bridge this gap, we introduce NINJA (short for Needle-in-haystack jailbreak attack), a method that jailbreaks aligned LMs by appending benign, model-generated content to harmful user goals. Critical to our method is the observation that the position of harmful goals play an important role in safety. Experiments on standard safety benchmark, HarmBench, show that NINJA significantly increases attack success rates across state-of-the-art open and proprietary models, including LLaMA, Qwen, Mistral, and Gemini. Unlike prior jailbreaking methods, our approach is low-resource, transferable, and less detectable. Moreover, we show that NINJA is compute-optimal -- under a fixed compute budget, increasing context length can outperform increasing the number of trials in best-of-N jailbreak. These findings reveal that even benign long contexts -- when crafted with careful goal positioning -- introduce fundamental vulnerabilities in modern LMs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 23,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04711",
        "abs_url": "https://arxiv.org/abs/2511.04711",
        "pdf_url": "https://arxiv.org/pdf/2511.04711",
        "title": "SWAP: Towards Copyright Auditing of Soft Prompts via Sequential Watermarking",
        "authors": [
            "Wenyuan Yang",
            "Yichen Sun",
            "Changzheng Chen",
            "Zhixuan Chu",
            "Jiaheng Zhang",
            "Yiming Li",
            "Dacheng Tao"
        ],
        "comments": "The first two authors contributed equally to this work. 27 pages",
        "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Large-scale vision-language models, especially CLIP, have demonstrated remarkable performance across diverse downstream tasks. Soft prompts, as carefully crafted modules that efficiently adapt vision-language models to specific tasks, necessitate effective copyright protection. In this paper, we investigate model copyright protection by auditing whether suspicious third-party models incorporate protected soft prompts. While this can be viewed as a special case of model ownership auditing, our analysis shows that existing techniques are ineffective due to prompt learning's unique characteristics. Non-intrusive auditing is inherently prone to false positives when independent models share similar data distributions with victim models. Intrusive approaches also fail: backdoor methods designed for CLIP cannot embed functional triggers, while extending traditional DNN backdoor techniques to prompt learning suffers from harmfulness and ambiguity challenges. We find that these failures in intrusive auditing stem from the same fundamental reason: watermarking operates within the same decision space as the primary task yet pursues opposing objectives. Motivated by these findings, we propose sequential watermarking for soft prompts (SWAP), which implants watermarks into a different and more complex space. SWAP encodes watermarks through a specific order of defender-specified out-of-distribution classes, inspired by the zero-shot prediction capability of CLIP. This watermark, which is embedded in a more complex space, keeps the original prediction label unchanged, making it less opposed to the primary task. We further design a hypothesis-test-guided verification protocol for SWAP and provide theoretical analyses of success conditions. Extensive experiments on 11 datasets demonstrate SWAP's effectiveness, harmlessness, and robustness against potential adaptive attacks.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 24,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04715",
        "abs_url": "https://arxiv.org/abs/2511.04715",
        "pdf_url": "https://arxiv.org/pdf/2511.04715",
        "title": "First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation",
        "authors": [
            "Dmytro Vitel",
            "Anshuman Chhabra"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Identifying how training samples influence/impact Large Language Model (LLM) decision-making is essential for effectively interpreting model decisions and auditing large-scale datasets. Current training sample influence estimation methods (also known as influence functions) undertake this goal by utilizing information flow through the model via its first-order and higher-order gradient terms. However, owing to the large model sizes of today consisting of billions of parameters, these influence computations are often restricted to some subset of model layers to ensure computational feasibility. Prior seminal work by Yeh et al. (2022) in assessing which layers are best suited for computing language data influence concluded that the first (embedding) layers are the most informative for this purpose, using a hypothesis based on influence scores canceling out (i.e., the cancellation effect). In this work, we propose theoretical and empirical evidence demonstrating how the cancellation effect is unreliable, and that middle attention layers are better estimators for influence. Furthermore, we address the broader challenge of aggregating influence scores across layers, and showcase how alternatives to standard averaging (such as ranking and vote-based methods) can lead to significantly improved performance. Finally, we propose better methods for evaluating influence score efficacy in LLMs without undertaking model retraining, and propose a new metric known as the Noise Detection Rate (NDR) that exhibits strong predictive capability compared to the cancellation effect. Through extensive experiments across LLMs of varying types and scales, we concretely determine that the first (layers) are not necessarily better than the last (layers) for LLM influence estimation, contrasting with prior knowledge in the field.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 25,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04716",
        "abs_url": "https://arxiv.org/abs/2511.04716",
        "pdf_url": "https://arxiv.org/pdf/2511.04716",
        "title": "P-MIA: A Profiled-Based Membership Inference Attack on Cognitive Diagnosis Models",
        "authors": [
            "Mingliang Hou",
            "Yinuo Wang",
            "Teng Guo",
            "Zitao Liu",
            "Wenzhou Dou",
            "Jiaqi Zheng",
            "Renqiang Luo",
            "Mi Tian",
            "Weiqi Luo"
        ],
        "comments": "",
        "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)",
        "abstract": "Cognitive diagnosis models (CDMs) are pivotal for creating fine-grained learner profiles in modern intelligent education platforms. However, these models are trained on sensitive student data, raising significant privacy concerns. While membership inference attacks (MIA) have been studied in various domains, their application to CDMs remains a critical research gap, leaving their privacy risks unquantified. This paper is the first to systematically investigate MIA against CDMs. We introduce a novel and realistic grey box threat model that exploits the explainability features of these platforms, where a model's internal knowledge state vectors are exposed to users through visualizations such as radar charts. We demonstrate that these vectors can be accurately reverse-engineered from such visualizations, creating a potent attack surface. Based on this threat model, we propose a profile-based MIA (P-MIA) framework that leverages both the model's final prediction probabilities and the exposed internal knowledge state vectors as features. Extensive experiments on three real-world datasets against mainstream CDMs show that our grey-box attack significantly outperforms standard black-box baselines. Furthermore, we showcase the utility of P-MIA as an auditing tool by successfully evaluating the efficacy of machine unlearning techniques and revealing their limitations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 26,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04720",
        "abs_url": "https://arxiv.org/abs/2511.04720",
        "pdf_url": "https://arxiv.org/pdf/2511.04720",
        "title": "Learning to reason about rare diseases through retrieval-augmented agents",
        "authors": [
            "Ha Young Kim",
            "Jun Li",
            "Ana Beatriz Solana",
            "Carolin M. Pirkl",
            "Benedikt Wiestler",
            "Julia A. Schnabel",
            "Cosmin I. Bercea"
        ],
        "comments": "Submitted on behalf of the PREDICTOM consortium",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Rare diseases represent the long tail of medical imaging, where AI models often fail due to the scarcity of representative training data. In clinical workflows, radiologists frequently consult case reports and literature when confronted with unfamiliar findings. Following this line of reasoning, we introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic system for rare disease detection in brain MRI. Our approach uses AI agents with access to external medical knowledge by embedding both case reports and literature using sentence transformers and indexing them with FAISS to enable efficient similarity search. The agent retrieves clinically relevant evidence to guide diagnostic decision making on unseen diseases, without the need of additional training. Designed as a model-agnostic reasoning module, RADAR can be seamlessly integrated with diverse large language models, consistently improving their rare pathology recognition and interpretability. On the NOVA dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2% performance gain, with the strongest improvements observed for open source models such as DeepSeek. Beyond accuracy, the retrieved examples provide interpretable, literature grounded explanations, highlighting retrieval-augmented reasoning as a powerful paradigm for low-prevalence conditions in medical imaging.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 27,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04723",
        "abs_url": "https://arxiv.org/abs/2511.04723",
        "pdf_url": "https://arxiv.org/pdf/2511.04723",
        "title": "Temporal convolutional and fusional transformer model with Bi-LSTM encoder-decoder for multi-time-window remaining useful life prediction",
        "authors": [
            "Mohamadreza Akbari Pour",
            "Mohamad Sadeq Karimi",
            "Amir Hossein Mazloumi"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Health prediction is crucial for ensuring reliability, minimizing downtime, and optimizing maintenance in industrial systems. Remaining Useful Life (RUL) prediction is a key component of this process; however, many existing models struggle to capture fine-grained temporal dependencies while dynamically prioritizing critical features across time for robust prognostics. To address these challenges, we propose a novel framework that integrates Temporal Convolutional Networks (TCNs) for localized temporal feature extraction with a modified Temporal Fusion Transformer (TFT) enhanced by Bi-LSTM encoder-decoder. This architecture effectively bridges short- and long-term dependencies while emphasizing salient temporal patterns. Furthermore, the incorporation of a multi-time-window methodology improves adaptability across diverse operating conditions. Extensive evaluations on benchmark datasets demonstrate that the proposed model reduces the average RMSE by up to 5.5%, underscoring its improved predictive accuracy compared to state-of-the-art methods. By closing critical gaps in current approaches, this framework advances the effectiveness of industrial prognostic systems and highlights the potential of advanced time-series transformers for RUL prediction.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 28,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04728",
        "abs_url": "https://arxiv.org/abs/2511.04728",
        "pdf_url": "https://arxiv.org/pdf/2511.04728",
        "title": "Trustworthiness Calibration Framework for Phishing Email Detection Using Large Language Models",
        "authors": [
            "Daniyal Ganiuly",
            "Assel Smaiyl"
        ],
        "comments": "10 pages, 5 figures",
        "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)",
        "abstract": "Phishing emails continue to pose a persistent challenge to online communication, exploiting human trust and evading automated filters through realistic language and adaptive tactics. While large language models (LLMs) such as GPT-4 and LLaMA-3-8B achieve strong accuracy in text classification, their deployment in security systems requires assessing reliability beyond benchmark performance. To address this, this study introduces the Trustworthiness Calibration Framework (TCF), a reproducible methodology for evaluating phishing detectors across three dimensions: calibration, consistency, and robustness. These components are integrated into a bounded index, the Trustworthiness Calibration Index (TCI), and complemented by the Cross-Dataset Stability (CDS) metric that quantifies stability of trustworthiness across datasets. Experiments conducted on five corpora, such as SecureMail 2025, Phishing Validation 2024, CSDMC2010, Enron-Spam, and Nazario, using DeBERTa-v3-base, LLaMA-3-8B, and GPT-4 demonstrate that GPT-4 achieves the strongest overall trust profile, followed by LLaMA-3-8B and DeBERTa-v3-base. Statistical analysis confirms that reliability varies independently of raw accuracy, underscoring the importance of trust-aware evaluation for real-world deployment. The proposed framework establishes a transparent and reproducible foundation for assessing model dependability in LLM-based phishing detection.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 29,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04753",
        "abs_url": "https://arxiv.org/abs/2511.04753",
        "pdf_url": "https://arxiv.org/pdf/2511.04753",
        "title": "CPO: Condition Preference Optimization for Controllable Image Generation",
        "authors": [
            "Zonglin Lyu",
            "Ming Li",
            "Xinxin Liu",
            "Chen Chen"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "To enhance controllability in text-to-image generation, ControlNet introduces image-based control signals, while ControlNet++ improves pixel-level cycle consistency between generated images and the input control signal. To avoid the prohibitive cost of back-propagating through the sampling process, ControlNet++ optimizes only low-noise timesteps (e.g., $t < 200$) using a single-step approximation, which not only ignores the contribution of high-noise timesteps but also introduces additional approximation errors. A straightforward alternative for optimizing controllability across all timesteps is Direct Preference Optimization (DPO), a fine-tuning method that increases model preference for more controllable images ($I^{w}$) over less controllable ones ($I^{l}$). However, due to uncertainty in generative models, it is difficult to ensure that win--lose image pairs differ only in controllability while keeping other factors, such as image quality, fixed. To address this, we propose performing preference learning over control conditions rather than generated images. Specifically, we construct winning and losing control signals, $\\mathbf{c}^{w}$ and $\\mathbf{c}^{l}$, and train the model to prefer $\\mathbf{c}^{w}$. This method, which we term \\textit{Condition Preference Optimization} (CPO), eliminates confounding factors and yields a low-variance training objective. Our approach theoretically exhibits lower contrastive loss variance than DPO and empirically achieves superior results. Moreover, CPO requires less computation and storage for dataset curation. Extensive experiments show that CPO significantly improves controllability over the state-of-the-art ControlNet++ across multiple control types: over $10\\%$ error rate reduction in segmentation, $70$--$80\\%$ in human pose, and consistent $2$--$5\\%$ reductions in edge and depth maps.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 30,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04758",
        "abs_url": "https://arxiv.org/abs/2511.04758",
        "pdf_url": "https://arxiv.org/pdf/2511.04758",
        "title": "ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling",
        "authors": [
            "Caelan Garrett",
            "Fabio Ramos"
        ],
        "comments": "Project website: this https URL",
        "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)",
        "abstract": "Bimanual and humanoid robots are appealing because of their human-like ability to leverage multiple arms to efficiently complete tasks. However, controlling multiple arms at once is computationally challenging due to the growth in the hybrid discrete-continuous action space. Task and Motion Planning (TAMP) algorithms can efficiently plan in hybrid spaces but generally produce plans, where only one arm is moving at a time, rather than schedules that allow for parallel arm motion. In order to extend TAMP to produce schedules, we present ScheduleStream, the first general-purpose framework for planning & scheduling with sampling operations. ScheduleStream models temporal dynamics using hybrid durative actions, which can be started asynchronously and persist for a duration that's a function of their parameters. We propose domain-independent algorithms that solve ScheduleStream problems without any application-specific mechanisms. We apply ScheduleStream to Task and Motion Planning & Scheduling (TAMPAS), where we use GPU acceleration within samplers to expedite planning. We compare ScheduleStream algorithms to several ablations in simulation and find that they produce more efficient solutions. We demonstrate ScheduleStream on several real-world bimanual robot tasks at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 31,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04790",
        "abs_url": "https://arxiv.org/abs/2511.04790",
        "pdf_url": "https://arxiv.org/pdf/2511.04790",
        "title": "Causal Structure and Representation Learning with Biomedical Applications",
        "authors": [
            "Caroline Uhler",
            "Jiaqi Zhang"
        ],
        "comments": "This article has successfully completed peer review and will appear in the Proceedings of the International Congress of Mathematicians 2026. Both authors contributed equally to this work",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)",
        "abstract": "Massive data collection holds the promise of a better understanding of complex phenomena and, ultimately, better decisions. Representation learning has become a key driver of deep learning applications, as it allows learning latent spaces that capture important properties of the data without requiring any supervised annotations. Although representation learning has been hugely successful in predictive tasks, it can fail miserably in causal tasks including predicting the effect of a perturbation/intervention. This calls for a marriage between representation learning and causal inference. An exciting opportunity in this regard stems from the growing availability of multi-modal data (observational and perturbational, imaging-based and sequencing-based, at the single-cell level, tissue-level, and organism-level). We outline a statistical and computational framework for causal structure and representation learning motivated by fundamental biomedical questions: how to effectively use observational and perturbational data to perform causal discovery on observed causal variables; how to use multi-modal views of the system to learn causal variables; and how to design optimal perturbations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 32,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04798",
        "abs_url": "https://arxiv.org/abs/2511.04798",
        "pdf_url": "https://arxiv.org/pdf/2511.04798",
        "title": "MDM: Manhattan Distance Mapping of DNN Weights for Parasitic-Resistance-Resilient Memristive Crossbars",
        "authors": [
            "Matheus Farias",
            "Wanghley Martins",
            "H. T. Kung"
        ],
        "comments": "5 pages, 6 figures",
        "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)",
        "abstract": "Manhattan Distance Mapping (MDM) is a post-training deep neural network (DNN) weight mapping technique for memristive bit-sliced compute-in-memory (CIM) crossbars that reduces parasitic resistance (PR) nonidealities. PR limits crossbar efficiency by mapping DNN matrices into small crossbar tiles, reducing CIM-based speedup. Each crossbar executes one tile, requiring digital synchronization before the next layer. At this granularity, designers either deploy many small crossbars in parallel or reuse a few sequentially-both increasing analog-to-digital conversions, latency, I/O pressure, and chip area. MDM alleviates PR effects by optimizing active-memristor placement. Exploiting bit-level structured sparsity, it feeds activations from the denser low-order side and reorders rows according to the Manhattan distance, relocating active cells toward regions less affected by PR and thus lowering the nonideality factor (NF). Applied to DNN models on ImageNet-1k, MDM reduces NF by up to 46% and improves accuracy under analog distortion by an average of 3.6% in ResNets. Overall, it provides a lightweight, spatially informed method for scaling CIM DNN accelerators.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 33,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04805",
        "abs_url": "https://arxiv.org/abs/2511.04805",
        "pdf_url": "https://arxiv.org/pdf/2511.04805",
        "title": "PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via Sparse Expert Merging and Bit-packed inference",
        "authors": [
            "Yushu Zhao",
            "Zheng Wang",
            "Minjia Zhang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Mixture-of-Experts (MoE) models have shown strong potential in scaling language models efficiently by activating only a small subset of experts per input. However, their widespread deployment remains limited due to the high memory overhead associated with storing all expert parameters, particularly as the number of experts increases. To address this challenge, prior works have explored expert dropping and merging strategies, yet they often suffer from performance drop at high compression ratios. In this paper, we introduce PuzzleMoE, a training-free MoE compression method that achieves both high accuracy and efficient inference through two key innovations: First, PuzzleMoE performs sparse expert merging by identifying element-wise weight redundancy and specialization. It uses a dual-mask to capture both shared and expert-specific parameters. Second, to avoid the overhead of storing binary masks and signs, PuzzleMoE introduces a bit-packed encoding scheme that reuses underutilized exponent bits, enabling efficient MoE inference on GPUs. Extensive experiments demonstrate that PuzzleMoE can compress MoE models by up to 50% while maintaining accuracy across various tasks. Specifically, it outperforms prior MoE compression methods by up to 16.7% on MMLU at 50% compression ratio, and achieves up to 1.28\\times inference speedup.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 34,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04812",
        "abs_url": "https://arxiv.org/abs/2511.04812",
        "pdf_url": "https://arxiv.org/pdf/2511.04812",
        "title": "Unified Multimodal Diffusion Forcing for Forceful Manipulation",
        "authors": [
            "Zixuan Huang",
            "Huaidian Hou",
            "Dmitry Berenson"
        ],
        "comments": "Project website: this https URL",
        "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Given a dataset of expert trajectories, standard imitation learning approaches typically learn a direct mapping from observations (e.g., RGB images) to actions. However, such methods often overlook the rich interplay between different modalities, i.e., sensory inputs, actions, and rewards, which is crucial for modeling robot behavior and understanding task outcomes. In this work, we propose Multimodal Diffusion Forcing, a unified framework for learning from multimodal robot trajectories that extends beyond action generation. Rather than modeling a fixed distribution, MDF applies random partial masking and trains a diffusion model to reconstruct the trajectory. This training objective encourages the model to learn temporal and cross-modal dependencies, such as predicting the effects of actions on force signals or inferring states from partial observations. We evaluate MDF on contact-rich, forceful manipulation tasks in simulated and real-world environments. Our results show that MDF not only delivers versatile functionalities, but also achieves strong performance, and robustness under noisy observations. More visualizations can be found on our website this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 35,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04814",
        "abs_url": "https://arxiv.org/abs/2511.04814",
        "pdf_url": "https://arxiv.org/pdf/2511.04814",
        "title": "A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification",
        "authors": [
            "Sebastian Ojeda",
            "Rafael Velasquez",
            "Nicolás Aparicio",
            "Juanita Puentes",
            "Paula Cárdenas",
            "Nicolás Andrade",
            "Gabriel González",
            "Sergio Rincón",
            "Carolina Muñoz-Camargo",
            "Pablo Arbeláez"
        ],
        "comments": "39th Conference on Neural Information Processing Systems (NeurIPS 2025). Camera-ready version. Code: this https URL. Dataset DOI: this https URL",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)",
        "abstract": "Antimicrobial peptides have emerged as promising molecules to combat antimicrobial resistance. However, fragmented datasets, inconsistent annotations, and the lack of standardized benchmarks hinder computational approaches and slow down the discovery of new candidates. To address these challenges, we present the Expanded Standardized Collection for Antimicrobial Peptide Evaluation (ESCAPE), an experimental framework integrating over 80.000 peptides from 27 validated repositories. Our dataset separates antimicrobial peptides from negative sequences and incorporates their functional annotations into a biologically coherent multilabel hierarchy, capturing activities across antibacterial, antifungal, antiviral, and antiparasitic classes. Building on ESCAPE, we propose a transformer-based model that leverages sequence and structural information to predict multiple functional activities of peptides. Our method achieves up to a 2.56% relative average improvement in mean Average Precision over the second-best method adapted for this task, establishing a new state-of-the-art multilabel peptide classification. ESCAPE provides a comprehensive and reproducible evaluation framework to advance AI-driven antimicrobial peptide research.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 36,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04831",
        "abs_url": "https://arxiv.org/abs/2511.04831",
        "pdf_url": "https://arxiv.org/pdf/2511.04831",
        "title": "Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning",
        "authors": [
            "NVIDIA",
            "Mayank Mittal",
            "Pascal Roth",
            "James Tigue",
            "Antoine Richard",
            "Octi Zhang",
            "Peter Du",
            "Antonio Serrano-Muñoz",
            "Xinjie Yao",
            "René Zurbrügg",
            "Nikita Rudin",
            "Lukasz Wawrzyniak",
            "Milad Rakhsha",
            "Alain Denzler",
            "Eric Heiden",
            "Ales Borovicka",
            "Ossama Ahmed",
            "Iretiayo Akinola",
            "Abrar Anwar",
            "Mark T. Carlson",
            "Ji Yuan Feng",
            "Animesh Garg",
            "Renato Gasoto",
            "Lionel Gulich",
            "Yijie Guo",
            "M. Gussert",
            "Alex Hansen",
            "Mihir Kulkarni",
            "Chenran Li",
            "Wei Liu",
            "Viktor Makoviychuk",
            "Grzegorz Malczyk",
            "Hammad Mazhar",
            "Masoud Moghani",
            "Adithyavairavan Murali",
            "Michael Noseworthy",
            "Alexander Poddubny",
            "Nathan Ratliff",
            "Welf Rehberg",
            "Clemens Schwarke",
            "Ritvik Singh",
            "James Latham Smith",
            "Bingjie Tang",
            "Ruchik Thaker",
            "Matthew Trepte",
            "Karl Van Wyk",
            "Fangzhou Yu",
            "Alex Millane",
            "Vikram Ramasamy",
            "Remo Steiner",
            "Sangeeta Subramanian",
            "Clemens Volk",
            "CY Chen",
            "Neel Jawale",
            "Ashwin Varghese Kuruttukulam",
            "Michael A. Lin",
            "Ajay Mandlekar",
            "Karsten Patzwaldt",
            "John Welsh",
            "Huihua Zhao",
            "Fatima Anes",
            "Jean-Francois Lafleche",
            "Nicolas Moënne-Loccoz",
            "Soowan Park",
            "Rob Stepinski",
            "Dirk Van Gelder",
            "Chris Amevor",
            "Jan Carius",
            "Jumyung Chang",
            "Anka He Chen",
            "Pablo de Heras Ciechomski",
            "Gilles Daviet",
            "Mohammad Mohajerani",
            "Julia von Muralt",
            "Viktor Reutskyy",
            "Michael Sauter",
            "Simon Schirm",
            "Eric L. Shi",
            "Pierre Terdiman",
            "Kenny Vilella",
            "Tobias Widmer",
            "Gordon Yeoman",
            "Tiffany Chen",
            "Sergey Grizan",
            "Cathy Li",
            "Lotus Li",
            "Connor Smith",
            "Rafael Wiltz",
            "Kostas Alexis",
            "Yan Chang",
            "David Chu",
            "Linxi \"Jim\" Fan",
            "Farbod Farshidian",
            "Ankur Handa",
            "Spencer Huang",
            "Marco Hutter",
            "Yashraj Narang",
            "Soha Pouya",
            "Shiwei Sheng",
            "Yuke Zhu"
        ],
        "comments": "Code and documentation are available here: this https URL",
        "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)",
        "abstract": "We present Isaac Lab, the natural successor to Isaac Gym, which extends the paradigm of GPU-native robotics simulation into the era of large-scale multi-modal learning. Isaac Lab combines high-fidelity GPU parallel physics, photorealistic rendering, and a modular, composable architecture for designing environments and training robot policies. Beyond physics and rendering, the framework integrates actuator models, multi-frequency sensor simulation, data collection pipelines, and domain randomization tools, unifying best practices for reinforcement and imitation learning at scale within a single extensible platform. We highlight its application to a diverse set of challenges, including whole-body control, cross-embodiment mobility, contact-rich and dexterous manipulation, and the integration of human demonstrations for skill acquisition. Finally, we discuss upcoming integration with the differentiable, GPU-accelerated Newton physics engine, which promises new opportunities for scalable, data-efficient, and gradient-based approaches to robot learning. We believe Isaac Lab's combination of advanced simulation capabilities, rich sensing, and data-center scale execution will help unlock the next generation of breakthroughs in robotics research.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 37,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04849",
        "abs_url": "https://arxiv.org/abs/2511.04849",
        "pdf_url": "https://arxiv.org/pdf/2511.04849",
        "title": "Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach",
        "authors": [
            "Quang-Dung Nguyen",
            "Tri-Dung Tran",
            "Thanh-Hieu Chu",
            "Hoang-Loc Tran",
            "Xiangwei Cheng",
            "Dirk Slama"
        ],
        "comments": "6 pages, 3 figures",
        "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
        "abstract": "The emergence of Software-Defined Vehicles (SDVs) marks a paradigm shift in the automotive industry, where software now plays a pivotal role in defining vehicle functionality, enabling rapid innovation of modern vehicles. Developing SDV-specific applications demands advanced tools to streamline code generation and improve development efficiency. In recent years, general-purpose large language models (LLMs) have demonstrated transformative potential across domains. Still, restricted access to proprietary model architectures hinders their adaption to specific tasks like SDV code generation. In this study, we propose using prompts, a common and basic strategy to interact with LLMs and redirect their responses. Using only system prompts with an appropriate and efficient prompt structure designed using advanced prompt engineering techniques, LLMs can be crafted without requiring a training session or access to their base design. This research investigates the extensive experiments on different models by applying various prompting techniques, including bare models, using a benchmark specifically created to evaluate LLMs' performance in generating SDV code. The results reveal that the model with a few-shot prompting strategy outperforms the others in adjusting the LLM answers to match the expected outcomes based on quantitative metrics.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 38,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04875",
        "abs_url": "https://arxiv.org/abs/2511.04875",
        "pdf_url": "https://arxiv.org/pdf/2511.04875",
        "title": "Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs",
        "authors": [
            "Matthew Bozoukov",
            "Matthew Nguyen",
            "Shubkarman Singh",
            "Bart Bussmann",
            "Patrick Leask"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Recent studies have revealed that LLMs can exhibit behavioral self-awareness: the ability to accurately describe or predict their own learned behaviors without explicit supervision. This capability raises safety concerns as it may, for example, allow models to better conceal their true abilities during evaluation. We attempt to characterize the minimal conditions under which such self-awareness emerges, and the mechanistic processes through which it manifests. Through controlled finetuning experiments on instruction-tuned LLMs with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably induced using a single rank-1 LoRA adapter; (2) that the learned self-aware behavior can be largely captured by a single steering vector in activation space, recovering nearly all of the fine-tune's behavioral effect; and (3) that self-awareness is non-universal and domain-localized, with independent representations across tasks. Together, these findings suggest that behavioral self-awareness emerges as a domain-specific, linear feature that can be easily induced and modulated.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 39,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04902",
        "abs_url": "https://arxiv.org/abs/2511.04902",
        "pdf_url": "https://arxiv.org/pdf/2511.04902",
        "title": "You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models",
        "authors": [
            "Shuvendu Roy",
            "Hossein Hajimirsadeghi",
            "Mengyao Zhai",
            "Golnoosh Samei"
        ],
        "comments": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: MATH-AI",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Recent advances in large language models have demonstrated the promise of unsupervised reinforcement learning (RL) methods for enhancing reasoning capabilities without external supervision. However, the generalizability of these label-free RL approaches to smaller base models with limited reasoning capabilities remains unexplored. In this work, we systematically investigate the performance of label-free RL methods across different model sizes and reasoning strengths, from 0.5B to 7B parameters. Our empirical analysis reveals critical limitations: label-free RL is highly dependent on the base model's pre-existing reasoning capability, with performance often degrading below baseline levels for weaker models. We find that smaller models fail to generate sufficiently long or diverse chain-of-thought reasoning to enable effective self-reflection, and that training data difficulty plays a crucial role in determining success. To address these challenges, we propose a simple yet effective method for label-free RL that utilizes curriculum learning to progressively introduce harder problems during training and mask no-majority rollouts during training. Additionally, we introduce a data curation pipeline to generate samples with predefined difficulty. Our approach demonstrates consistent improvements across all model sizes and reasoning capabilities, providing a path toward more robust unsupervised RL that can bootstrap reasoning abilities in resource-constrained models. We make our code available at this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 40,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04909",
        "abs_url": "https://arxiv.org/abs/2511.04909",
        "pdf_url": "https://arxiv.org/pdf/2511.04909",
        "title": "A Dual Perspective on Decision-Focused Learning: Scalable Training via Dual-Guided Surrogates",
        "authors": [
            "Paula Rodriguez-Diaz",
            "Kirk Bansak Elisabeth Paulson"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Many real-world decisions are made under uncertainty by solving optimization problems using predicted quantities. This predict-then-optimize paradigm has motivated decision-focused learning, which trains models with awareness of how the optimizer uses predictions, improving the performance of downstream decisions. Despite its promise, scaling is challenging: state-of-the-art methods either differentiate through a solver or rely on task-specific surrogates, both of which require frequent and expensive calls to an optimizer, often a combinatorial one. In this paper, we leverage dual variables from the downstream problem to shape learning and introduce Dual-Guided Loss (DGL), a simple, scalable objective that preserves decision alignment while reducing solver dependence. We construct DGL specifically for combinatorial selection problems with natural one-of-many constraints, such as matching, knapsack, and shortest path. Our approach (a) decouples optimization from gradient updates by solving the downstream problem only periodically; (b) between refreshes, trains on dual-adjusted targets using simple differentiable surrogate losses; and (c) as refreshes become less frequent, drives training cost toward standard supervised learning while retaining strong decision alignment. We prove that DGL has asymptotically diminishing decision regret, analyze runtime complexity, and show on two problem classes that DGL matches or exceeds state-of-the-art DFL methods while using far fewer solver calls and substantially less training time. Code is available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 41,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04914",
        "abs_url": "https://arxiv.org/abs/2511.04914",
        "pdf_url": "https://arxiv.org/pdf/2511.04914",
        "title": "MERaLiON-SER: Robust Speech Emotion Recognition Model for English and SEA Languages",
        "authors": [
            "Hardik B. Sailor",
            "Aw Ai Ti",
            "Chen Fang Yih Nancy",
            "Chiu Ying Lay",
            "Ding Yang",
            "He Yingxu",
            "Jiang Ridong",
            "Li Jingtao",
            "Liao Jingyi",
            "Liu Zhuohan",
            "Lu Yanfeng",
            "Ma Yi",
            "Manas Gupta",
            "Muhammad Huzaifah Bin Md Shahrin",
            "Nabilah Binte Md Johan",
            "Nattadaporn Lertcheva",
            "Pan Chunlei",
            "Pham Minh Duc",
            "Siti Maryam Binte Ahmad Subaidi",
            "Siti Umairah Binte Mohammad Salleh",
            "Sun Shuo",
            "Tarun Kumar Vangani",
            "Wang Qiongqiong",
            "Won Cheng Yi Lewis",
            "Wong Heng Meng Jeremy",
            "Wu Jinyang",
            "Zhang Huayun",
            "Zhang Longyin",
            "Zou Xunlong"
        ],
        "comments": "this https URL",
        "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI)",
        "abstract": "We present MERaLiON-SER, a robust speech emotion recognition model de- signed for English and Southeast Asian languages. The model is trained using a hybrid objective combining weighted categorical cross-entropy and Concordance Correlation Coefficient (CCC) losses for joint discrete and dimensional emotion modelling. This dual approach enables the model to capture both the distinct categories of emotion (like happy or angry) and the fine-grained, such as arousal (intensity), valence (positivity/negativity), and dominance (sense of control), lead- ing to a more comprehensive and robust representation of human affect. Extensive evaluations across multilingual Singaporean languages (English, Chinese, Malay, and Tamil ) and other public benchmarks show that MERaLiON-SER consistently surpasses both open-source speech encoders and large Audio-LLMs. These results underscore the importance of specialised speech-only models for accurate paralin- guistic understanding and cross-lingual generalisation. Furthermore, the proposed framework provides a foundation for integrating emotion-aware perception into future agentic audio systems, enabling more empathetic and contextually adaptive multimodal reasoning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 42,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04919",
        "abs_url": "https://arxiv.org/abs/2511.04919",
        "pdf_url": "https://arxiv.org/pdf/2511.04919",
        "title": "BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models",
        "authors": [
            "Chandra Vamsi Krishna Alla",
            "Harish Naidu Gaddam",
            "Manohar Kommi"
        ],
        "comments": "11 pages, 3 figures, 5 tables. Evaluated on 700 QA pairs across multiple document lengths",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) face significant computational and memory constraints when processing long contexts, despite growing demand for applications requiring reasoning over extensive documents, multi-session dialogues, and book length texts. While recent advances have extended context windows to 100K-1M tokens, such approaches incur prohibitive costs for resource constrained deployments. We propose BudgetMem, a novel memory augmented architecture that learns what to remember rather than remembering everything. Our system combines selective memory policies with feature based salience scoring (entity density, TF-IDF, discourse markers, position bias) to decide which information merits storage under strict budget constraints. Unlike existing retrieval augmented generation (RAG) systems that store all chunks, BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval for efficient information access. Through comprehensive experiments on 700 question answer pairs across short (237 tokens) and long (5K-10K tokens) documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves remarkable results on long documents: only 1.0% F1 score degradation while saving 72.4% memory compared to baseline RAG. We validate our approach through budget sensitivity analysis (testing 7 budget ratios), naive baseline comparisons, and document length analysis, showing that BudgetMem's benefits increase with document length. Our work provides a practical pathway for deploying capable long context systems on modest hardware, democratizing access to advanced language understanding capabilities.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 43,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04939",
        "abs_url": "https://arxiv.org/abs/2511.04939",
        "pdf_url": "https://arxiv.org/pdf/2511.04939",
        "title": "Search Is Not Retrieval: Decoupling Semantic Matching from Contextual Assembly in RAG",
        "authors": [
            "Harshit Nainwani",
            "Hediyeh Baban"
        ],
        "comments": "22 pages, 2 figures, technical framework paper",
        "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)",
        "abstract": "Retrieval systems are essential to contemporary AI pipelines, although most confuse two separate processes: finding relevant information and giving enough context for reasoning. We introduce the Search-Is-Not-Retrieve (SINR) framework, a dual-layer architecture that distinguishes between fine-grained search representations and coarse-grained retrieval contexts. SINR enhances the composability, scalability, and context fidelity of retrieval systems by directly connecting small, semantically accurate search chunks to larger, contextually complete retrieve chunks, all without incurring extra processing costs. This design changes retrieval from a passive step to an active one, making the system architecture more like how people process information. We discuss the SINR framework's conceptual foundation, formal structure, implementation issues, and qualitative outcomes. This provides a practical foundation for the next generation of AI systems that use retrieval.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 44,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04949",
        "abs_url": "https://arxiv.org/abs/2511.04949",
        "pdf_url": "https://arxiv.org/pdf/2511.04949",
        "title": "DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning",
        "authors": [
            "Tharindu Fernando",
            "Clinton Fookes",
            "Sridha Sridharan"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
        "abstract": "Rapid advances in generative AI have led to increasingly realistic deepfakes, posing growing challenges for law enforcement and public trust. Existing passive deepfake detectors struggle to keep pace, largely due to their dependence on specific forgery artifacts, which limits their ability to generalize to new deepfake types. Proactive deepfake detection using watermarks has emerged to address the challenge of identifying high-quality synthetic media. However, these methods often struggle to balance robustness against benign distortions with sensitivity to malicious tampering. This paper introduces a novel deep learning framework that harnesses high-dimensional latent space representations and the Multi-Agent Adversarial Reinforcement Learning (MAARL) paradigm to develop a robust and adaptive watermarking approach. Specifically, we develop a learnable watermark embedder that operates in the latent space, capturing high-level image semantics, while offering precise control over message encoding and extraction. The MAARL paradigm empowers the learnable watermarking agent to pursue an optimal balance between robustness and fragility by interacting with a dynamic curriculum of benign and malicious image manipulations simulated by an adversarial attacker agent. Comprehensive evaluations on the CelebA and CelebA-HQ benchmarks reveal that our method consistently outperforms state-of-the-art approaches, achieving improvements of over 4.5% on CelebA and more than 5.3% on CelebA-HQ under challenging manipulation scenarios.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 45,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04962",
        "abs_url": "https://arxiv.org/abs/2511.04962",
        "pdf_url": "https://arxiv.org/pdf/2511.04962",
        "title": "Too Good to be Bad: On the Failure of LLMs to Role-Play Villains",
        "authors": [
            "Zihao Yi",
            "Qingxuan Jiang",
            "Ruotian Ma",
            "Xingyu Chen",
            "Qu Yang",
            "Mengru Wang",
            "Fanghua Ye",
            "Ying Shen",
            "Zhaopeng Tu",
            "Xiaolong Li",
            "Linus"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) are increasingly tasked with creative generation, including the simulation of fictional characters. However, their ability to portray non-prosocial, antagonistic personas remains largely unexamined. We hypothesize that the safety alignment of modern LLMs creates a fundamental conflict with the task of authentically role-playing morally ambiguous or villainous characters. To investigate this, we introduce the Moral RolePlay benchmark, a new dataset featuring a four-level moral alignment scale and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs with role-playing characters from moral paragons to pure villains. Our large-scale evaluation reveals a consistent, monotonic decline in role-playing fidelity as character morality decreases. We find that models struggle most with traits directly antithetical to safety principles, such as ``Deceitful'' and ``Manipulative'', often substituting nuanced malevolence with superficial aggression. Furthermore, we demonstrate that general chatbot proficiency is a poor predictor of villain role-playing ability, with highly safety-aligned models performing particularly poorly. Our work provides the first systematic evidence of this critical limitation, highlighting a key tension between model safety and creative fidelity. Our benchmark and findings pave the way for developing more nuanced, context-aware alignment methods.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 46,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04970",
        "abs_url": "https://arxiv.org/abs/2511.04970",
        "pdf_url": "https://arxiv.org/pdf/2511.04970",
        "title": "Learning Fourier shapes to probe the geometric world of deep neural networks",
        "authors": [
            "Jian Wang",
            "Yixing Yong",
            "Haixia Bi",
            "Lijun He",
            "Fan Li"
        ],
        "comments": "20 pages, 5 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "While both shape and texture are fundamental to visual recognition, research on deep neural networks (DNNs) has predominantly focused on the latter, leaving their geometric understanding poorly probed. Here, we show: first, that optimized shapes can act as potent semantic carriers, generating high-confidence classifications from inputs defined purely by their geometry; second, that they are high-fidelity interpretability tools that precisely isolate a model's salient regions; and third, that they constitute a new, generalizable adversarial paradigm capable of deceiving downstream visual tasks. This is achieved through an end-to-end differentiable framework that unifies a powerful Fourier series to parameterize arbitrary shapes, a winding number-based mapping to translate them into the pixel grid required by DNNs, and signal energy constraints that enhance optimization efficiency while ensuring physically plausible shapes. Our work provides a versatile framework for probing the geometric world of DNNs and opens new frontiers for challenging and understanding machine perception.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 47,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04995",
        "abs_url": "https://arxiv.org/abs/2511.04995",
        "pdf_url": "https://arxiv.org/pdf/2511.04995",
        "title": "Enhancing Public Speaking Skills in Engineering Students Through AI",
        "authors": [
            "Amol Harsh",
            "Brainerd Prince",
            "Siddharth Siddharth",
            "Deepan Raj Prabakar Muthirayan",
            "Kabir S Bhalla",
            "Esraaj Sarkar Gupta",
            "Siddharth Sahu"
        ],
        "comments": "",
        "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
        "abstract": "This research-to-practice full paper was inspired by the persistent challenge in effective communication among engineering students. Public speaking is a necessary skill for future engineers as they have to communicate technical knowledge with diverse stakeholders. While universities offer courses or workshops, they are unable to offer sustained and personalized training to students. Providing comprehensive feedback on both verbal and non-verbal aspects of public speaking is time-intensive, making consistent and individualized assessment impractical. This study integrates research on verbal and non-verbal cues in public speaking to develop an AI-driven assessment model for engineering students. Our approach combines speech analysis, computer vision, and sentiment detection into a multi-modal AI system that provides assessment and feedback. The model evaluates (1) verbal communication (pitch, loudness, pacing, intonation), (2) non-verbal communication (facial expressions, gestures, posture), and (3) expressive coherence, a novel integration ensuring alignment between speech and body language. Unlike previous systems that assess these aspects separately, our model fuses multiple modalities to deliver personalized, scalable feedback. Preliminary testing demonstrated that our AI-generated feedback was moderately aligned with expert evaluations. Among the state-of-the-art AI models evaluated, all of which were Large Language Models (LLMs), including Gemini and OpenAI models, Gemini Pro emerged as the best-performing, showing the strongest agreement with human annotators. By eliminating reliance on human evaluators, this AI-driven public speaking trainer enables repeated practice, helping students naturally align their speech with body language and emotion, crucial for impactful and professional communication.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 48,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.04998",
        "abs_url": "https://arxiv.org/abs/2511.04998",
        "pdf_url": "https://arxiv.org/pdf/2511.04998",
        "title": "BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records",
        "authors": [
            "Daniel S. Lee",
            "Mayra S. Haedo-Cruz",
            "Chen Jiang",
            "Oshin Miranda",
            "LiRong Wang"
        ],
        "comments": "20 pages, 2 figures, 6 tables, 2 supplementary figures, 4 supplementary tables, submitted to Journal of Biomedical Informatics on 6 Nov, 2025",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)",
        "abstract": "Transformer-based deep learning models have shown promise for disease risk prediction using electronic health records(EHRs), but modeling temporal dependencies remains a key challenge due to irregular visit intervals and lack of uniform structure. We propose a Bi-Positional Embedding Transformer Encoder or BiPETE for single-disease prediction, which integrates rotary positional embeddings to encode relative visit timing and sinusoidal embeddings to preserve visit order. Without relying on large-scale pretraining, BiPETE is trained on EHR data from two mental health cohorts-depressive disorder and post-traumatic stress disorder (PTSD)-to predict the risk of alcohol and substance use disorders (ASUD). BiPETE outperforms baseline models, improving the area under the precision-recall curve (AUPRC) by 34% and 50% in the depression and PTSD cohorts, respectively. An ablation study further confirms the effectiveness of the dual positional encoding strategy. We apply the Integrated Gradients method to interpret model predictions, identifying key clinical features associated with ASUD risk and protection, such as abnormal inflammatory, hematologic, and metabolic markers, as well as specific medications and comorbidities. Overall, these key clinical features identified by the attribution methods contribute to a deeper understanding of the risk assessment process and offer valuable clues for mitigating potential risks. In summary, our study presents a practical and interpretable framework for disease risk prediction using EHR data, which can achieve strong performance.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 49,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05000",
        "abs_url": "https://arxiv.org/abs/2511.05000",
        "pdf_url": "https://arxiv.org/pdf/2511.05000",
        "title": "Query Generation Pipeline with Enhanced Answerability Assessment for Financial Information Retrieval",
        "authors": [
            "Hyunkyu Kim",
            "Yeeun Yoo",
            "Youngjun Kwak"
        ],
        "comments": "Accepted(Oral) by ICAIF 2025. Hyunkyu Kim and Yeeun Yoo contributed equally to this work",
        "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)",
        "abstract": "As financial applications of large language models (LLMs) gain attention, accurate Information Retrieval (IR) remains crucial for reliable AI services. However, existing benchmarks fail to capture the complex and domain-specific information needs of real-world banking scenarios. Building domain-specific IR benchmarks is costly and constrained by legal restrictions on using real customer data. To address these challenges, we propose a systematic methodology for constructing domain-specific IR benchmarks through LLM-based query generation. As a concrete implementation of this methodology, our pipeline combines single and multi-document query generation with an enhanced and reasoning-augmented answerability assessment method, achieving stronger alignment with human judgments than prior approaches. Using this methodology, we construct KoBankIR, comprising 815 queries derived from 204 official banking documents. Our experiments show that existing retrieval models struggle with the complex multi-document queries in KoBankIR, demonstrating the value of our systematic approach for domain-specific benchmark construction and underscoring the need for improved retrieval techniques in financial domains.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 50,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05005",
        "abs_url": "https://arxiv.org/abs/2511.05005",
        "pdf_url": "https://arxiv.org/pdf/2511.05005",
        "title": "Multi-agent Coordination via Flow Matching",
        "authors": [
            "Dongsu Lee",
            "Daehee Lee",
            "Amy Zhang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)",
        "abstract": "This work presents MAC-Flow, a simple yet expressive framework for multi-agent coordination. We argue that requirements of effective coordination are twofold: (i) a rich representation of the diverse joint behaviors present in offline data and (ii) the ability to act efficiently in real time. However, prior approaches often sacrifice one for the other, i.e., denoising diffusion-based solutions capture complex coordination but are computationally slow, while Gaussian policy-based solutions are fast but brittle in handling multi-agent interaction. MAC-Flow addresses this trade-off by first learning a flow-based representation of joint behaviors, and then distilling it into decentralized one-step policies that preserve coordination while enabling fast execution. Across four different benchmarks, including $12$ environments and $34$ datasets, MAC-Flow alleviates the trade-off between performance and computational cost, specifically achieving about $\\boldsymbol{\\times14.5}$ faster inference compared to diffusion-based MARL methods, while maintaining good performance. At the same time, its inference speed is similar to that of prior Gaussian policy-based offline multi-agent reinforcement learning (MARL) methods.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 51,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05018",
        "abs_url": "https://arxiv.org/abs/2511.05018",
        "pdf_url": "https://arxiv.org/pdf/2511.05018",
        "title": "Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies",
        "authors": [
            "Prasoon Varshney",
            "Makesh Narsimhan Sreedhar",
            "Liwei Jiang",
            "Traian Rebedea",
            "Christopher Parisien"
        ],
        "comments": "Accepted at the Multi-Turn Interactions workshop at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025)",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) are typically aligned to a universal set of safety and usage principles intended for broad public acceptability. Yet, real-world applications of LLMs often take place within organizational ecosystems shaped by distinctive corporate policies, regulatory requirements, use cases, brand guidelines, and ethical commitments. This reality highlights the need for rigorous and comprehensive evaluation of LLMs with pluralistic alignment goals, an alignment paradigm that emphasizes adaptability to diverse user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE (PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs' capacity to adhere to pluralistic alignment specifications in multi-turn, interactive conversations. PBSUITE consists of (1) a diverse dataset of 300 realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic evaluation framework for stress-testing model compliance with custom behavioral specifications under adversarial conditions. Using PBSUITE, We find that leading open- and closed-source LLMs maintain robust adherence to behavioral policies in single-turn settings (less than 4% failure rates), but their compliance weakens substantially in multi-turn adversarial interactions (up to 84% failure rates). These findings highlight that existing model alignment and safety moderation methods fall short in coherently enforcing pluralistic behavioral policies in real-world LLM interactions. Our work contributes both the dataset and analytical framework to support future research toward robust and context-aware pluralistic alignment techniques.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 52,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05025",
        "abs_url": "https://arxiv.org/abs/2511.05025",
        "pdf_url": "https://arxiv.org/pdf/2511.05025",
        "title": "8bit-GPT: Exploring Human-AI Interaction on Obsolete Macintosh Operating Systems",
        "authors": [
            "Hala Sheta"
        ],
        "comments": "NeurIPS Creative AI Track 2025: Humanity",
        "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)",
        "abstract": "The proliferation of assistive chatbots offering efficient, personalized communication has driven widespread over-reliance on them for decision-making, information-seeking and everyday tasks. This dependence was found to have adverse consequences on information retention as well as lead to superficial emotional attachment. As such, this work introduces 8bit-GPT; a language model simulated on a legacy Macintosh Operating System, to evoke reflection on the nature of Human-AI interaction and the consequences of anthropomorphic rhetoric. Drawing on reflective design principles such as slow-technology and counterfunctionality, this work aims to foreground the presence of chatbots as a tool by defamiliarizing the interface and prioritizing inefficient interaction, creating a friction between the familiar and not.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 53,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05028",
        "abs_url": "https://arxiv.org/abs/2511.05028",
        "pdf_url": "https://arxiv.org/pdf/2511.05028",
        "title": "OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data",
        "authors": [
            "Dongjin Park",
            "Hasung Yeo",
            "Joon-Woo Lee"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Federated fine-tuning (FFT) adapts foundation models to decentralized data but remains fragile under heterogeneous client distributions due to local drift, i.e., client-level update divergences that induce systematic bias and amplified variance in the global model. Existing aggregation and personalization methods largely correct drift post hoc, which proves brittle under extreme non-IID conditions. We introduce OvA-LP, a minimalist framework that is, to our knowledge, the first explicitly designed to suppress drift at its source within the PEFT-based FFT paradigm. OvA-LP combines linear probing on a frozen encoder with a one-vs-all head and a simple two-stage procedure, preserving pretrained feature geometry and decoupling logits to prevent the mechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over shard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of its IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1% (PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains resilience under both symmetric and asymmetric label noise. In addition, precomputing encoder features makes per-round cost nearly independent of encoder size. Together, these results demonstrate that OvA-LP provides a principled and efficient basis for robust FFT under heterogeneity.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 54,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05039",
        "abs_url": "https://arxiv.org/abs/2511.05039",
        "pdf_url": "https://arxiv.org/pdf/2511.05039",
        "title": "PECL: A Heterogeneous Parallel Multi-Domain Network for Radar-Based Human Activity Recognition",
        "authors": [
            "Jiuqi Yan",
            "Chendong Xu",
            "Dongyu Liu"
        ],
        "comments": "",
        "subjects": "Signal Processing (eess.SP); Artificial Intelligence (cs.AI)",
        "abstract": "Radar systems are increasingly favored for medical applications because they provide non-intrusive monitoring with high privacy and robustness to lighting conditions. However, existing research typically relies on single-domain radar signals and overlooks the temporal dependencies inherent in human activity, which complicates the classification of similar actions. To address this issue, we designed the Parallel-EfficientNet-CBAM-LSTM (PECL) network to process data in three complementary domains: Range-Time, Doppler-Time, and Range-Doppler. PECL combines a channel-spatial attention module and temporal units to capture more features and dynamic dependencies during action sequences, improving both accuracy and robustness. The experimental results show that PECL achieves an accuracy of 96.16% on the same dataset, outperforming existing methods by at least 4.78%. PECL also performs best in distinguishing between easily confused actions. Despite its strong performance, PECL maintains moderate model complexity, with 23.42M parameters and 1324.82M FLOPs. Its parameter-efficient design further reduces computational cost.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 55,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05040",
        "abs_url": "https://arxiv.org/abs/2511.05040",
        "pdf_url": "https://arxiv.org/pdf/2511.05040",
        "title": "UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian",
        "authors": [
            "Mykyta Syromiatnikov",
            "Victoria Ruvinskaya"
        ],
        "comments": "8 pages, 5 figures. XI International conference \"Informatics. Culture. Technique.\" (2025)",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)",
        "abstract": "Evaluating the real capabilities of large language models in low-resource languages still represents a challenge, as many existing benchmarks focus on widespread tasks translated from English or evaluate only simple language understanding. This paper introduces UA-Code-Bench, a new open-source benchmark established for a thorough evaluation of language models' code generation and competitive programming problem-solving abilities in Ukrainian. The benchmark comprises 500 problems from the Eolymp platform, evenly distributed across five complexity levels from very easy to very hard. A diverse set of 13 leading proprietary and open-source models, generating Python solutions based on a one-shot prompt, was evaluated via the dedicated Eolymp environment against hidden tests, ensuring code correctness. The obtained results reveal that even top-performing models, such as OpenAI o3 and GPT-5, solve only half of the problems, highlighting the challenge of code generation in low-resource natural language. Furthermore, this research presents a comprehensive analysis of performance across various difficulty levels, as well as an assessment of solution uniqueness and computational efficiency, measured by both elapsed time and memory consumption of the generated solutions. In conclusion, this work demonstrates the value of competitive programming benchmarks in evaluating large language models, especially in underrepresented languages. It also paves the way for future research on multilingual code generation and reasoning-enhanced models. The benchmark, data parsing, preparation, code generation, and evaluation scripts are available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 56,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05053",
        "abs_url": "https://arxiv.org/abs/2511.05053",
        "pdf_url": "https://arxiv.org/pdf/2511.05053",
        "title": "Accelerating HDC-CNN Hybrid Models Using Custom Instructions on RISC-V GPUs",
        "authors": [
            "Wakuto Matsumi",
            "Riaz-Ul-Haque Mian"
        ],
        "comments": "",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Graphics (cs.GR)",
        "abstract": "Machine learning based on neural networks has advanced rapidly, but the high energy consumption required for training and inference remains a major challenge. Hyperdimensional Computing (HDC) offers a lightweight, brain-inspired alternative that enables high parallelism but often suffers from lower accuracy on complex visual tasks. To overcome this, hybrid accelerators combining HDC and Convolutional Neural Networks (CNNs) have been proposed, though their adoption is limited by poor generalizability and programmability. The rise of open-source RISC-V architectures has created new opportunities for domain-specific GPU design. Unlike traditional proprietary GPUs, emerging RISC-V-based GPUs provide flexible, programmable platforms suitable for custom computation models such as HDC. In this study, we design and implement custom GPU instructions optimized for HDC operations, enabling efficient processing for hybrid HDC-CNN workloads. Experimental results using four types of custom HDC instructions show a performance improvement of up to 56.2 times in microbenchmark tests, demonstrating the potential of RISC-V GPUs for energy-efficient, high-performance computing.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 57,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05073",
        "abs_url": "https://arxiv.org/abs/2511.05073",
        "pdf_url": "https://arxiv.org/pdf/2511.05073",
        "title": "Deep learning models are vulnerable, but adversarial examples are even more vulnerable",
        "authors": [
            "Jun Li",
            "Yanwei Xu",
            "Keran Li",
            "Xiaoli Zhang"
        ],
        "comments": "25 pages,12 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
        "abstract": "Understanding intrinsic differences between adversarial examples and clean samples is key to enhancing DNN robustness and detection against adversarial attacks. This study first empirically finds that image-based adversarial examples are notably sensitive to occlusion. Controlled experiments on CIFAR-10 used nine canonical attacks (e.g., FGSM, PGD) to generate adversarial examples, paired with original samples for evaluation. We introduce Sliding Mask Confidence Entropy (SMCE) to quantify model confidence fluctuation under occlusion. Using 1800+ test images, SMCE calculations supported by Mask Entropy Field Maps and statistical distributions show adversarial examples have significantly higher confidence volatility under occlusion than originals. Based on this, we propose Sliding Window Mask-based Adversarial Example Detection (SWM-AED), which avoids catastrophic overfitting of conventional adversarial training. Evaluations across classifiers and attacks on CIFAR-10 demonstrate robust performance, with accuracy over 62% in most cases and up to 96.5%.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 58,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05131",
        "abs_url": "https://arxiv.org/abs/2511.05131",
        "pdf_url": "https://arxiv.org/pdf/2511.05131",
        "title": "DL101 Neural Network Outputs and Loss Functions",
        "authors": [
            "Fernando Berzal"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)",
        "abstract": "The loss function used to train a neural network is strongly connected to its output layer from a statistical point of view. This technical report analyzes common activation functions for a neural network output layer, like linear, sigmoid, ReLU, and softmax, detailing their mathematical properties and their appropriate use cases. A strong statistical justification exists for the selection of the suitable loss function for training a deep learning model. This report connects common loss functions such as Mean Squared Error (MSE), Mean Absolute Error (MAE), and various Cross-Entropy losses to the statistical principle of Maximum Likelihood Estimation (MLE). Choosing a specific loss function is equivalent to assuming a specific probability distribution for the model output, highlighting the link between these functions and the Generalized Linear Models (GLMs) that underlie network output layers. Additional scenarios of practical interest are also considered, such as alternative output encodings, constrained outputs, and distributions with heavy tails.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 59,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05156",
        "abs_url": "https://arxiv.org/abs/2511.05156",
        "pdf_url": "https://arxiv.org/pdf/2511.05156",
        "title": "SmartSecChain-SDN: A Blockchain-Integrated Intelligent Framework for Secure and Efficient Software-Defined Networks",
        "authors": [
            "Azhar Hussain Mozumder",
            "M. John Basha",
            "Chayapathi A. R"
        ],
        "comments": "20 pages, 12 figures",
        "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)",
        "abstract": "With more and more existing networks being transformed to Software-Defined Networking (SDN), they need to be more secure and demand smarter ways of traffic control. This work, SmartSecChain-SDN, is a platform that combines machine learning based intrusion detection, blockchain-based storage of logs, and application-awareness-based priority in SDN networks. To detect network intrusions in a real-time, precision and low-false positives setup, the framework utilizes the application of advanced machine learning algorithms, namely Random Forest, XGBoost, CatBoost, and CNN-BiLSTM. SmartSecChain-SDN is based on the Hyperledger Fabric, which is a permissioned blockchain technology, to provide secure, scalable, and privacy-preserving storage and, thus, guarantee that the Intrusion Detection System (IDS) records cannot be altered and can be analyzed comprehensively. The system also has Quality of Service (QoS) rules and traffic shaping based on applications, which enables prioritization of critical services, such as VoIP, video conferencing, and business applications, as well as de-prioritization of non-essential traffic, such as downloads and updates. Mininet can simulate real-time SDN scenarios because it is used to prototype whole architectures. It is also compatible with controllers OpenDaylight and Ryu. It has tested the framework using the InSDN dataset and proved that it can identify different kinds of cyberattacks and handle bandwidth allocation efficiently under circumstances of resource constraints. SmartSecChain-SDN comprehensively addresses SDN system protection, securing and enhancing. The proposed study offers an innovative, extensible way to improve cybersecurity, regulatory compliance, and the administration of next-generation programmable networks.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 60,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05165",
        "abs_url": "https://arxiv.org/abs/2511.05165",
        "pdf_url": "https://arxiv.org/pdf/2511.05165",
        "title": "Generating Software Architecture Description from Source Code using Reverse Engineering and Large Language Model",
        "authors": [
            "Ahmad Hatahet",
            "Christoph Knieke",
            "Andreas Rausch"
        ],
        "comments": "",
        "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
        "abstract": "Software Architecture Descriptions (SADs) are essential for managing the inherent complexity of modern software systems. They enable high-level architectural reasoning, guide design decisions, and facilitate effective communication among diverse stakeholders. However, in practice, SADs are often missing, outdated, or poorly aligned with the system's actual implementation. Consequently, developers are compelled to derive architectural insights directly from source code-a time-intensive process that increases cognitive load, slows new developer onboarding, and contributes to the gradual degradation of clarity over the system's lifetime. To address these issues, we propose a semi-automated generation of SADs from source code by integrating reverse engineering (RE) techniques with a Large Language Model (LLM). Our approach recovers both static and behavioral architectural views by extracting a comprehensive component diagram, filtering architecturally significant elements (core components) via prompt engineering, and generating state machine diagrams to model component behavior based on underlying code logic with few-shots prompting. This resulting views representation offer a scalable and maintainable alternative to traditional manual architectural documentation. This methodology, demonstrated using C++ examples, highlights the potent capability of LLMs to: 1) abstract the component diagram, thereby reducing the reliance on human expert involvement, and 2) accurately represent complex software behaviors, especially when enriched with domain-specific knowledge through few-shot prompting. These findings suggest a viable path toward significantly reducing manual effort while enhancing system understanding and long-term maintainability.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 61,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05171",
        "abs_url": "https://arxiv.org/abs/2511.05171",
        "pdf_url": "https://arxiv.org/pdf/2511.05171",
        "title": "Model Merging Improves Zero-Shot Generalization in Bioacoustic Foundation Models",
        "authors": [
            "Davide Marincione",
            "Donato Crisostomi",
            "Roberto Dessi",
            "Emanuele Rodolà",
            "Emanuele Rossi"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Sound (cs.SD)",
        "abstract": "Foundation models capable of generalizing across species and tasks represent a promising new frontier in bioacoustics, with NatureLM being one of the most prominent examples. While its domain-specific fine-tuning yields strong performance on bioacoustic benchmarks, we observe that it also introduces trade-offs in instruction-following flexibility. For instance, NatureLM achieves high accuracy when prompted for either the common or scientific name individually, but its accuracy drops significantly when both are requested in a single prompt. We address this by applying a simple model merging strategy that interpolates NatureLM with its base language model, recovering instruction-following capabilities with minimal loss of domain expertise. Finally, we show that the merged model exhibits markedly stronger zero-shot generalization, achieving over a 200% relative improvement and setting a new state-of-the-art in closed-set zero-shot classification of unseen species.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 62,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05179",
        "abs_url": "https://arxiv.org/abs/2511.05179",
        "pdf_url": "https://arxiv.org/pdf/2511.05179",
        "title": "No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs with Graph Neural Networks and Foundation Models",
        "authors": [
            "Ragini Gupta",
            "Naman Raina",
            "Bo Chen",
            "Li Chen",
            "Claudiu Danilov",
            "Josh Eckhardt",
            "Keyshla Bernard",
            "Klara Nahrstedt"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)",
        "abstract": "Modern IoT deployments for environmental sensing produce high volume spatiotemporal data to support downstream tasks such as forecasting, typically powered by machine learning models. While existing filtering and strategic deployment techniques optimize collected data volume at the edge, they overlook how variations in sampling frequencies and spatial coverage affect downstream model performance. In many forecasting models, incorporating data from additional sensors denoise predictions by providing broader spatial contexts. This interplay between sampling frequency, spatial coverage and different forecasting model architectures remain underexplored. This work presents a systematic study of forecasting models - classical models (VAR), neural networks (GRU, Transformer), spatio-temporal graph neural networks (STGNNs), and time series foundation models (TSFMs: Chronos Moirai, TimesFM) under varying spatial sensor nodes density and sampling intervals using real-world temperature data in a wireless sensor network. Our results show that STGNNs are effective when sensor deployments are sparse and sampling rate is moderate, leveraging spatial correlations via encoded graph structure to compensate for limited coverage. In contrast, TSFMs perform competitively at high frequencies but degrade when spatial coverage from neighboring sensors is reduced. Crucially, the multivariate TSFM Moirai outperforms all models by natively learning cross-sensor dependencies. These findings offer actionable insights for building efficient forecasting pipelines in spatio-temporal systems. All code for model configurations, training, dataset, and logs are open-sourced for reproducibility: this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 63,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05250",
        "abs_url": "https://arxiv.org/abs/2511.05250",
        "pdf_url": "https://arxiv.org/pdf/2511.05250",
        "title": "Accurate online action and gesture recognition system using detectors and Deep SPD Siamese Networks",
        "authors": [
            "Mohamed Sanim Akremi",
            "Rim Slama",
            "Hedi Tabia"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)",
        "abstract": "Online continuous motion recognition is a hot topic of research since it is more practical in real life application cases. Recently, Skeleton-based approaches have become increasingly popular, demonstrating the power of using such 3D temporal data. However, most of these works have focused on segment-based recognition and are not suitable for the online scenarios. In this paper, we propose an online recognition system for skeleton sequence streaming composed from two main components: a detector and a classifier, which use a Semi-Positive Definite (SPD) matrix representation and a Siamese network. The powerful statistical representations for the skeletal data given by the SPD matrices and the learning of their semantic similarity by the Siamese network enable the detector to predict time intervals of the motions throughout an unsegmented sequence. In addition, they ensure the classifier capability to recognize the motion in each predicted interval. The proposed detector is flexible and able to identify the kinetic state continuously. We conduct extensive experiments on both hand gesture and body action recognition benchmarks to prove the accuracy of our online recognition system which in most cases outperforms state-of-the-art performances.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 64,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05254",
        "abs_url": "https://arxiv.org/abs/2511.05254",
        "pdf_url": "https://arxiv.org/pdf/2511.05254",
        "title": "A Gate-Based Quantum Genetic Algorithm for Real-Valued Global Optimization",
        "authors": [
            "Leandro C. Souza",
            "Laurent E. Dardenne",
            "Renato Portugal"
        ],
        "comments": "16 pages",
        "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)",
        "abstract": "We propose a gate-based Quantum Genetic Algorithm (QGA) for real-valued global optimization. In this model, individuals are represented by quantum circuits whose measurement outcomes are decoded into real-valued vectors through binary discretization. Evolutionary operators act directly on circuit structures, allowing mutation and crossover to explore the space of gate-based encodings. Both fixed-depth and variable-depth variants are introduced, enabling either uniform circuit complexity or adaptive structural evolution. Fitness is evaluated through quantum sampling, using the mean decoded output of measurement outcomes as the argument of the objective function. To isolate the impact of quantum resources, we compare gate sets with and without the Hadamard gate, showing that superposition consistently improves convergence and robustness across benchmark functions such as the Rastrigin function. Furthermore, we demonstrate that introducing pairwise inter-individual entanglement in the population accelerates early convergence, revealing that quantum correlations among individuals provide an additional optimization advantage. Together, these results show that both superposition and entanglement enhance the search dynamics of evolutionary quantum algorithms, establishing gate-based QGAs as a promising framework for quantum-enhanced global optimization.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 65,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05265",
        "abs_url": "https://arxiv.org/abs/2511.05265",
        "pdf_url": "https://arxiv.org/pdf/2511.05265",
        "title": "An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones",
        "authors": [
            "Taihelong Zeng",
            "Yun Lin",
            "Yuhe Shi",
            "Yan Li",
            "Zhiqing Wei",
            "Xuanru Ji"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "The emergence of truck-drone collaborative systems in last-mile logistics has positioned the Traveling Salesman Problem with Drones (TSP-D) as a pivotal extension of classical routing optimization, where synchronized vehicle coordination promises substantial operational efficiency and reduced environmental impact, yet introduces NP-hard combinatorial complexity beyond the reach of conventional optimization paradigms. Deep reinforcement learning offers a theoretically grounded framework to address TSP-D's inherent challenges through self-supervised policy learning and adaptive decision-making. This study proposes a hierarchical Actor-Critic deep reinforcement learning framework for solving the TSP-D problem. The architecture consists of two primary components: a Transformer-inspired encoder and an efficient Minimal Gated Unit decoder. The encoder incorporates a novel, optimized k-nearest neighbors sparse attention mechanism specifically for focusing on relevant spatial relationships, further enhanced by the integration of global node features. The Minimal Gated Unit decoder processes these encoded representations to efficiently generate solution sequences. The entire framework operates within an asynchronous advantage actor-critic paradigm. Experimental results show that, on benchmark TSP-D instances of various scales (N=10 to 100), the proposed model can obtain competitive or even superior solutions in shorter average computation times compared to high-performance heuristic algorithms and existing reinforcement learning methods. Moreover, compared to advanced reinforcement learning algorithm benchmarks, the proposed framework significantly reduces the total training time required while achieving superior final performance, highlighting its notable advantage in training efficiency.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 66,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05266",
        "abs_url": "https://arxiv.org/abs/2511.05266",
        "pdf_url": "https://arxiv.org/pdf/2511.05266",
        "title": "Integrating Score-Based Diffusion Models with Machine Learning-Enhanced Localization for Advanced Data Assimilation in Geological Carbon Storage",
        "authors": [
            "Gabriel Serrão Seabra",
            "Nikolaj T. Mücke",
            "Vinicius Luiz Santos Silva",
            "Alexandre A. Emerick",
            "Denis Voskov",
            "Femke Vossepoel"
        ],
        "comments": "Corresponding author: Gabriel Serrão Seabra",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Accurate characterization of subsurface heterogeneity is important for the safe and effective implementation of geological carbon storage (GCS) projects. This paper explores how machine learning methods can enhance data assimilation for GCS with a framework that integrates score-based diffusion models with machine learning-enhanced localization in channelized reservoirs during CO$_2$ injection. We employ a machine learning-enhanced localization framework that uses large ensembles ($N_s = 5000$) with permeabilities generated by the diffusion model and states computed by simple ML algorithms to improve covariance estimation for the Ensemble Smoother with Multiple Data Assimilation (ESMDA). We apply ML algorithms to a prior ensemble of channelized permeability fields, generated with the geostatistical model FLUVSIM. Our approach is applied on a CO$_2$ injection scenario simulated using the Delft Advanced Research Terra Simulator (DARTS). Our ML-based localization maintains significantly more ensemble variance than when localization is not applied, while achieving comparable data-matching quality. This framework has practical implications for GCS projects, helping improve the reliability of uncertainty quantification for risk assessment.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 67,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05269",
        "abs_url": "https://arxiv.org/abs/2511.05269",
        "pdf_url": "https://arxiv.org/pdf/2511.05269",
        "title": "TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems",
        "authors": [
            "Ishan Kavathekar",
            "Hemang Jain",
            "Ameya Rathod",
            "Ponnurangam Kumaraguru",
            "Tanuja Ganu"
        ],
        "comments": "Accepted at ICML 2025 MAS Workshop. This version includes additional experiments and analysis",
        "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)",
        "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities as autonomous agents through tool use, planning, and decision-making abilities, leading to their widespread adoption across diverse tasks. As task complexity grows, multi-agent LLM systems are increasingly used to solve problems collaboratively. However, safety and security of these systems remains largely under-explored. Existing benchmarks and datasets predominantly focus on single-agent settings, failing to capture the unique vulnerabilities of multi-agent dynamics and co-ordination. To address this gap, we introduce $\\textbf{T}$hreats and $\\textbf{A}$ttacks in $\\textbf{M}$ulti-$\\textbf{A}$gent $\\textbf{S}$ystems ($\\textbf{TAMAS}$), a benchmark designed to evaluate the robustness and safety of multi-agent LLM systems. TAMAS includes five distinct scenarios comprising 300 adversarial instances across six attack types and 211 tools, along with 100 harmless tasks. We assess system performance across ten backbone LLMs and three agent interaction configurations from Autogen and CrewAI frameworks, highlighting critical challenges and failure modes in current multi-agent deployments. Furthermore, we introduce Effective Robustness Score (ERS) to assess the tradeoff between safety and task effectiveness of these frameworks. Our findings show that multi-agent systems are highly vulnerable to adversarial attacks, underscoring the urgent need for stronger defenses. TAMAS provides a foundation for systematically studying and improving the safety of multi-agent LLM systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 68,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05299",
        "abs_url": "https://arxiv.org/abs/2511.05299",
        "pdf_url": "https://arxiv.org/pdf/2511.05299",
        "title": "LiveStar: Live Streaming Assistant for Real-World Online Video Understanding",
        "authors": [
            "Zhenyu Yang",
            "Kairui Zhang",
            "Yuhang Hu",
            "Bing Wang",
            "Shengsheng Qian",
            "Bin Wen",
            "Fan Yang",
            "Tingting Gao",
            "Weiming Dong",
            "Changsheng Xu"
        ],
        "comments": "NeurIPS 2025 Accepted",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
        "abstract": "Despite significant progress in Video Large Language Models (Video-LLMs) for offline video understanding, existing online Video-LLMs typically struggle to simultaneously process continuous frame-by-frame inputs and determine optimal response timing, often compromising real-time responsiveness and narrative coherence. To address these limitations, we introduce LiveStar, a pioneering live streaming assistant that achieves always-on proactive responses through adaptive streaming decoding. Specifically, LiveStar incorporates: (1) a training strategy enabling incremental video-language alignment for variable-length video streams, preserving temporal consistency across dynamically evolving frame sequences; (2) a response-silence decoding framework that determines optimal proactive response timing via a single forward pass verification; (3) memory-aware acceleration via peak-end memory compression for online inference on 10+ minute videos, combined with streaming key-value cache to achieve 1.53x faster inference. We also construct an OmniStar dataset, a comprehensive dataset for training and benchmarking that encompasses 15 diverse real-world scenarios and 5 evaluation tasks for online video understanding. Extensive experiments across three benchmarks demonstrate LiveStar's state-of-the-art performance, achieving an average 19.5% improvement in semantic correctness with 18.1% reduced timing difference compared to existing online Video-LLMs, while improving FPS by 12.0% across all five OmniStar tasks. Our model and dataset can be accessed at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 69,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05320",
        "abs_url": "https://arxiv.org/abs/2511.05320",
        "pdf_url": "https://arxiv.org/pdf/2511.05320",
        "title": "What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions",
        "authors": [
            "Klára Bendová",
            "Tomáš Knap",
            "Jan Černý",
            "Vojtěch Pour",
            "Jaromir Savelka",
            "Ivana Kvapilíková",
            "Jakub Drápal"
        ],
        "comments": "Paper accepted to the proceedings of ASAIL 2025 Workshop under ICAIL conference for publication. Paper contains 6 pages (references included) and 2 appendices. It contains 8 tables, no figures",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Criminal justice administrative data contain only a limited amount of information about the committed offense. However, there is an unused source of extensive information in continental European courts' decisions: descriptions of criminal behaviors in verdicts by which offenders are found guilty. In this paper, we study the feasibility of extracting these descriptions from publicly available court decisions from Slovakia. We use two different approaches for retrieval: regular expressions and large language models (LLMs). Our baseline was a simple method employing regular expressions to identify typical words occurring before and after the description. The advanced regular expression approach further focused on \"sparing\" and its normalization (insertion of spaces between individual letters), typical for delineating the description. The LLM approach involved prompting the Gemini Flash 2.0 model to extract the descriptions using predefined instructions. Although the baseline identified descriptions in only 40.5% of verdicts, both methods significantly outperformed it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and 99.5% when combined. Evaluation by law students showed that both advanced methods matched human annotations in about 90% of cases, compared to just 34.5% for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of instances, and a combination of advanced regular expressions with LLMs reached 92%.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 70,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05350",
        "abs_url": "https://arxiv.org/abs/2511.05350",
        "pdf_url": "https://arxiv.org/pdf/2511.05350",
        "title": "Perceptually Aligning Representations of Music via Noise-Augmented Autoencoders",
        "authors": [
            "Mathias Rose Bjare",
            "Giorgia Cantisani",
            "Marco Pasini",
            "Stefan Lattner",
            "Gerhard Widmer"
        ],
        "comments": "Accepted at NeurIPS 2025 - AI for Music Workshop, 11 pages, 5 figures, 1 table",
        "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI)",
        "abstract": "We argue that training autoencoders to reconstruct inputs from noised versions of their encodings, when combined with perceptual losses, yields encodings that are structured according to a perceptual hierarchy. We demonstrate the emergence of this hierarchical structure by showing that, after training an audio autoencoder in this manner, perceptually salient information is captured in coarser representation structures than with conventional training. Furthermore, we show that such perceptual hierarchies improve latent diffusion decoding in the context of estimating surprisal in music pitches and predicting EEG-brain responses to music listening. Pretrained weights are available on this http URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 71,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05361",
        "abs_url": "https://arxiv.org/abs/2511.05361",
        "pdf_url": "https://arxiv.org/pdf/2511.05361",
        "title": "A multimodal multiplex of the mental lexicon for multilingual individuals",
        "authors": [
            "Maria Huynh",
            "Wilder C. Rodrigues"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
        "abstract": "Historically, bilingualism was often perceived as an additional cognitive load that could hinder linguistic and intellectual development. However, over the last three decades, this view has changed considerably. Numerous studies have aimed to model and understand the architecture of the bilingual word recognition system Dijkstra and van Heuven (2002), investigating how parallel activation operates in the brain and how one language influences another Kroll et al. (2015). Increasingly, evidence suggests that multilinguals, individuals who speak three or more languages, can perform better than monolinguals in various linguistic and cognitive tasks, such as learning an additional language Abu-Rabia and Sanitsky (2010). This research proposal focuses on the study of the mental lexicon and how it may be structured in individuals who speak multiple languages. Building on the work of Stella et al. (2018), who investigated explosive learning in humans using a multiplex model of the mental lexicon, and the Bilingual Interactive Activation (BIA+) framework proposed by Dijkstra and van Heuven (2002), the present study applies the same multilayer network principles introduced by Kivela et al. (2014). Our experimental design extends previous research by incorporating multimodality into the multiplex model, introducing an additional layer that connects visual inputs to their corresponding lexical representations across the multilingual layers of the mental lexicon. In this research, we aim to explore how a heritage language influences the acquisition of another language. Specifically, we ask: Does the presence of visual input in a translation task influence participants' proficiency and accuracy compared to text-only conditions?",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 72,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05363",
        "abs_url": "https://arxiv.org/abs/2511.05363",
        "pdf_url": "https://arxiv.org/pdf/2511.05363",
        "title": "AI Literacy for Community Colleges: Instructors' Perspectives on Scenario-Based and Interactive Approaches to Teaching AI",
        "authors": [
            "Aparna Maya Warrier",
            "Arav Agarwal",
            "Jaromir Savelka",
            "Christopher A Bogart",
            "Heather Burte"
        ],
        "comments": "",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)",
        "abstract": "This research category full paper investigates how community college instructors evaluate interactive, no-code AI literacy resources designed for non-STEM learners. As artificial intelligence becomes increasingly integrated into everyday technologies, AI literacy - the ability to evaluate AI systems, communicate with them, and understand their broader impacts - has emerged as a critical skill across disciplines. Yet effective, scalable approaches for teaching these concepts in higher education remain limited, particularly for students outside STEM fields. To address this gap, we developed AI User, an interactive online curriculum that introduces core AI concepts through scenario - based activities set in real - world contexts. This study presents findings from four focus groups with instructors who engaged with AI User materials and participated in structured feedback activities. Thematic analysis revealed that instructors valued exploratory tasks that simulated real - world AI use cases and fostered experimentation, while also identifying challenges related to scaffolding, accessibility, and multi-modal support. A ranking task for instructional support materials showed a strong preference for interactive demonstrations over traditional educational materials like conceptual guides or lecture slides. These findings offer insights into instructor perspectives on making AI concepts more accessible and relevant for broad learner audiences. They also inform the design of AI literacy tools that align with diverse teaching contexts and support critical engagement with AI in higher education.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 73,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05385",
        "abs_url": "https://arxiv.org/abs/2511.05385",
        "pdf_url": "https://arxiv.org/pdf/2511.05385",
        "title": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework",
        "authors": [
            "Chao Zhang",
            "Yuhao Wang",
            "Derong Xu",
            "Haoxin Zhang",
            "Yuanjie Lyu",
            "Yuhao Chen",
            "Shuochen Liu",
            "Tong Xu",
            "Xiangyu Zhao",
            "Yan Gao",
            "Yao Hu",
            "Enhong Chen"
        ],
        "comments": "32 pages",
        "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)",
        "abstract": "Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment Large Language Models' (LLMs) reliability. For flexibility, agentic RAG employs autonomous, multi-round retrieval and reasoning to resolve queries. Although recent agentic RAG has improved via reinforcement learning, they often incur substantial token overhead from search and reasoning processes. This trade-off prioritizes accuracy over efficiency. To address this issue, this work proposes TeaRAG, a token-efficient agentic RAG framework capable of compressing both retrieval content and reasoning steps. 1) First, the retrieved content is compressed by augmenting chunk-based semantic retrieval with a graph retrieval using concise triplets. A knowledge association graph is then built from semantic similarity and co-occurrence. Finally, Personalized PageRank is leveraged to highlight key knowledge within this graph, reducing the number of tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative Process-aware Direct Preference Optimization (IP-DPO) is proposed. Specifically, our reward function evaluates the knowledge sufficiency by a knowledge matching mechanism, while penalizing excessive reasoning steps. This design can produce high-quality preference-pair datasets, supporting iterative DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 74,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05396",
        "abs_url": "https://arxiv.org/abs/2511.05396",
        "pdf_url": "https://arxiv.org/pdf/2511.05396",
        "title": "Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction",
        "authors": [
            "Yiting He",
            "Zhishuai Liu",
            "Weixin Wang",
            "Pan Xu"
        ],
        "comments": "53 pages, 6 figures, 3 tables. Published in Proceedings of the 42nd International Conference on Machine Learning (ICML 2025)",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Machine Learning (stat.ML)",
        "abstract": "Off-dynamics reinforcement learning (RL), where training and deployment transition dynamics are different, can be formulated as learning in a robust Markov decision process (RMDP) where uncertainties in transition dynamics are imposed. Existing literature mostly assumes access to generative models allowing arbitrary state-action queries or pre-collected datasets with a good state coverage of the deployment environment, bypassing the challenge of exploration. In this work, we study a more realistic and challenging setting where the agent is limited to online interaction with the training environment. To capture the intrinsic difficulty of exploration in online RMDPs, we introduce the supremal visitation ratio, a novel quantity that measures the mismatch between the training dynamics and the deployment dynamics. We show that if this ratio is unbounded, online learning becomes exponentially hard. We propose the first computationally efficient algorithm that achieves sublinear regret in online RMDPs with $f$-divergence based transition uncertainties. We also establish matching regret lower bounds, demonstrating that our algorithm achieves optimal dependence on both the supremal visitation ratio and the number of interaction episodes. Finally, we validate our theoretical results through comprehensive numerical experiments.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 75,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05399",
        "abs_url": "https://arxiv.org/abs/2511.05399",
        "pdf_url": "https://arxiv.org/pdf/2511.05399",
        "title": "Robust Neural Audio Fingerprinting using Music Foundation Models",
        "authors": [
            "Shubhr Singh",
            "Kiran Bhat",
            "Xavier Riley",
            "Benjamin Resnick",
            "John Thickstun",
            "Walter De Brouwer"
        ],
        "comments": "",
        "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI)",
        "abstract": "The proliferation of distorted, compressed, and manipulated music on modern media platforms like TikTok motivates the development of more robust audio fingerprinting techniques to identify the sources of musical recordings. In this paper, we develop and evaluate new neural audio fingerprinting techniques with the aim of improving their robustness. We make two contributions to neural fingerprinting methodology: (1) we use a pretrained music foundation model as the backbone of the neural architecture and (2) we expand the use of data augmentation to train fingerprinting models under a wide variety of audio manipulations, including time streching, pitch modulation, compression, and filtering. We systematically evaluate our methods in comparison to two state-of-the-art neural fingerprinting models: NAFP and GraFPrint. Results show that fingerprints extracted with music foundation models (e.g., MuQ, MERT) consistently outperform models trained from scratch or pretrained on non-musical audio. Segment-level evaluation further reveals their capability to accurately localize fingerprint matches, an important practical feature for catalog management.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 76,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05420",
        "abs_url": "https://arxiv.org/abs/2511.05420",
        "pdf_url": "https://arxiv.org/pdf/2511.05420",
        "title": "ProDER: A Continual Learning Approach for Fault Prediction in Evolving Smart Grids",
        "authors": [
            "Emad Efatinasab",
            "Nahal Azadi",
            "Davide Dalle Pezze",
            "Gian Antonio Susto",
            "Chuadhry Mujeeb Ahmed",
            "Mirco Rampazzo"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "As smart grids evolve to meet growing energy demands and modern operational challenges, the ability to accurately predict faults becomes increasingly critical. However, existing AI-based fault prediction models struggle to ensure reliability in evolving environments where they are required to adapt to new fault types and operational zones. In this paper, we propose a continual learning (CL) framework in the smart grid context to evolve the model together with the environment. We design four realistic evaluation scenarios grounded in class-incremental and domain-incremental learning to emulate evolving grid conditions. We further introduce Prototype-based Dark Experience Replay (ProDER), a unified replay-based approach that integrates prototype-based feature regularization, logit distillation, and a prototype-guided replay memory. ProDER achieves the best performance among tested CL techniques, with only a 0.045 accuracy drop for fault type prediction and 0.015 for fault zone prediction. These results demonstrate the practicality of CL for scalable, real-world fault prediction in smart grids.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 77,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05430",
        "abs_url": "https://arxiv.org/abs/2511.05430",
        "pdf_url": "https://arxiv.org/pdf/2511.05430",
        "title": "\"I Like That You Have to Poke Around\": Instructors on How Experiential Approaches to AI Literacy Spark Inquiry and Critical Thinking",
        "authors": [
            "Aparna Maya Warrier",
            "Arav Agarwal",
            "Jaromir Savelka",
            "Christopher Bogart",
            "Heather Burte"
        ],
        "comments": "",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)",
        "abstract": "As artificial intelligence (AI) increasingly shapes decision-making across domains, there is a growing need to support AI literacy among learners beyond computer science. However, many current approaches rely on programming-heavy tools or abstract lecture-based content, limiting accessibility for non-STEM audiences. This paper presents findings from a study of AI User, a modular, web-based curriculum that teaches core AI concepts through interactive, no-code projects grounded in real-world scenarios. The curriculum includes eight projects; this study focuses on instructor feedback on Projects 5-8, which address applied topics such as natural language processing, computer vision, decision support, and responsible AI. Fifteen community college instructors participated in structured focus groups, completing the projects as learners and providing feedback through individual reflection and group discussion. Using thematic analysis, we examined how instructors evaluated the design, instructional value, and classroom applicability of these experiential activities. Findings highlight instructors' appreciation for exploratory tasks, role-based simulations, and real-world relevance, while also surfacing design trade-offs around cognitive load, guidance, and adaptability for diverse learners. This work extends prior research on AI literacy by centering instructor perspectives on teaching complex AI topics without code. It offers actionable insights for designing inclusive, experiential AI learning resources that scale across disciplines and learner backgrounds.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 78,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05442",
        "abs_url": "https://arxiv.org/abs/2511.05442",
        "pdf_url": "https://arxiv.org/pdf/2511.05442",
        "title": "APP: Accelerated Path Patching with Task-Specific Pruning",
        "authors": [
            "Frauke Andersen",
            "William Rudman",
            "Ruochen Zhang",
            "Carsten Eickhoff"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
        "abstract": "Circuit discovery is a key step in many mechanistic interpretability pipelines. Current methods, such as Path Patching, are computationally expensive and have limited in-depth circuit analysis for smaller models. In this study, we propose Accelerated Path Patching (APP), a hybrid approach leveraging our novel contrastive attention head pruning method to drastically reduce the search space of circuit discovery methods. Our Contrastive-FLAP pruning algorithm uses techniques from causal mediation analysis to assign higher pruning scores to task-specific attention heads, leading to higher performing sparse models compared to traditional pruning techniques. Although Contrastive-FLAP is successful at preserving task-specific heads that existing pruning algorithms remove at low sparsity ratios, the circuits found by Contrastive-FLAP alone are too large to satisfy the minimality constraint required in circuit analysis. APP first applies Contrastive-FLAP to reduce the search space on required for circuit discovery algorithms by, on average, 56\\%. Next, APP, applies traditional Path Patching on the remaining attention heads, leading to a speed up of 59.63\\%-93.27\\% compared to Path Patching applied to the dense model. Despite the substantial computational saving that APP provides, circuits obtained from APP exhibit substantial overlap and similar performance to previously established Path Patching circuits",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 79,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05452",
        "abs_url": "https://arxiv.org/abs/2511.05452",
        "pdf_url": "https://arxiv.org/pdf/2511.05452",
        "title": "Self-adaptive weighting and sampling for physics-informed neural networks",
        "authors": [
            "Wenqian Chen",
            "Amanda Howard",
            "Panos Stinis"
        ],
        "comments": "11 figures",
        "subjects": "Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)",
        "abstract": "Physics-informed deep learning has emerged as a promising framework for solving partial differential equations (PDEs). Nevertheless, training these models on complex problems remains challenging, often leading to limited accuracy and efficiency. In this work, we introduce a hybrid adaptive sampling and weighting method to enhance the performance of physics-informed neural networks (PINNs). The adaptive sampling component identifies training points in regions where the solution exhibits rapid variation, while the adaptive weighting component balances the convergence rate across training points. Numerical experiments show that applying only adaptive sampling or only adaptive weighting is insufficient to consistently achieve accurate predictions, particularly when training points are scarce. Since each method emphasizes different aspects of the solution, their effectiveness is problem dependent. By combining both strategies, the proposed framework consistently improves prediction accuracy and training efficiency, offering a more robust approach for solving PDEs with PINNs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 80,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05459",
        "abs_url": "https://arxiv.org/abs/2511.05459",
        "pdf_url": "https://arxiv.org/pdf/2511.05459",
        "title": "SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models",
        "authors": [
            "Jingxuan Xu",
            "Ken Deng",
            "Weihao Li",
            "Songwei Yu",
            "Huaixi Tang",
            "Haoyang Huang",
            "Zhiyi Lai",
            "Zizheng Zhan",
            "Yanan Wu",
            "Chenchen Zhang",
            "Kepeng Lei",
            "Yifan Yao",
            "Xinping Lei",
            "Wenqiang Zhu",
            "Zongxian Feng",
            "Han Li",
            "Junqi Xiong",
            "Dailin Li",
            "Zuchen Gao",
            "Kun Wu",
            "Wen Xiang",
            "Ziqi Zhan",
            "Yuanxing Zhang",
            "Wuxuan Gong",
            "Ziyuan Gao",
            "Guanxiang Wang",
            "Yirong Xue",
            "Xiaojiang Zhang",
            "Jinghui Wang",
            "Huiming Wang",
            "Wenhao Zhuang",
            "Zhaoxiang Zhang",
            "Yuqun Zhang",
            "Haotian Zhang",
            "Bin Chen",
            "Jiaheng Liu"
        ],
        "comments": "",
        "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)",
        "abstract": "Evaluating large language models (LLMs) for software engineering has been limited by narrow task coverage, language bias, and insufficient alignment with real-world developer workflows. Existing benchmarks often focus on algorithmic problems or Python-centric bug fixing, leaving critical dimensions of software engineering underexplored. To address these gaps, we introduce SWE-Compass1, a comprehensive benchmark that unifies heterogeneous code-related evaluations into a structured and production-aligned framework. SWE-Compass spans 8 task types, 8 programming scenarios, and 10 programming languages, with 2000 high-quality instances curated from authentic GitHub pull requests and refined through systematic filtering and validation. We benchmark ten state-of-the-art LLMs under two agentic frameworks, SWE-Agent and Claude Code, revealing a clear hierarchy of difficulty across task types, languages, and scenarios. Moreover, by aligning evaluation with real-world developer practices, SWE-Compass provides a rigorous and reproducible foundation for diagnosing and advancing agentic coding capabilities in large language models.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 81,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05475",
        "abs_url": "https://arxiv.org/abs/2511.05475",
        "pdf_url": "https://arxiv.org/pdf/2511.05475",
        "title": "AI Literacy Assessment Revisited: A Task-Oriented Approach Aligned with Real-world Occupations",
        "authors": [
            "Christopher Bogart",
            "Aparna Warrier",
            "Arav Agarwal",
            "Ross Higashi",
            "Yufan Zhang",
            "Jesse Flot",
            "Jaromir Savelka",
            "Heather Burte",
            "Majd Sakr"
        ],
        "comments": "",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)",
        "abstract": "As artificial intelligence (AI) systems become ubiquitous in professional contexts, there is an urgent need to equip workers, often with backgrounds outside of STEM, with the skills to use these tools effectively as well as responsibly, that is, to be AI literate. However, prevailing definitions and therefore assessments of AI literacy often emphasize foundational technical knowledge, such as programming, mathematics, and statistics, over practical knowledge such as interpreting model outputs, selecting tools, or identifying ethical concerns. This leaves a noticeable gap in assessing someone's AI literacy for real-world job use. We propose a work-task-oriented assessment model for AI literacy which is grounded in the competencies required for effective use of AI tools in professional settings. We describe the development of a novel AI literacy assessment instrument, and accompanying formative assessments, in the context of a US Navy robotics training program. The program included training in robotics and AI literacy, as well as a competition with practical tasks and a multiple choice scenario task meant to simulate use of AI in a job setting. We found that, as a measure of applied AI literacy, the competition's scenario task outperformed the tests we adopted from past research or developed ourselves. We argue that when training people for AI-related work, educators should consider evaluating them with instruments that emphasize highly contextualized practical skills rather than abstract technical knowledge, especially when preparing workers without technical backgrounds for AI-integrated roles.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 82,
        "date": "2025-11-10",
        "date_url": "https://arxiv.org/catchup/cs.AI/2025-11-10?abs=True",
        "arxiv_id": "2511.05483",
        "abs_url": "https://arxiv.org/abs/2511.05483",
        "pdf_url": "https://arxiv.org/pdf/2511.05483",
        "title": "DGTN: Graph-Enhanced Transformer with Diffusive Attention Gating Mechanism for Enzyme DDG Prediction",
        "authors": [
            "Abigail Lin"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Predicting the effect of amino acid mutations on enzyme thermodynamic stability (DDG) is fundamental to protein engineering and drug design. While recent deep learning approaches have shown promise, they often process sequence and structure information independently, failing to capture the intricate coupling between local structural geometry and global sequential patterns. We present DGTN (Diffused Graph-Transformer Network), a novel architecture that co-learns graph neural network (GNN) weights for structural priors and transformer attention through a diffusion mechanism. Our key innovation is a bidirectional diffusion process where: (1) GNN-derived structural embeddings guide transformer attention via learnable diffusion kernels, and (2) transformer representations refine GNN message passing through attention-modulated graph updates. We provide rigorous mathematical analysis showing this co-learning scheme achieves provably better approximation bounds than independent processing. On ProTherm and SKEMPI benchmarks, DGTN achieves state-of-the-art performance (Pearson Rho = 0.87, RMSE = 1.21 kcal/mol), with 6.2% improvement over best baselines. Ablation studies confirm the diffusion mechanism contributes 4.8 points to correlation. Our theoretical analysis proves the diffused attention converges to optimal structure-sequence coupling, with convergence rate O(1/sqrt(T) ) where T is diffusion steps. This work establishes a principled framework for integrating heterogeneous protein representations through learnable diffusion.",
        "gemini2.5flash": "",
        "overall_idea": ""
    }
]