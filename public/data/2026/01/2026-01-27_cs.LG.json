[
    {
        "order": 1,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.16991",
        "abs_url": "https://arxiv.org/abs/2601.16991",
        "pdf_url": "https://arxiv.org/pdf/2601.16991",
        "title": "Sparsity-Aware Low-Rank Representation for Efficient Fine-Tuning of Large Language Models",
        "authors": [
            "Longteng Zhang",
            "Sen Wu",
            "Shuai Hou",
            "Zhengyu Qing",
            "Zhuo Zheng",
            "Danning Ke",
            "Qihong Lin",
            "Qiang Wang",
            "Shaohuai Shi",
            "Xiaowen Chu"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Adapting large pre-trained language models to downstream tasks often entails fine-tuning millions of parameters or deploying costly dense weight updates, which hinders their use in resource-constrained environments. Low-rank Adaptation (LoRA) reduces trainable parameters by factorizing weight updates, yet the underlying dense weights still impose high storage and computation costs. Magnitude-based pruning can yield sparse models but typically degrades LoRA's performance when applied naively. In this paper, we introduce SALR (Sparsity-Aware Low-Rank Representation), a novel fine-tuning paradigm that unifies low-rank adaptation with sparse pruning under a rigorous mean-squared-error framework. We prove that statically pruning only the frozen base weights minimizes the pruning error bound, and we recover the discarded residual information via a truncated-SVD low-rank adapter, which provably reduces per-entry MSE by a factor of $(1 - r/\\min(d,k))$. To maximize hardware efficiency, we fuse multiple low-rank adapters into a single concatenated GEMM, and we adopt a bitmap-based encoding with a two-stage pipelined decoding + GEMM design to achieve true model compression and speedup. Empirically, SALR attains 50\\% sparsity on various LLMs while matching the performance of LoRA on GSM8K and MMLU, reduces model size by $2\\times$, and delivers up to a $1.7\\times$ inference speedup.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 2,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.16994",
        "abs_url": "https://arxiv.org/abs/2601.16994",
        "pdf_url": "https://arxiv.org/pdf/2601.16994",
        "title": "A Dataset of Dengue Hospitalizations in Brazil (1999 to 2021) with Weekly Disaggregation from Monthly Counts",
        "authors": [
            "Lucas M. Morello",
            "Matheus Lima Castro",
            "Pedro Cesar M. G. Camargo",
            "Liliane Moreira Nery",
            "Darllan Collins da Cunha e Silva",
            "Leopoldo Lusquino Filho"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This data paper describes and publicly releases this dataset (v1.0.0), published on Zenodo under DOI https://doi.org/10.5281/zenodo.18189192. Motivated by the need to increase the temporal granularity of originally monthly data to enable more effective training of AI models for epidemiological forecasting, the dataset harmonizes municipal-level dengue hospitalization time series across Brazil and disaggregates them to weekly resolution (epidemiological weeks) through an interpolation protocol with a correction step that preserves monthly totals. The statistical and temporal validity of this disaggregation was assessed using a high-resolution reference dataset from the state of Sao Paulo (2024), which simultaneously provides monthly and epidemiological-week counts, enabling a direct comparison of three strategies: linear interpolation, jittering, and cubic spline. Results indicated that cubic spline interpolation achieved the highest adherence to the reference data, and this strategy was therefore adopted to generate weekly series for the 1999 to 2021 period. In addition to hospitalization time series, the dataset includes a comprehensive set of explanatory variables commonly used in epidemiological and environmental modeling, such as demographic density, CH4, CO2, and NO2 emissions, poverty and urbanization indices, maximum temperature, mean monthly precipitation, minimum relative humidity, and municipal latitude and longitude, following the same temporal disaggregation scheme to ensure multivariate compatibility. The paper documents the datasets provenance, structure, formats, licenses, limitations, and quality metrics (MAE, RMSE, R2, KL, JSD, DTW, and the KS test), and provides usage recommendations for multivariate time-series analysis, environmental health studies, and the development of machine learning and deep learning models for outbreak forecasting.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 3,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17007",
        "abs_url": "https://arxiv.org/abs/2601.17007",
        "pdf_url": "https://arxiv.org/pdf/2601.17007",
        "title": "Analysis of voice recordings features for Classification of Parkinson's Disease",
        "authors": [
            "Beatriz Pérez-Sánchez",
            "Noelia Sánchez-Maroño",
            "Miguel A. Díaz-Freire"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Parkinson's disease (PD) is a chronic neurodegenerative disease. Early diagnosis is essential to mitigate the progressive deterioration of patients' quality of life. The most characteristic motor symptoms are very mild in the early stages, making diagnosis difficult. Recent studies have shown that the use of patient voice recordings can aid in early diagnosis. Although the analysis of such recordings is costly from a clinical point of view, advances in machine learning techniques are making the processing of this type of data increasingly accurate and efficient. Vocal recordings contain many features, but it is not known whether all of them are relevant for diagnosing the disease. This paper proposes the use of different types of machine learning models combined with feature selection methods to detect the disease. The selection techniques allow to reduce the number of features used by the classifiers by determining which ones provide the most information about the problem. The results show that machine learning methods, in particular neural networks, are suitable for PD classification and that the number of features can be significantly reduced without affecting the performance of the models.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 4,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17008",
        "abs_url": "https://arxiv.org/abs/2601.17008",
        "pdf_url": "https://arxiv.org/pdf/2601.17008",
        "title": "Bayesian Robust Financial Trading with Adversarial Synthetic Market Data",
        "authors": [
            "Haochong Xia",
            "Simin Li",
            "Ruixiao Xu",
            "Zhixia Zhang",
            "Hongxiang Wang",
            "Zhiqian Liu",
            "Teng Yao Long",
            "Molei Qin",
            "Chuqiao Zong",
            "Bo An"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Trading and Market Microstructure (q-fin.TR)",
        "abstract": "Algorithmic trading relies on machine learning models to make trading decisions. Despite strong in-sample performance, these models often degrade when confronted with evolving real-world market regimes, which can shift dramatically due to macroeconomic changes-e.g., monetary policy updates or unanticipated fluctuations in participant behavior. We identify two challenges that perpetuate this mismatch: (1) insufficient robustness in existing policy against uncertainties in high-level market fluctuations, and (2) the absence of a realistic and diverse simulation environment for training, leading to policy overfitting. To address these issues, we propose a Bayesian Robust Framework that systematically integrates a macro-conditioned generative model with robust policy learning. On the data side, to generate realistic and diverse data, we propose a macro-conditioned GAN-based generator that leverages macroeconomic indicators as primary control variables, synthesizing data with faithful temporal, cross-instrument, and macro correlations. On the policy side, to learn robust policy against market fluctuations, we cast the trading process as a two-player zero-sum Bayesian Markov game, wherein an adversarial agent simulates shifting regimes by perturbing macroeconomic indicators in the macro-conditioned generator, while the trading agent-guided by a quantile belief network-maintains and updates its belief over hidden market states. The trading agent seeks a Robust Perfect Bayesian Equilibrium via Bayesian neural fictitious self-play, stabilizing learning under adversarial market perturbations. Extensive experiments on 9 financial instruments demonstrate that our framework outperforms 9 state-of-the-art baselines. In extreme events like the COVID, our method shows improved profitability and risk management, offering a reliable solution for trading under uncertain and shifting market dynamics.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 5,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17010",
        "abs_url": "https://arxiv.org/abs/2601.17010",
        "pdf_url": "https://arxiv.org/pdf/2601.17010",
        "title": "Optimizing the Landscape of LLM Embeddings with Dynamic Exploratory Graph Analysis for Generative Psychometrics: A Monte Carlo Study",
        "authors": [
            "Hudson Golino"
        ],
        "comments": "18 pages, 6 figures, conference paper",
        "subjects": "Machine Learning (cs.LG); Applications (stat.AP)",
        "abstract": "Large language model (LLM) embeddings are increasingly used to estimate dimensional structure in psychological item pools prior to data collection, yet current applications treat embeddings as static, cross-sectional representations. This approach implicitly assumes uniform contribution across all embedding coordinates and overlooks the possibility that optimal structural information may be concentrated in specific regions of the embedding space. This study reframes embeddings as searchable landscapes and adapts Dynamic Exploratory Graph Analysis (DynEGA) to systematically traverse embedding coordinates, treating the dimension index as a pseudo-temporal ordering analogous to intensive longitudinal trajectories. A large-scale Monte Carlo simulation embedded items representing five dimensions of grandiose narcissism using OpenAI's text-embedding-3-small model, generating network estimations across systematically varied item pool sizes (3-40 items per dimension) and embedding depths (3-1,298 dimensions). Results reveal that Total Entropy Fit Index (TEFI) and Normalized Mutual Information (NMI) leads to competing optimization trajectories across the embedding landscape. TEFI achieves minima at deep embedding ranges (900--1,200 dimensions) where entropy-based organization is maximal but structural accuracy degrades, whereas NMI peaks at shallow depths where dimensional recovery is strongest but entropy-based fit remains suboptimal. Single-metric optimization produces structurally incoherent solutions, whereas a weighted composite criterion identifies embedding dimensions depth regions that jointly balance accuracy and organization. Optimal embedding depth scales systematically with item pool size. These findings establish embedding landscapes as non-uniform semantic spaces requiring principled optimization rather than default full-vector usage.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 6,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17063",
        "abs_url": "https://arxiv.org/abs/2601.17063",
        "pdf_url": "https://arxiv.org/pdf/2601.17063",
        "title": "FlashMoE: Reducing SSD I/O Bottlenecks via ML-Based Cache Replacement for Mixture-of-Experts Inference on Edge Devices",
        "authors": [
            "Byeongju Kim",
            "Jungwan Lee",
            "Donghyeon Han",
            "Hoi-Jun Yoo",
            "Sangyeob Kim"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Recently, Mixture-of-Experts (MoE) models have gained attention for efficiently scaling large language models. Although these models are extremely large, their sparse activation enables inference to be performed by accessing only a fraction of the model at a time. This property opens the possibility of on-device inference of MoE, which was previously considered infeasible for such large models. Consequently, various systems have been proposed to leverage this sparsity and enable efficient MoE inference for edge devices. However, previous MoE inference systems like Fiddler[8] or DAOP[13] rely on DRAM-based offloading and are not suitable for memory constrained on-device environments. As recent MoE models grow to hundreds of gigabytes, RAM-offloading solutions become impractical. To address this, we propose FlashMoE, a system that offloads inactive experts to SSD, enabling efficient MoE inference under limited RAM. FlashMoE incorporates a lightweight ML-based caching strategy that adaptively combines recency and frequency signals to maximize expert reuse, significantly reducing storage I/O. In addition, we built a user-grade desktop platform to demonstrate the practicality of FlashMoE. On this real hardware setup, FlashMoE improves cache hit rate by up to 51% over well-known offloading policies such as LRU and LFU, and achieves up to 2.6x speedup compared to existing MoE inference systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 7,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17069",
        "abs_url": "https://arxiv.org/abs/2601.17069",
        "pdf_url": "https://arxiv.org/pdf/2601.17069",
        "title": "Multi-Agent Deep Reinforcement Learning Under Constrained Communications",
        "authors": [
            "Shahil Shaik",
            "Jonathon M. Smereka",
            "Yue Wang"
        ],
        "comments": "21 pages, 8 figures, Under review at ICLR",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Centralized training with decentralized execution (CTDE) has been the dominant paradigm in multi-agent reinforcement learning (MARL), but its reliance on global state information during training introduces scalability, robustness, and generalization bottlenecks. Moreover, in practical scenarios such as adding/dropping teammates or facing environment dynamics that differ from the training, CTDE methods can be brittle and costly to retrain, whereas distributed approaches allow agents to adapt using only local information and peer-to-peer communication. We present a distributed MARL framework that removes the need for centralized critics or global information. Firstly, we develop a novel Distributed Graph Attention Network (D-GAT) that performs global state inference through multi-hop communication, where agents integrate neighbor features via input-dependent attention weights in a fully distributed manner. Leveraging D-GAT, we develop the distributed graph-attention MAPPO (DG-MAPPO) -- a distributed MARL framework where agents optimize local policies and value functions using local observations, multi-hop communication, and shared/averaged rewards. Empirical evaluation on the StarCraftII Multi-Agent Challenge, Google Research Football, and Multi-Agent Mujoco demonstrates that our method consistently outperforms strong CTDE baselines, achieving superior coordination across a wide range of cooperative tasks with both homogeneous and heterogeneous teams. Our distributed MARL framework provides a principled and scalable solution for robust collaboration, eliminating the need for centralized training or global observability. To the best of our knowledge, DG-MAPPO appears to be the first to fully eliminate reliance on privileged centralized information, enabling agents to learn and act solely through peer-to-peer communication.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 8,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17074",
        "abs_url": "https://arxiv.org/abs/2601.17074",
        "pdf_url": "https://arxiv.org/pdf/2601.17074",
        "title": "PhysE-Inv: A Physics-Encoded Inverse Modeling approach for Arctic Snow Depth Prediction",
        "authors": [
            "Akila Sampath",
            "Vandana Janeja",
            "Jianwu Wang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "The accurate estimation of Arctic snow depth ($h_s$) remains a critical time-varying inverse problem due to the extreme scarcity and noise inherent in associated sea ice parameters. Existing process-based and data-driven models are either highly sensitive to sparse data or lack the physical interpretability required for climate-critical applications. To address this gap, we introduce PhysE-Inv, a novel framework that integrates a sophisticated sequential architecture, an LSTM Encoder-Decoder with Multi-head Attention and physics-guided contrastive learning, with physics-guided this http URL core innovation lies in a surjective, physics-constrained inversion methodology. This methodology first leverages the hydrostatic balance forward model as a target-formulation proxy, enabling effective learning in the absence of direct $h_s$ ground truth; second, it uses reconstruction physics regularization over a latent space to dynamically discover hidden physical parameters from noisy, incomplete time-series input. Evaluated against state-of-the-art baselines, PhysE-Inv significantly improves prediction performance, reducing error by 20\\% while demonstrating superior physical consistency and resilience to data sparsity compared to empirical methods. This approach pioneers a path for noise-tolerant, interpretable inverse modeling, with wide applicability in geospatial and cryospheric domains.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 9,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17090",
        "abs_url": "https://arxiv.org/abs/2601.17090",
        "pdf_url": "https://arxiv.org/pdf/2601.17090",
        "title": "SFO: Learning PDE Operators via Spectral Filtering",
        "authors": [
            "Noam Koren",
            "Rafael Moschopoulos",
            "Kira Radinsky",
            "Elad Hazan"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Partial differential equations (PDEs) govern complex systems, yet neural operators often struggle to efficiently capture the long-range, nonlocal interactions inherent in their solution maps. We introduce Spectral Filtering Operator (SFO), a neural operator that parameterizes integral kernels using the Universal Spectral Basis (USB), a fixed, global orthonormal basis derived from the eigenmodes of the Hilbert matrix in spectral filtering theory. Motivated by our theoretical finding that the discrete Green's functions of shift-invariant PDE discretizations exhibit spatial Linear Dynamical System (LDS) structure, we prove that these kernels admit compact approximations in the USB. By learning only the spectral coefficients of rapidly decaying eigenvalues, SFO achieves a highly efficient representation. Across six benchmarks, including reaction-diffusion, fluid dynamics, and 3D electromagnetics, SFO achieves state-of-the-art accuracy, reducing error by up to 40% relative to strong baselines while using substantially fewer parameters.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 10,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17093",
        "abs_url": "https://arxiv.org/abs/2601.17093",
        "pdf_url": "https://arxiv.org/pdf/2601.17093",
        "title": "The Triangle of Similarity: A Multi-Faceted Framework for Comparing Neural Network Representations",
        "authors": [
            "Olha Sirikova",
            "Alvin Chan"
        ],
        "comments": "Accepted to AAAI 2026 Workshop on AI for Scientific Research (AI4Research)",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Comparing neural network representations is essential for understanding and validating models in scientific applications. Existing methods, however, often provide a limited view. We propose the Triangle of Similarity, a framework that combines three complementary perspectives: static representational similarity (CKA/Procrustes), functional similarity (Linear Mode Connectivity or Predictive Similarity), and sparsity similarity (robustness under pruning). Analyzing a range of CNNs, Vision Transformers, and Vision-Language Models using both in-distribution (ImageNetV2) and out-of-distribution (CIFAR-10) testbeds, our initial findings suggest that: (1) architectural family is a primary determinant of representational similarity, forming distinct clusters; (2) CKA self-similarity and task accuracy are strongly correlated during pruning, though accuracy often degrades more sharply; and (3) for some model pairs, pruning appears to regularize representations, exposing a shared computational core. This framework offers a more holistic approach for assessing whether models have converged on similar internal mechanisms, providing a useful tool for model selection and analysis in scientific research.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 11,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17108",
        "abs_url": "https://arxiv.org/abs/2601.17108",
        "pdf_url": "https://arxiv.org/pdf/2601.17108",
        "title": "MambaNet: Mamba-assisted Channel Estimation Neural Network With Attention Mechanism",
        "authors": [
            "Dianxin Luan",
            "Chengsi Liang",
            "Jie Huang",
            "Zheng Lin",
            "Kaitao Meng",
            "John Thompson",
            "Cheng-Xiang Wang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Signal Processing (eess.SP)",
        "abstract": "This paper proposes a Mamba-assisted neural network framework incorporating self-attention mechanism to achieve improved channel estimation with low complexity for orthogonal frequency-division multiplexing (OFDM) waveforms, particularly for configurations with a large number of subcarriers. With the integration of customized Mamba architecture, the proposed framework handles large-scale subcarrier channel estimation efficiently while capturing long-distance dependencies among these subcarriers effectively. Unlike conventional Mamba structure, this paper implements a bidirectional selective scan to improve channel estimation performance, because channel gains at different subcarriers are non-causal. Moreover, the proposed framework exhibits relatively lower space complexity than transformer-based neural networks. Simulation results tested on the 3GPP TS 36.101 channel demonstrate that compared to other baseline neural network solutions, the proposed method achieves improved channel estimation performance with a reduced number of tunable parameters.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 12,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17112",
        "abs_url": "https://arxiv.org/abs/2601.17112",
        "pdf_url": "https://arxiv.org/pdf/2601.17112",
        "title": "Low-Rank Tensor Approximation of Weights in Large Language Models via Cosine Lanczos Bidiagonalization",
        "authors": [
            "A. El Ichi",
            "K. Jbilou"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse natural language tasks but suffer from extremely large memory footprints and computational costs. In this paper, we introduce a tensor compression framework based on the cproduct for computing low rank approximation In the first part of our approach, we leverage the algebraic structure of the cproduct to represent weight tensors such as those in embedding layers, attention projections, and feed forward networks in a transform domain where frontal slices can be jointly approximated by low rank tensor factors. This enables computationally efficient compression that exploits multidimensional correlations beyond traditional SVD methods.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 13,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17130",
        "abs_url": "https://arxiv.org/abs/2601.17130",
        "pdf_url": "https://arxiv.org/pdf/2601.17130",
        "title": "How does Graph Structure Modulate Membership-Inference Risk for Graph Neural Networks?",
        "authors": [
            "Megha Khosla"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Cryptography and Security (cs.CR)",
        "abstract": "Graph neural networks (GNNs) have become the standard tool for encoding data and their complex relationships into continuous representations, improving prediction accuracy in several machine learning tasks like node classification and link prediction. However, their use in sensitive applications has raised concerns about the potential leakage of training data. Research on privacy leakage in GNNs has largely been shaped by findings from non-graph domains, such as images and tabular data. We emphasize the need of graph specific analysis and investigate the impact of graph structure on node level membership inference. We formalize MI over node-neighbourhood tuples and investigate two important dimensions: (i) training graph construction and (ii) inference-time edge access. Empirically, snowball's coverage bias often harms generalisation relative to random sampling, while enabling inter-train-test edges at inference improves test accuracy, shrinks the train-test gap, and yields the lowest membership advantage across most of the models and datasets. We further show that the generalisation gap empirically measured as the performance difference between the train and test nodes is an incomplete proxy for MI risk: access to edges dominates-MI can rise or fall independent of gap changes. Finally, we examine the auditability of differentially private GNNs, adapting the definition of statistical exchangeability of train-test data points for graph based models. We show that for node level tasks the inductive splits (random or snowball sampled) break exchangeability, limiting the applicability of standard bounds for membership advantage of differential private models.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 14,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17135",
        "abs_url": "https://arxiv.org/abs/2601.17135",
        "pdf_url": "https://arxiv.org/pdf/2601.17135",
        "title": "ConceptACT: Episode-Level Concepts for Sample-Efficient Robotic Imitation Learning",
        "authors": [
            "Jakob Karalus",
            "Friedhelm Schwenker"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Robotics (cs.RO)",
        "abstract": "Imitation learning enables robots to acquire complex manipulation skills from human demonstrations, but current methods rely solely on low-level sensorimotor data while ignoring the rich semantic knowledge humans naturally possess about tasks. We present ConceptACT, an extension of Action Chunking with Transformers that leverages episode-level semantic concept annotations during training to improve learning efficiency. Unlike language-conditioned approaches that require semantic input at deployment, ConceptACT uses human-provided concepts (object properties, spatial relationships, task constraints) exclusively during demonstration collection, adding minimal annotation burden. We integrate concepts using a modified transformer architecture in which the final encoder layer implements concept-aware cross-attention, supervised to align with human annotations. Through experiments on two robotic manipulation tasks with logical constraints, we demonstrate that ConceptACT converges faster and achieves superior sample efficiency compared to standard ACT. Crucially, we show that architectural integration through attention mechanisms significantly outperforms naive auxiliary prediction losses or language-conditioned models. These results demonstrate that properly integrated semantic supervision provides powerful inductive biases for more efficient robot learning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 15,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17183",
        "abs_url": "https://arxiv.org/abs/2601.17183",
        "pdf_url": "https://arxiv.org/pdf/2601.17183",
        "title": "Federated Proximal Optimization for Privacy-Preserving Heart Disease Prediction: A Controlled Simulation Study on Non-IID Clinical Data",
        "authors": [
            "Farzam Asad",
            "Junaid Saif Khan",
            "Maria Tariq",
            "Sundus Munir",
            "Muhammad Adnan Khan"
        ],
        "comments": "27 pages, 7 figures, 4 tables",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Healthcare institutions have access to valuable patient data that could be of great help in the development of improved diagnostic models, but privacy regulations like HIPAA and GDPR prevent hospitals from directly sharing data with one another. Federated Learning offers a way out to this problem by facilitating collaborative model training without having the raw patient data centralized. However, clinical datasets intrinsically have non-IID (non-independent and identically distributed) features brought about by demographic disparity and diversity in disease prevalence and institutional practices. This paper presents a comprehensive simulation research of Federated Proximal Optimization (FedProx) for Heart Disease prediction based on UCI Heart Disease dataset. We generate realistic non-IID data partitions by simulating four heterogeneous hospital clients from the Cleveland Clinic dataset (303 patients), by inducing statistical heterogeneity by demographic-based stratification. Our experimental results show that FedProx with proximal parameter mu=0.05 achieves 85.00% accuracy, which is better than both centralized learning (83.33%) and isolated local models (78.45% average) without revealing patient privacy. Through generous sheer ablation studies with statistical validation on 50 independent runs we demonstrate that proximal regularization is effective in curbing client drift in heterogeneous environments. This proof-of-concept research offers algorithmic insights and practical deployment guidelines for real-world federated healthcare systems, and thus, our results are directly transferable to hospital IT-administrators, implementing privacy-preserving collaborative learning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 16,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17189",
        "abs_url": "https://arxiv.org/abs/2601.17189",
        "pdf_url": "https://arxiv.org/pdf/2601.17189",
        "title": "Rethinking Benchmarks for Differentially Private Image Classification",
        "authors": [
            "Sabrina Mokhtari",
            "Sara Kodeiri",
            "Shubhankar Mohapatra",
            "Florian Tramer",
            "Gautam Kamath"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We revisit benchmarks for differentially private image classification. We suggest a comprehensive set of benchmarks, allowing researchers to evaluate techniques for differentially private machine learning in a variety of settings, including with and without additional data, in convex settings, and on a variety of qualitatively different datasets. We further test established techniques on these benchmarks in order to see which ideas remain effective in different settings. Finally, we create a publicly available leader board for the community to track progress in differentially private machine learning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 17,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17192",
        "abs_url": "https://arxiv.org/abs/2601.17192",
        "pdf_url": "https://arxiv.org/pdf/2601.17192",
        "title": "PUNCH: Physics-informed Uncertainty-aware Network for Coronary Hemodynamics",
        "authors": [
            "Sukirt Thakur",
            "Marcus Roper",
            "Yang Zhou",
            "Reza Akbarian Bafghi",
            "Brahmajee K. Nallamothu",
            "C. Alberto Figueroa",
            "Srinivas Paruchuri",
            "Scott Burger",
            "Maziar Raissi"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Coronary microvascular dysfunction (CMD) affects millions worldwide yet remains underdiagnosed because gold-standard physiological measurements are invasive and variably reproducible. We introduce a non-invasive, uncertainty-aware framework for estimating coronary flow reserve (CFR) directly from standard angiography. The system integrates physics-informed neural networks with variational inference to infer coronary blood flow from first-principles models of contrast transport, without requiring ground-truth flow measurements. The pipeline runs in approximately three minutes per patient on a single GPU, with no population-level training. Using 1{,}000 synthetic spatiotemporal intensity maps (kymographs) with controlled noise and artifacts, the framework reliably identifies degraded data and outputs appropriately inflated uncertainty estimates, showing strong correspondence between predictive uncertainty and error (Pearson $r = 0.997$, Spearman $\\rho = 0.998$). Clinical validation in 12 patients shows strong agreement between PUNCH-derived CFR and invasive bolus thermodilution (Pearson $r = 0.90$, $p = 6.3 \\times 10^{-5}$). We focus on the LAD, the artery most commonly assessed in routine CMD testing. Probabilistic CFR estimates have confidence intervals narrower than the variability of repeated invasive measurements. By transforming routine angiography into quantitative, uncertainty-aware assessment, this approach enables scalable, safer, and more reproducible evaluation of coronary microvascular function. Because standard angiography is widely available globally, the framework could expand access to CMD diagnosis and establish a new paradigm for physics-informed, patient-specific inference from clinical imaging.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 18,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17196",
        "abs_url": "https://arxiv.org/abs/2601.17196",
        "pdf_url": "https://arxiv.org/pdf/2601.17196",
        "title": "Accelerated Sinkhorn Algorithms for Partial Optimal Transport",
        "authors": [
            "Nghia Thu Truong",
            "Qui Phu Pham",
            "Quang Nguyen",
            "Dung Luong",
            "Mai Tran"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Partial Optimal Transport (POT) addresses the problem of transporting only a fraction of the total mass between two distributions, making it suitable when marginals have unequal size or contain outliers. While Sinkhorn-based methods are widely used, their complexity bounds for POT remain suboptimal and can limit scalability. We introduce Accelerated Sinkhorn for POT (ASPOT), which integrates alternating minimization with Nesterov-style acceleration in the POT setting, yielding a complexity of $\\mathcal{O}(n^{7/3}\\varepsilon^{-5/3})$. We also show that an informed choice of the entropic parameter $\\gamma$ improves rates for the classical Sinkhorn method. Experiments on real-world applications validate our theories and demonstrate the favorable performance of our proposed methods.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 19,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17204",
        "abs_url": "https://arxiv.org/abs/2601.17204",
        "pdf_url": "https://arxiv.org/pdf/2601.17204",
        "title": "SpecBridge: Bridging Mass Spectrometry and Molecular Representations via Cross-Modal Alignment",
        "authors": [
            "Yinkai Wang",
            "Yan Zhou Chen",
            "Xiaohui Chen",
            "Li-Ping Liu",
            "Soha Hassoun"
        ],
        "comments": "preprint",
        "subjects": "Machine Learning (cs.LG); Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Small-molecule identification from tandem mass spectrometry (MS/MS) remains a bottleneck in untargeted settings where spectral libraries are incomplete. While deep learning offers a solution, current approaches typically fall into two extremes: explicit generative models that construct molecular graphs atom-by-atom, or joint contrastive models that learn cross-modal subspaces from scratch. We introduce SpecBridge, a novel implicit alignment framework that treats structure identification as a geometric alignment problem. SpecBridge fine-tunes a self-supervised spectral encoder (DreaMS) to project directly into the latent space of a frozen molecular foundation model (ChemBERTa), and then performs retrieval by cosine similarity to a fixed bank of precomputed molecular embeddings. Across MassSpecGym, Spectraverse, and MSnLib benchmarks, SpecBridge improves top-1 retrieval accuracy by roughly 20-25% relative to strong neural baselines, while keeping the number of trainable parameters small. These results suggest that aligning to frozen foundation models is a practical, stable alternative to designing new architectures from scratch. The code for SpecBridge is released at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 20,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17207",
        "abs_url": "https://arxiv.org/abs/2601.17207",
        "pdf_url": "https://arxiv.org/pdf/2601.17207",
        "title": "NewPINNs: Physics-Informing Neural Networks Using Conventional Solvers for Partial Differential Equations",
        "authors": [
            "Maedeh Makki",
            "Satish Chandran",
            "Maziar Raissi",
            "Adrien Grenier",
            "Behzad Mohebbi"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We introduce NewPINNs, a physics-informing learning framework that couples neural networks with conventional numerical solvers for solving differential equations. Rather than enforcing governing equations and boundary conditions through residual-based loss terms, NewPINNs integrates the solver directly into the training loop and defines learning objectives through solver-consistency. The neural network produces candidate solution states that are advanced by the numerical solver, and training minimizes the discrepancy between the network prediction and the solver-evolved state. This pull-push interaction enables the network to learn physically admissible solutions through repeated exposure to the solver's action, without requiring problem-specific loss engineering or explicit evaluation of differential equation residuals. By delegating the enforcement of physics, boundary conditions, and numerical stability to established numerical solvers, NewPINNs mitigates several well-known failure modes of standard physics-informed neural networks, including optimization pathologies, sensitivity to loss weighting, and poor performance in stiff or nonlinear regimes. We demonstrate the effectiveness of the proposed approach across multiple forward and inverse problems involving finite volume, finite element, and spectral solvers.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 21,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17215",
        "abs_url": "https://arxiv.org/abs/2601.17215",
        "pdf_url": "https://arxiv.org/pdf/2601.17215",
        "title": "JetFormer: A Scalable and Efficient Transformer for Jet Tagging from Offline Analysis to FPGA Triggers",
        "authors": [
            "Ruoqing Zheng",
            "Chang Sun",
            "Qibin Liu",
            "Lauri Laatu",
            "Arianna Cox",
            "Benedikt Maier",
            "Alexander Tapper",
            "Jose G. F. Coutinho",
            "Wayne Luk",
            "Zhiqiang Que"
        ],
        "comments": "15 pages,",
        "subjects": "Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)",
        "abstract": "We present JetFormer, a versatile and scalable encoder-only Transformer architecture for particle jet tagging at the Large Hadron Collider (LHC). Unlike prior approaches that are often tailored to specific deployment regimes, JetFormer is designed to operate effectively across the full spectrum of jet tagging scenarios, from high-accuracy offline analysis to ultra-low-latency online triggering. The model processes variable-length sets of particle features without relying on input of explicit pairwise interactions, yet achieves competitive or superior performance compared to state-of-the-art methods. On the large-scale JetClass dataset, a large-scale JetFormer matches the accuracy of the interaction-rich ParT model (within 0.7%) while using 37.4% fewer FLOPs, demonstrating its computational efficiency and strong generalization. On benchmark HLS4ML 150P datasets, JetFormer consistently outperforms existing models such as MLPs, Deep Sets, and Interaction Networks by 3-4% in accuracy. To bridge the gap to hardware deployment, we further introduce a hardware-aware optimization pipeline based on multi-objective hyperparameter search, yielding compact variants like JetFormer-tiny suitable for FPGA-based trigger systems with sub-microsecond latency requirements. Through structured pruning and quantization, we show that JetFormer can be aggressively compressed with minimal accuracy loss. By unifying high-performance modeling and deployability within a single architectural framework, JetFormer provides a practical pathway for deploying Transformer-based jet taggers in both offline and online environments at the LHC. Code is available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 22,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17224",
        "abs_url": "https://arxiv.org/abs/2601.17224",
        "pdf_url": "https://arxiv.org/pdf/2601.17224",
        "title": "Parameter Inference and Uncertainty Quantification with Diffusion Models: Extending CDI to 2D Spatial Conditioning",
        "authors": [
            "Dmitrii Torbunov",
            "Yihui Ren",
            "Lijun Wu",
            "Yimei Zhu"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Uncertainty quantification is critical in scientific inverse problems to distinguish identifiable parameters from those that remain ambiguous given available measurements. The Conditional Diffusion Model-based Inverse Problem Solver (CDI) has previously demonstrated effective probabilistic inference for one-dimensional temporal signals, but its applicability to higher-dimensional spatial data remains unexplored. We extend CDI to two-dimensional spatial conditioning, enabling probabilistic parameter inference directly from spatial observations. We validate this extension on convergent beam electron diffraction (CBED) parameter inference - a challenging multi-parameter inverse problem in materials characterization where sample geometry, electronic structure, and thermal properties must be extracted from 2D diffraction patterns. Using simulated CBED data with ground-truth parameters, we demonstrate that CDI produces well-calibrated posterior distributions that accurately reflect measurement constraints: tight distributions for well-determined quantities and appropriately broad distributions for ambiguous parameters. In contrast, standard regression methods - while appearing accurate on aggregate metrics - mask this underlying uncertainty by predicting training set means for poorly constrained parameters. Our results confirm that CDI successfully extends from temporal to spatial domains, providing the genuine uncertainty information required for robust scientific inference.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 23,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17257",
        "abs_url": "https://arxiv.org/abs/2601.17257",
        "pdf_url": "https://arxiv.org/pdf/2601.17257",
        "title": "A Constrained Optimization Perspective of Unrolled Transformers",
        "authors": [
            "Javier Porras-Valenzuela",
            "Samar Hadou",
            "Alejandro Ribeiro"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We introduce a constrained optimization framework for training transformers that behave like optimization descent algorithms. Specifically, we enforce layerwise descent constraints on the objective function and replace standard empirical risk minimization (ERM) with a primal-dual training scheme. This approach yields models whose intermediate representations decrease the loss monotonically in expectation across layers. We apply our method to both unrolled transformer architectures and conventional pretrained transformers on tasks of video denoising and text classification. Across these settings, we observe constrained transformers achieve stronger robustness to perturbations and maintain higher out-of-distribution generalization, while preserving in-distribution performance.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 24,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17261",
        "abs_url": "https://arxiv.org/abs/2601.17261",
        "pdf_url": "https://arxiv.org/pdf/2601.17261",
        "title": "AGZO: Activation-Guided Zeroth-Order Optimization for LLM Fine-Tuning",
        "authors": [
            "Wei Lin",
            "Yining Jiang",
            "Qingyu Song",
            "Qiao Xiang",
            "Hong Xu"
        ],
        "comments": "21 pages in total, including 9 pages of main text, with 4 figures and 3 tables. This manuscript is submitted to arXiv",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Zeroth-Order (ZO) optimization has emerged as a promising solution for fine-tuning LLMs under strict memory constraints, as it avoids the prohibitive memory cost of storing activations for backpropagation. However, existing ZO methods typically employ isotropic perturbations, neglecting the rich structural information available during the forward pass. In this paper, we identify a crucial link between gradient formation and activation structure: the gradient of a linear layer is confined to the subspace spanned by its input activations. Leveraging this insight, we propose Activation-Guided Zeroth-Order optimization (AGZO). Unlike prior methods, AGZO extracts a compact, activation-informed subspace on the fly during the forward pass and restricts perturbations to this low-rank subspace. We provide a theoretical framework showing that AGZO optimizes a subspace-smoothed objective and provably yields update directions with higher cosine similarity to the true gradient than isotropic baselines. Empirically, we evaluate AGZO on Qwen3 and Pangu models across various benchmarks. AGZO consistently outperforms state-of-the-art ZO baselines and significantly narrows the performance gap with first-order fine-tuning, while maintaining almost the same peak memory footprint as other ZO methods.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 25,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17274",
        "abs_url": "https://arxiv.org/abs/2601.17274",
        "pdf_url": "https://arxiv.org/pdf/2601.17274",
        "title": "Unrolled Neural Networks for Constrained Optimization",
        "authors": [
            "Samar Hadou",
            "Alejandro Ribeiro"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we develop unrolled neural networks to solve constrained optimization problems, offering accelerated, learnable counterparts to dual ascent (DA) algorithms. Our framework, termed constrained dual unrolling (CDU), comprises two coupled neural networks that jointly approximate the saddle point of the Lagrangian. The primal network emulates an iterative optimizer that finds a stationary point of the Lagrangian for a given dual multiplier, sampled from an unknown distribution. The dual network generates trajectories towards the optimal multipliers across its layers while querying the primal network at each layer. Departing from standard unrolling, we induce DA dynamics by imposing primal-descent and dual-ascent constraints through constrained learning. We formulate training the two networks as a nested optimization problem and propose an alternating procedure that updates the primal and dual networks in turn, mitigating uncertainty in the multiplier distribution required for primal network training. We numerically evaluate the framework on mixed-integer quadratic programs (MIQPs) and power allocation in wireless networks. In both cases, our approach yields near-optimal near-feasible solutions and exhibits strong out-of-distribution (OOD) generalization.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 26,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17301",
        "abs_url": "https://arxiv.org/abs/2601.17301",
        "pdf_url": "https://arxiv.org/pdf/2601.17301",
        "title": "Tabular Foundation Models are Strong Graph Anomaly Detectors",
        "authors": [
            "Yunhui Liu",
            "Tieke He",
            "Yongchao Liu",
            "Can Yi",
            "Hong Jin",
            "Chuntao Hong"
        ],
        "comments": "Accepted by WWW 2026 (Short Paper)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph anomaly detection (GAD), which aims to identify abnormal nodes that deviate from the majority, has become increasingly important in high-stakes Web domains. However, existing GAD methods follow a \"one model per dataset\" paradigm, leading to high computational costs, substantial data demands, and poor generalization when transferred to new datasets. This calls for a foundation model that enables a \"one-for-all\" GAD solution capable of detecting anomalies across diverse graphs without retraining. Yet, achieving this is challenging due to the large structural and feature heterogeneity across domains. In this paper, we propose TFM4GAD, a simple yet effective framework that adapts tabular foundation models (TFMs) for graph anomaly detection. Our key insight is that the core challenges of foundation GAD, handling heterogeneous features, generalizing across domains, and operating with scarce labels, are the exact problems that modern TFMs are designed to solve via synthetic pre-training and powerful in-context learning. The primary challenge thus becomes structural: TFMs are agnostic to graph topology. TFM4GAD bridges this gap by \"flattening\" the graph, constructing an augmented feature table that enriches raw node features with Laplacian embeddings, local and global structural characteristics, and anomaly-sensitive neighborhood aggregations. This augmented table is processed by a TFM in a fully in-context regime. Extensive experiments on multiple datasets with various TFM backbones reveal that TFM4GAD surprisingly achieves significant performance gains over specialized GAD models trained from scratch. Our work offers a new perspective and a practical paradigm for leveraging TFMs as powerful, generalist graph anomaly detectors.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 27,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17303",
        "abs_url": "https://arxiv.org/abs/2601.17303",
        "pdf_url": "https://arxiv.org/pdf/2601.17303",
        "title": "Decentralized Multi-Agent Swarms for Autonomous Grid Security in Industrial IoT: A Consensus-based Approach",
        "authors": [
            "Samaresh Kumar Singh",
            "Joyjit Roy"
        ],
        "comments": "9 pages, 8 figures, and Submitted to IEEE SoutheastCon 2026",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET)",
        "abstract": "As Industrial Internet of Things (IIoT) environments expand to include tens of thousands of connected devices. The centralization of security monitoring architectures creates serious latency issues that savvy attackers can exploit to compromise an entire manufacturing ecosystem. This paper outlines a new, decentralized multi-agent swarm (DMAS) architecture that includes autonomous artificial intelligence (AI) agents at each edge gateway, functioning as a distributed digital \"immune system\" for IIoT networks. Instead of using a traditional static firewall approach, the DMAS agents communicate via a lightweight peer-to-peer protocol to cooperatively detect anomalous behavior across the IIoT network without sending data to a cloud infrastructure. The authors also outline a consensus-based threat validation (CVT) process in which agents vote on the threat level of an identified threat, enabling instant quarantine of a compromised node or nodes. The authors conducted experiments on a testbed that simulated an innovative factory environment with 2000 IIoT devices and found that the DMAS demonstrated sub-millisecond response times (average of 0.85ms), 97.3% accuracy in detecting malicious activity under high load, and 87% accuracy in detecting zero-day attacks. All significantly higher than baseline values for both centralized and edge computing. Additionally, the proposed architecture can prevent real-time cascading failures in industrial control systems and reduce network bandwidth use by 89% compared to cloud-based solutions.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 28,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17307",
        "abs_url": "https://arxiv.org/abs/2601.17307",
        "pdf_url": "https://arxiv.org/pdf/2601.17307",
        "title": "Weighted Graph Clustering via Scale Contraction and Graph Structure Learning",
        "authors": [
            "Haobing Liu",
            "Yinuo Zhang",
            "Tingting Wang",
            "Ruobing Jiang",
            "Yanwei Yu"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph clustering aims to partition nodes into distinct clusters based on their similarity, thereby revealing relationships among nodes. Nevertheless, most existing methods do not fully utilize these edge weights. Leveraging edge weights in graph clustering tasks faces two critical challenges. (1) The introduction of edge weights may significantly increase storage space and training time, making it essential to reduce the graph scale while preserving nodes that are beneficial for the clustering task. (2) Edge weight information may inherently contain noise that negatively impacts clustering results. However, few studies can jointly optimize clustering and edge weights, which is crucial for mitigating the negative impact of noisy edges on clustering task. To address these challenges, we propose a contractile edge-weight-aware graph clustering network. Specifically, a cluster-oriented graph contraction module is designed to reduce the graph scale while preserving important nodes. An edge-weight-aware attention network is designed to identify and weaken noisy connections. In this way, we can more easily identify and mitigate the impact of noisy edges during the clustering process, thus enhancing clustering effectiveness. We conducted extensive experiments on three real-world weighted graph datasets. In particular, our model outperforms the best baseline, demonstrating its superior performance. Furthermore, experiments also show that the proposed graph contraction module can significantly reduce training time and storage space.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 29,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17309",
        "abs_url": "https://arxiv.org/abs/2601.17309",
        "pdf_url": "https://arxiv.org/pdf/2601.17309",
        "title": "PAR: Plausibility-aware Amortized Recourse Generation",
        "authors": [
            "Anagha Sabu",
            "Vidhya S",
            "Narayanan C Krishnan"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Algorithmic recourse aims to recommend actionable changes to a factual's attributes that flip an unfavorable model decision while remaining realistic and feasible. We formulate recourse as a Constrained Maximum A-Posteriori (MAP) inference problem under the accepted-class data distribution seeking counterfactuals with high likelihood while respecting other recourse constraints. We present PAR, an amortized approximate inference procedure that generates highly likely recourses efficiently. Recourse likelihood is estimated directly using tractable probabilistic models that admit exact likelihood evaluation and efficient gradient propagation that is useful during training. The recourse generator is trained with the objective of maximizing the likelihood under the accepted-class distribution while minimizing the likelihood under the denied-class distribution and other losses that encode recourse constraints. Furthermore, PAR includes a neighborhood-based conditioning mechanism to promote recourse generation that is customized to a factual. We validate PAR on widely used algorithmic recourse datasets and demonstrate its efficiency in generating recourses that are valid, similar to the factual, sparse, and highly plausible, yielding superior performance over existing state-of-the-art approaches.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 30,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17329",
        "abs_url": "https://arxiv.org/abs/2601.17329",
        "pdf_url": "https://arxiv.org/pdf/2601.17329",
        "title": "Conformal Feedback Alignment: Quantifying Answer-Level Reliability for Robust LLM Alignment",
        "authors": [
            "Tiejin Chen",
            "Xiaoou Liu",
            "Vishnu Nandam",
            "Kuan-Ru Liou",
            "Hua Wei"
        ],
        "comments": "Accetped to Findings of EACL",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Preference-based alignment like Reinforcement Learning from Human Feedback (RLHF) learns from pairwise preferences, yet the labels are often noisy and inconsistent. Existing uncertainty-aware approaches weight preferences, but ignore a more fundamental factor: the reliability of the \\emph{answers} being compared. To address the problem, we propose Conformal Feedback Alignment (CFA), a framework that grounds preference weighting in the statistical guarantees of Conformal Prediction (CP). CFA quantifies answer-level reliability by constructing conformal prediction sets with controllable coverage and aggregates these reliabilities into principled weights for both DPO- and PPO-style training. Experiments across different datasets show that CFA improves alignment robustness and data efficiency, highlighting that modeling \\emph{answer-side} uncertainty complements preference-level weighting and yields more robust, data-efficient alignment. Codes are provided here.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 31,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17334",
        "abs_url": "https://arxiv.org/abs/2601.17334",
        "pdf_url": "https://arxiv.org/pdf/2601.17334",
        "title": "Power-based Partial Attention: Bridging Linear-Complexity and Full Attention",
        "authors": [
            "Yufeng Huang"
        ],
        "comments": "12 pages, 3 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "It is widely accepted from transformer research that \"attention is all we need\", but the amount of attention required has never been systematically quantified. Is quadratic $O(L^2)$ attention necessary, or is there a sub-quadratic attention mechanism that can achieve comparable performance? To answer this question, we introduce power-based partial attention (PPA), an attention mechanism of order $O(L^{1+p})$, where $0 \\leq p \\leq 1$, such that $p=0$ corresponds to sliding window attention with linear complexity, and $p=1$ corresponds to full attention. With this attention construction, we can explore how transformer architecture performance varies as a function of the attention scaling behavior controlled by $p$. The overall trend from our experiments shows an S-curve-like behavior where the performance transitions from sliding-window (linear-complexity) attention to full attention over a narrow window of $p$ values, and plateaus as $p$ approaches $1$. In our experiments, we show that there exists $0<p<1$ such that $O(L^{1+p})$ attention is sufficient to achieve similar results as $O(L^2)$ full attention.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 32,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17357",
        "abs_url": "https://arxiv.org/abs/2601.17357",
        "pdf_url": "https://arxiv.org/pdf/2601.17357",
        "title": "Spectral Geometry for Deep Learning: Compression and Hallucination Detection via Random Matrix Theory",
        "authors": [
            "Davide Ettori"
        ],
        "comments": "Master thesis, MS in Computer Science, University of Illinois Chicago, defended November 21, 2025",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Large language models and deep neural networks achieve strong performance but suffer from reliability issues and high computational cost. This thesis proposes a unified framework based on spectral geometry and random matrix theory to address both problems by analyzing the eigenvalue structure of hidden activations. The first contribution, EigenTrack, is a real-time method for detecting hallucinations and out-of-distribution behavior in language and vision-language models using spectral features and their temporal dynamics. The second contribution, RMT-KD, is a principled compression method that identifies informative spectral components and applies iterative knowledge distillation to produce compact and efficient models while preserving accuracy. Together, these results show that spectral statistics provide interpretable and robust signals for monitoring uncertainty and guiding compression in large-scale neural networks.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 33,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17376",
        "abs_url": "https://arxiv.org/abs/2601.17376",
        "pdf_url": "https://arxiv.org/pdf/2601.17376",
        "title": "Diversified Scaling Inference in Time Series Foundation Models",
        "authors": [
            "Ruijin Hua",
            "Zichuan Liu",
            "Kun Zhang",
            "Yiyuan Yang"
        ],
        "comments": "23 pages, 16 figures, 9 tables",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "The advancement of Time Series Foundation Models (TSFMs) has been driven primarily by large-scale pre-training, but inference-time compute potential remains largely untapped. This work systematically investigates two questions: how do TSFMs behave under standard sampling-based inference scaling, and can controlled sampling diversity enhance performance? We first examine the properties of TSFMs under standard sampling often fail to adhere to scaling laws due to insufficient exploration of the solution space. Building on this, we then delve into diversified inference scaling via tailored time series perturbations to expand the generative distribution's support. We theoretically analyze the diversity-fidelity trade-off and derive a critical sample threshold for diversified sampling to outperform standard sampling. Extensive experiments across various TSFMs and datasets show proper diversified inference scaling yields substantial performance gains without parameter updates, establishing inference design as a critical, compute-efficient dimension of TSFM optimization. As an application, we propose RobustMSE, a rigorous metric to quantify the headroom performance of TSFM under a fixed budget. Overall, our findings clarify these factor interactions, enabling reliable performance via diverse large-scale inference time series in parallel environments without re-training TSFMs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 34,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17407",
        "abs_url": "https://arxiv.org/abs/2601.17407",
        "pdf_url": "https://arxiv.org/pdf/2601.17407",
        "title": "Efficient Dilated Squeeze and Excitation Neural Operator for Differential Equations",
        "authors": [
            "Prajwal Chauhan",
            "Salah Eddine Choutri",
            "Saif Eddin Jabari"
        ],
        "comments": "Accepted to Transactions on Machine Learning Research (TMLR)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Fast and accurate surrogates for physics-driven partial differential equations (PDEs) are essential in fields such as aerodynamics, porous media design, and flow control. However, many transformer-based models and existing neural operators remain parameter-heavy, resulting in costly training and sluggish deployment. We propose D-SENO (Dilated Squeeze-Excitation Neural Operator), a lightweight operator learning framework for efficiently solving a wide range of PDEs, including airfoil potential flow, Darcy flow in porous media, pipe Poiseuille flow, and incompressible Navier Stokes vortical fields. D-SENO combines dilated convolution (DC) blocks with squeeze-and-excitation (SE) modules to jointly capture wide receptive fields and dynamics alongside channel-wise attention, enabling both accurate and efficient PDE inference. Carefully chosen dilation rates allow the receptive field to focus on critical regions, effectively modeling long-range physical dependencies. Meanwhile, the SE modules adaptively recalibrate feature channels to emphasize dynamically relevant scales. Our model achieves training speed of up to approximately $20\\times$ faster than standard transformer-based models and neural operators, while also surpassing (or matching) them in accuracy across multiple PDE benchmarks. Ablation studies show that removing the SE modules leads to a slight drop in performance.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 35,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17430",
        "abs_url": "https://arxiv.org/abs/2601.17430",
        "pdf_url": "https://arxiv.org/pdf/2601.17430",
        "title": "Active Hypothesis Testing for Correlated Combinatorial Anomaly Detection",
        "authors": [
            "Zichuan Yang",
            "Yiming Xing"
        ],
        "comments": "47 pages, 26 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study the problem of identifying an anomalous subset of streams under correlated noise, motivated by monitoring and security in cyber-physical systems. This problem can be viewed as a form of combinatorial pure exploration, where each stream plays the role of an arm and measurements must be allocated sequentially under uncertainty. Existing combinatorial bandit and hypothesis testing methods typically assume independent observations and fail to exploit correlation for efficient measurement design. We propose ECC-AHT, an adaptive algorithm that selects continuous, constrained measurements to maximize Chernoff information between competing hypotheses, enabling active noise cancellation through differential sensing. ECC-AHT achieves optimal sample complexity guarantees and significantly outperforms state-of-the-art baselines in both synthetic and real-world correlated environments. The code is available on this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 36,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17449",
        "abs_url": "https://arxiv.org/abs/2601.17449",
        "pdf_url": "https://arxiv.org/pdf/2601.17449",
        "title": "DREAM: Dual-Standard Semantic Homogeneity with Dynamic Optimization for Graph Learning with Label Noise",
        "authors": [
            "Yusheng Zhao",
            "Jiaye Xie",
            "Qixin Zhang",
            "Weizhi Zhang",
            "Xiao Luo",
            "Zhiping Xiao",
            "Philip S. Yu",
            "Ming Zhang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph neural networks (GNNs) have been widely used in various graph machine learning scenarios. Existing literature primarily assumes well-annotated training graphs, while the reliability of labels is not guaranteed in real-world scenarios. Recently, efforts have been made to address the problem of graph learning with label noise. However, existing methods often (i) struggle to distinguish between reliable and unreliable nodes, and (ii) overlook the relational information embedded in the graph topology. To tackle this problem, this paper proposes a novel method, Dual-Standard Semantic Homogeneity with Dynamic Optimization (DREAM), for reliable, relation-informed optimization on graphs with label noise. Specifically, we design a relation-informed dynamic optimization framework that iteratively reevaluates the reliability of each labeled node in the graph during the optimization process according to the relation of the target node and other nodes. To measure this relation comprehensively, we propose a dual-standard selection strategy that selects a set of anchor nodes based on both node proximity and graph topology. Subsequently, we compute the semantic homogeneity between the target node and the anchor nodes, which serves as guidance for optimization. We also provide a rigorous theoretical analysis to justify the design of DREAM. Extensive experiments are performed on six graph datasets across various domains under three types of graph label noise against competing baselines, and the results demonstrate the effectiveness of the proposed DREAM.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 37,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17467",
        "abs_url": "https://arxiv.org/abs/2601.17467",
        "pdf_url": "https://arxiv.org/pdf/2601.17467",
        "title": "Harnessing Reasoning Trajectories for Hallucination Detection via Answer-agreement Representation Shaping",
        "authors": [
            "Jianxiong Zhang",
            "Bing Guo",
            "Yuming Jiang",
            "Haobo Wang",
            "Bo An",
            "Xuefeng Du"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large reasoning models (LRMs) often generate long, seemingly coherent reasoning traces yet still produce incorrect answers, making hallucination detection challenging. Although trajectories contain useful signals, directly using trace text or vanilla hidden states for detection is brittle: traces vary in form and detectors can overfit to superficial patterns rather than answer validity. We introduce Answer-agreement Representation Shaping (ARS), which learns detection-friendly trace-conditioned representations by explicitly encoding answer stability. ARS generates counterfactual answers through small latent interventions, specifically, perturbing the trace-boundary embedding, and labels each perturbation by whether the resulting answer agrees with the original. It then learns representations that bring answer-agreeing states together and separate answer-disagreeing ones, exposing latent instability indicative of hallucination risk. The shaped embeddings are plug-and-play with existing embedding-based detectors and require no human annotations during training. Experiments demonstrate that ARS consistently improves detection and achieves substantial gains over strong baselines.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 38,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17469",
        "abs_url": "https://arxiv.org/abs/2601.17469",
        "pdf_url": "https://arxiv.org/pdf/2601.17469",
        "title": "Identifying and Correcting Label Noise for Robust GNNs via Influence Contradiction",
        "authors": [
            "Wei Ju",
            "Wei Zhang",
            "Siyu Yi",
            "Zhengyang Mao",
            "Yifan Wang",
            "Jingyang Yuan",
            "Zhiping Xiao",
            "Ziyue Qiao",
            "Ming Zhang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Graph Neural Networks (GNNs) have shown remarkable capabilities in learning from graph-structured data with various applications such as social analysis and bioinformatics. However, the presence of label noise in real scenarios poses a significant challenge in learning robust GNNs, and their effectiveness can be severely impacted when dealing with noisy labels on graphs, often stemming from annotation errors or inconsistencies. To address this, in this paper we propose a novel approach called ICGNN that harnesses the structure information of the graph to effectively alleviate the challenges posed by noisy labels. Specifically, we first design a novel noise indicator that measures the influence contradiction score (ICS) based on the graph diffusion matrix to quantify the credibility of nodes with clean labels, such that nodes with higher ICS values are more likely to be detected as having noisy labels. Then we leverage the Gaussian mixture model to precisely detect whether the label of a node is noisy or not. Additionally, we develop a soft strategy to combine the predictions from neighboring nodes on the graph to correct the detected noisy labels. At last, pseudo-labeling for abundant unlabeled nodes is incorporated to provide auxiliary supervision signals and guide the model optimization. Experiments on benchmark datasets show the superiority of our proposed approach.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 39,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17473",
        "abs_url": "https://arxiv.org/abs/2601.17473",
        "pdf_url": "https://arxiv.org/pdf/2601.17473",
        "title": "LeanTutor: Towards a Verified AI Mathematical Proof Tutor",
        "authors": [
            "Manooshree Patel",
            "Rayna Bhattacharyya",
            "Thomas Lu",
            "Arnav Mehta",
            "Niels Voss",
            "Narges Norouzi",
            "Gireeja Ranade"
        ],
        "comments": "arXiv admin note: substantial text overlap with arXiv:2506.08321. substantial text overlap with arXiv:2506.08321. substantial text overlap with arXiv:2506.08321. substantial text overlap with arXiv:2506.08321",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper considers the development of an AI-based provably-correct mathematical proof tutor. While Large Language Models (LLMs) allow seamless communication in natural language, they are error prone. Theorem provers such as Lean allow for provable-correctness, but these are hard for students to learn. We present a proof-of-concept system (LeanTutor) by combining the complementary strengths of LLMs and theorem provers. LeanTutor is composed of three modules: (i) an autoformalizer/proof-checker, (ii) a next-step generator, and (iii) a natural language feedback generator. To evaluate the system, we introduce PeanoBench, a dataset of 371 Peano Arithmetic proofs in human-written natural language and formal language, derived from the Natural Numbers Game.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 40,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17483",
        "abs_url": "https://arxiv.org/abs/2601.17483",
        "pdf_url": "https://arxiv.org/pdf/2601.17483",
        "title": "Automatic Stability and Recovery for Neural Network Training",
        "authors": [
            "Barak Or"
        ],
        "comments": "Under Review",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Training modern neural networks is increasingly fragile, with rare but severe destabilizing updates often causing irreversible divergence or silent performance degradation. Existing optimization methods primarily rely on preventive mechanisms embedded within the optimizer, offering limited ability to detect and recover from instability once it occurs. We introduce a supervisory runtime stability framework that treats optimization as a controlled stochastic process. By isolating an innovation signal derived from secondary measurements, such as validation probes, the framework enables automatic detection and recovery from destabilizing updates without modifying the underlying optimizer. We provide theoretical runtime safety guarantees that formalize bounded degradation and recovery. Our implementation incurs minimal overhead and is compatible with memory-constrained training settings.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 41,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17495",
        "abs_url": "https://arxiv.org/abs/2601.17495",
        "pdf_url": "https://arxiv.org/pdf/2601.17495",
        "title": "PEARL: Prototype-Enhanced Alignment for Label-Efficient Representation Learning with Deployment-Driven Insights from Digital Governance Communication Systems",
        "authors": [
            "Ruiyu Zhang",
            "Lin Nie",
            "Wai-Fung Lam",
            "Qihao Wang",
            "Xin Zhao"
        ],
        "comments": "15 pages, 1 figure",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)",
        "abstract": "In many deployed systems, new text inputs are handled by retrieving similar past cases, for example when routing and responding to citizen messages in digital governance platforms. When these systems fail, the problem is often not the language model itself, but that the nearest neighbors in the embedding space correspond to the wrong cases. Modern machine learning systems increasingly rely on fixed, high-dimensional embeddings produced by large pretrained models and sentence encoders. In real-world deployments, labels are scarce, domains shift over time, and retraining the base encoder is expensive or infeasible. As a result, downstream performance depends heavily on embedding geometry. Yet raw embeddings are often poorly aligned with the local neighborhood structure required by nearest-neighbor retrieval, similarity search, and lightweight classifiers that operate directly on embeddings. We propose PEARL (Prototype-Enhanced Aligned Representation Learning), a label-efficient approach that uses limited supervision to softly align embeddings toward class prototypes. The method reshapes local neighborhood geometry while preserving dimensionality and avoiding aggressive projection or collapse. Its aim is to bridge the gap between purely unsupervised post-processing, which offers limited and inconsistent gains, and fully supervised projections that require substantial labeled data. We evaluate PEARL under controlled label regimes ranging from extreme label scarcity to higher-label settings. In the label-scarce condition, PEARL substantially improves local neighborhood quality, yielding 25.7% gains over raw embeddings and more than 21.1% gains relative to strong unsupervised post-processing, precisely in the regime where similarity-based systems are most brittle.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 42,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17512",
        "abs_url": "https://arxiv.org/abs/2601.17512",
        "pdf_url": "https://arxiv.org/pdf/2601.17512",
        "title": "One-Shot Federated Clustering of Non-Independent Completely Distributed Data",
        "authors": [
            "Yiqun Zhang",
            "Shenghong Cai",
            "Zihua Yang",
            "Sen Feng",
            "Yuzhu Ji",
            "Haijun Zhang"
        ],
        "comments": "This work has been accepted for publication in IEEE Internet of Things Journal",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Federated Learning (FL) that extracts data knowledge while protecting the privacy of multiple clients has achieved remarkable results in distributed privacy-preserving IoT systems, including smart traffic flow monitoring, smart grid load balancing, and so on. Since most data collected from edge devices are unlabeled, unsupervised Federated Clustering (FC) is becoming increasingly popular for exploring pattern knowledge from complex distributed data. However, due to the lack of label guidance, the common Non-Independent and Identically Distributed (Non-IID) issue of clients have greatly challenged FC by posing the following problems: How to fuse pattern knowledge (i.e., cluster distribution) from Non-IID clients; How are the cluster distributions among clients related; and How does this relationship connect with the global knowledge fusion? In this paper, a more tricky but overlooked phenomenon in Non-IID is revealed, which bottlenecks the clustering performance of the existing FC approaches. That is, different clients could fragment a cluster, and accordingly, a more generalized Non-IID concept, i.e., Non-ICD (Non-Independent Completely Distributed), is derived. To tackle the above FC challenges, a new framework named GOLD (Global Oriented Local Distribution Learning) is proposed. GOLD first finely explores the potential incomplete local cluster distributions of clients, then uploads the distribution summarization to the server for global fusion, and finally performs local cluster enhancement under the guidance of the global distribution. Extensive experiments, including significance tests, ablation studies, scalability evaluations, qualitative results, etc., have been conducted to show the superiority of GOLD.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 43,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17570",
        "abs_url": "https://arxiv.org/abs/2601.17570",
        "pdf_url": "https://arxiv.org/pdf/2601.17570",
        "title": "Quantum-Inspired Episode Selection for Monte Carlo Reinforcement Learning via QUBO Optimization",
        "authors": [
            "Hadi Salloum",
            "Ali Jnadi",
            "Yaroslav Kholodov",
            "Alexander Gasnikov"
        ],
        "comments": "Proceedings of Machine Learning Research tbd: 1_13, 2025 International Conference on Computational Optimization",
        "subjects": "Machine Learning (cs.LG); Robotics (cs.RO)",
        "abstract": "Monte Carlo (MC) reinforcement learning suffers from high sample complexity, especially in environments with sparse rewards, large state spaces, and correlated trajectories. We address these limitations by reformulating episode selection as a Quadratic Unconstrained Binary Optimization (QUBO) problem and solving it with quantum-inspired samplers. Our method, MC+QUBO, integrates a combinatorial filtering step into standard MC policy evaluation: from each batch of trajectories, we select a subset that maximizes cumulative reward while promoting state-space coverage. This selection is encoded as a QUBO, where linear terms favor high-reward episodes and quadratic terms penalize redundancy. We explore both Simulated Quantum Annealing (SQA) and Simulated Bifurcation (SB) as black-box solvers within this framework. Experiments in a finite-horizon GridWorld demonstrate that MC+QUBO outperforms vanilla MC in convergence speed and final policy quality, highlighting the potential of quantum-inspired optimization as a decision-making subroutine in reinforcement learning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 44,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17602",
        "abs_url": "https://arxiv.org/abs/2601.17602",
        "pdf_url": "https://arxiv.org/pdf/2601.17602",
        "title": "Understanding Transformer Encoder-Decoder Representations through Bernoulli Dropout",
        "authors": [
            "Xuanzhou Chen"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We study Transformer overparameterization through the lens of angular similarity in high-dimensional encoder-decoder embeddings. We apply Bernoulli dropout between the encoder and the decoder, varying the keep probability $p$ to identify a sparsity-dependent threshold above which the Top-1 prediction is preserved. Theoretically, we prove that, if the effective sparsity embeddings is sufficiently large, and thus decoder performance, remain stable under moderate coordinate dropout. Empirically, we implement the Bernoulli dropout by constructing a new Transformer model augmented with Binary Erasure Channel (BEC) and test its performance on an English-French translation task. Experimental results visualize the trends for validation accuracies and BLEU scores, both decline sharply at some threshold.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 45,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17607",
        "abs_url": "https://arxiv.org/abs/2601.17607",
        "pdf_url": "https://arxiv.org/pdf/2601.17607",
        "title": "A Thermodynamic Theory of Learning I: Irreversible Ensemble Transport and Epistemic Costs",
        "authors": [
            "Daisuke Okanohara"
        ],
        "comments": "9 pages. Part I of a planned series entitled \"A Thermodynamic Theory of Learning.\"",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Learning systems acquire structured internal representations from data, yet classical information-theoretic results state that deterministic transformations do not increase information. This raises a fundamental question: how can learning produce abstraction and insight without violating information-theoretic limits? We argue that learning is inherently an irreversible process when performed over finite time, and that the realization of epistemic structure necessarily incurs entropy production. To formalize this perspective, we model learning as a transport process in the space of probability distributions over model configurations and introduce an epistemic free-energy framework. Within this framework, we define the free-energy drop as a bookkeeping quantity that records the total reduction of epistemic free energy along a learning trajectory. This reduction decomposes into a reversible component associated with potential improvement and an irreversible component corresponding to entropy production. We then derive the Epistemic Speed Limit (ESL), a finite-time inequality that lower-bounds the minimal entropy production required by any learning process to realize a given distributional transformation. This bound depends only on the Wasserstein distance between initial and final ensemble distributions and is independent of the specific learning algorithm.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 46,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17616",
        "abs_url": "https://arxiv.org/abs/2601.17616",
        "pdf_url": "https://arxiv.org/pdf/2601.17616",
        "title": "Split-on-Share: Mixture of Sparse Experts for Task-Agnostic Continual Learning",
        "authors": [
            "Fatema Siddika",
            "Md Anwar Hossen",
            "Tanwi Mallick",
            "Ali Jannesari"
        ],
        "comments": "17 pages, 9 figures, 8 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Continual learning in Large Language Models (LLMs) is hindered by the plasticity-stability dilemma, where acquiring new capabilities often leads to catastrophic forgetting of previous knowledge. Existing methods typically treat parameters uniformly, failing to distinguish between specific task knowledge and shared capabilities. We introduce Mixture of Sparse Experts for Task-Agnostic Continual Learning, referred to as SETA, a framework that resolves the plasticity-stability conflict by decomposing the model into modular subspaces. Unlike standard updates, where tasks compete for the same parameters, SETA separates knowledge into unique experts, designed to isolate task-specific patterns, and shared experts, responsible for capturing common features. This structure is maintained through elastic weight anchoring, which protects critical shared knowledge and enables a unified gating network to automatically retrieve the correct expert combination for each task during inference. Extensive experiments across diverse domain-specific and general benchmarks demonstrate that SETA consistently outperforms state-of-the-art parameter-efficient fine-tuning-based continual learning methods.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 47,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17641",
        "abs_url": "https://arxiv.org/abs/2601.17641",
        "pdf_url": "https://arxiv.org/pdf/2601.17641",
        "title": "RPNT: Robust Pre-trained Neural Transformer -- A Pathway for Generalized Motor Decoding",
        "authors": [
            "Hao Fang",
            "Ryan A. Canfield",
            "Tomohiro Ouchi",
            "Beatrice Macagno",
            "Eli Shlizerman",
            "Amy L. Orsborn"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Signal Processing (eess.SP)",
        "abstract": "Brain decoding aims to interpret and translate neural activity into behaviors. As such, it is imperative that decoding models are able to generalize across variations, such as recordings from different brain sites, distinct sessions, different types of behavior, and a variety of subjects. Current models can only partially address these challenges and warrant the development of pretrained neural transformer models capable to adapt and generalize. In this work, we propose RPNT - Robust Pretrained Neural Transformer, designed to achieve robust generalization through pretraining, which in turn enables effective finetuning given a downstream task. In particular, RPNT unique components include 1) Multidimensional rotary positional embedding (MRoPE) to aggregate experimental metadata such as site coordinates, session name and behavior types; 2) Context-based attention mechanism via convolution kernels operating on global attention to learn local temporal structures for handling non-stationarity of neural population activity; 3) Robust self-supervised learning (SSL) objective with uniform causal masking strategies and contrastive representations. We pretrained two separate versions of RPNT on distinct datasets a) Multi-session, multi-task, and multi-subject microelectrode benchmark; b) Multi-site recordings using high-density Neuropixel 1.0 probes. The datasets include recordings from the dorsal premotor cortex (PMd) and from the primary motor cortex (M1) regions of nonhuman primates (NHPs) as they performed reaching tasks. After pretraining, we evaluated the generalization of RPNT in cross-session, cross-type, cross-subject, and cross-site downstream behavior decoding tasks. Our results show that RPNT consistently achieves and surpasses the decoding performance of existing decoding models in all tasks.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 48,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17646",
        "abs_url": "https://arxiv.org/abs/2601.17646",
        "pdf_url": "https://arxiv.org/pdf/2601.17646",
        "title": "A Mosco sufficient condition for intrinsic stability of non-unique convex Empirical Risk Minimization",
        "authors": [
            "Karim Bounja",
            "Lahcen Laayouni",
            "Abdeljalil Sakat"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Functional Analysis (math.FA); Optimization and Control (math.OC); Statistics Theory (math.ST)",
        "abstract": "Empirical risk minimization (ERM) stability is usually studied via single-valued outputs, while convex non-strict losses yield set-valued minimizers. We identify Painlevé-Kuratowski upper semicontinuity (PK-u.s.c.) as the intrinsic stability notion for the ERM solution correspondence (set-level Hadamard well-posedness) and a prerequisite to interpret stability of selections. We then characterize a minimal non-degenerate qualitative regime: Mosco-consistent perturbations and locally bounded minimizers imply PK-u.s.c., minimal-value continuity, and consistency of vanishing-gap near-minimizers. Quadratic growth yields explicit quantitative deviation bounds.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 49,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17654",
        "abs_url": "https://arxiv.org/abs/2601.17654",
        "pdf_url": "https://arxiv.org/pdf/2601.17654",
        "title": "Kareus: Joint Reduction of Dynamic and Static Energy in Large Model Training",
        "authors": [
            "Ruofan Wu",
            "Jae-Won Chung",
            "Mosharaf Chowdhury"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "The computing demand of AI is growing at an unprecedented rate, but energy supply is not keeping pace. As a result, energy has become an expensive, contended resource that requires explicit management and optimization. Although recent works have made significant progress in large model training optimization, they focus only on a single aspect of energy consumption: dynamic or static energy. We find that fine-grained kernel scheduling and frequency scaling jointly and interdependently impact both dynamic and static energy consumption. Based on this finding, we design Kareus, a training system that pushes the time--energy tradeoff frontier by optimizing both aspects. Kareus decomposes the intractable joint optimization problem into local, partition-based subproblems. It then uses a multi-pass multi-objective optimization algorithm to find execution schedules that push the time--energy tradeoff frontier. Compared to the state of the art, Kareus reduces training energy by up to 28.3% at the same training time, or reduces training time by up to 27.5% at the same energy consumption.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 50,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17667",
        "abs_url": "https://arxiv.org/abs/2601.17667",
        "pdf_url": "https://arxiv.org/pdf/2601.17667",
        "title": "Entropic Risk-Aware Monte Carlo Tree Search",
        "authors": [
            "Pedro P. Santos",
            "Jacopo Silvestrin",
            "Alberto Sardinha",
            "Francisco S. Melo"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We propose a provably correct Monte Carlo tree search (MCTS) algorithm for solving \\textit{risk-aware} Markov decision processes (MDPs) with \\textit{entropic risk measure} (ERM) objectives. We provide a \\textit{non-asymptotic} analysis of our proposed algorithm, showing that the algorithm: (i) is \\textit{correct} in the sense that the empirical ERM obtained at the root node converges to the optimal ERM; and (ii) enjoys \\textit{polynomial regret concentration}. Our algorithm successfully exploits the dynamic programming formulations for solving risk-aware MDPs with ERM objectives introduced by previous works in the context of an upper confidence bound-based tree search algorithm. Finally, we provide a set of illustrative experiments comparing our risk-aware MCTS method against relevant baselines.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 51,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17668",
        "abs_url": "https://arxiv.org/abs/2601.17668",
        "pdf_url": "https://arxiv.org/pdf/2601.17668",
        "title": "Fast KVzip: Efficient and Accurate LLM Inference with Gated KV Eviction",
        "authors": [
            "Jang-Hyun Kim",
            "Dongyoon Han",
            "Sangdoo Yun"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "Efficient key-value (KV) cache management is crucial for the practical deployment of large language models (LLMs), yet existing compression techniques often incur a trade-off between performance degradation and computational overhead. We propose a novel gating-based KV cache eviction method for frozen-weight LLMs that achieves high compression ratios with negligible computational cost. Our approach introduces lightweight sink-attention gating modules to identify and retain critical KV pairs, and integrates seamlessly into both the prefill and decoding stages. The proposed gate training algorithm relies on forward passes of an LLM, avoiding expensive backpropagation, while achieving strong task generalization through a task-agnostic reconstruction objective. Extensive experiments across the Qwen2.5-1M, Qwen3, and Gemma3 families show that our method maintains near-lossless performance while evicting up to 70% of the KV cache. The results are consistent across a wide range of tasks, including long-context understanding, code comprehension, and mathematical reasoning, demonstrating the generality of our approach.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 52,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17680",
        "abs_url": "https://arxiv.org/abs/2601.17680",
        "pdf_url": "https://arxiv.org/pdf/2601.17680",
        "title": "$\\infty$-MoE: Generalizing Mixture of Experts to Infinite Experts",
        "authors": [
            "Shota Takashiro",
            "Takeshi Kojima",
            "Shohei Taniguchi",
            "Yusuke Iwasawa",
            "Yutaka Matsuo"
        ],
        "comments": "Accepted at EACL 2026 (Main)",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "The Mixture of Experts (MoE) selects a few feed-forward networks (FFNs) per token, achieving an effective trade-off between computational cost and performance. In conventional MoE, each expert is treated as entirely independent, and experts are combined in a discrete space. As a result, when the number of experts increases, it becomes difficult to train each expert effectively. To stabilize training while increasing the number of experts, we propose $\\infty$-MoE that selects a portion of the parameters of large FFNs based on continuous values sampled for each token. By considering experts in a continuous space, this approach allows for an infinite number of experts while maintaining computational efficiency. Experiments show that a GPT-2 Small-based $\\infty$-MoE model, with 129M active and 186M total parameters, achieves comparable performance to a dense GPT-2 Medium with 350M parameters. Adjusting the number of sampled experts at inference time allows for a flexible trade-off between accuracy and speed, with an improvement of up to 2.5\\% in accuracy over conventional MoE.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 53,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17689",
        "abs_url": "https://arxiv.org/abs/2601.17689",
        "pdf_url": "https://arxiv.org/pdf/2601.17689",
        "title": "REV-INR: Regularized Evidential Implicit Neural Representation for Uncertainty-Aware Volume Visualization",
        "authors": [
            "Shanu Saklani",
            "Tushar M. Athawale",
            "Nairita Pal",
            "David Pugmire",
            "Christopher R. Johnson",
            "Soumya Dutta"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Graphics (cs.GR)",
        "abstract": "Applications of Implicit Neural Representations (INRs) have emerged as a promising deep learning approach for compactly representing large volumetric datasets. These models can act as surrogates for volume data, enabling efficient storage and on-demand reconstruction via model predictions. However, conventional deterministic INRs only provide value predictions without insights into the model's prediction uncertainty or the impact of inherent noisiness in the data. This limitation can lead to unreliable data interpretation and visualization due to prediction inaccuracies in the reconstructed volume. Identifying erroneous results extracted from model-predicted data may be infeasible, as raw data may be unavailable due to its large size. To address this challenge, we introduce REV-INR, Regularized Evidential Implicit Neural Representation, which learns to predict data values accurately along with the associated coordinate-level data uncertainty and model uncertainty using only a single forward pass of the trained REV-INR during inference. By comprehensively comparing and contrasting REV-INR with existing well-established deep uncertainty estimation methods, we show that REV-INR achieves the best volume reconstruction quality with robust data (aleatoric) and model (epistemic) uncertainty estimates using the fastest inference time. Consequently, we demonstrate that REV-INR facilitates assessment of the reliability and trustworthiness of the extracted isosurfaces and volume visualization results, enabling analyses to be solely driven by model-predicted data.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 54,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17716",
        "abs_url": "https://arxiv.org/abs/2601.17716",
        "pdf_url": "https://arxiv.org/pdf/2601.17716",
        "title": "Do Reasoning Models Ask Better Questions? A Formal Information-Theoretic Analysis on Multi-Turn LLM Games",
        "authors": [
            "Daniel M. Pedrozo",
            "Telma W. de L. Soares",
            "Bryan L. M. de Oliveira"
        ],
        "comments": "Presented at the NeusymBridge Workshop at AAAI 2026",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large Language Models (LLMs) excel at many tasks but still struggle with a critical ability for LLM-based agents: asking good questions for resolving ambiguity in user requests. While prior work has explored information-seeking behavior through word games, existing benchmarks lack comprehensive evaluation frameworks that provide both final and intermediate signals based on Information Gain (IG). Moreover, they rarely provide systematic comparisons between models that use chain-of-thought reasoning and those that do not. We propose a multi-turn dialogue framework that quantitatively measures how effectively LLMs gather information through yes/no questions in a hierarchical knowledge graph environment. Our framework employs a triad of interacting LLM agents that ask questions, answer them, and update the hypothesis space. We adopt IG as the main metric, grounded in Shannon entropy, to assess query effectiveness at each turn and cumulatively. We instantiate our framework in a geographical Guess My City game setting organized in a five-level taxonomy and evaluate multiple LLM variants under fully and partially observable conditions, with and without Chain-of-Thought reasoning. Our experiments demonstrate that, among the evaluated models, the ones with explicit reasoning capabilities achieve higher IG per turn and reach solutions in fewer steps, particularly in partially observable settings. Analysis of reasoning traces reveals that smaller models compensate for limited capacity through more aggressive exploration of candidate questions, while larger models exhibit higher assertiveness in selecting optimal queries, generating candidates with greater potential IG.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 55,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17768",
        "abs_url": "https://arxiv.org/abs/2601.17768",
        "pdf_url": "https://arxiv.org/pdf/2601.17768",
        "title": "LLM-42: Enabling Determinism in LLM Inference with Verified Speculation",
        "authors": [
            "Raja Gond",
            "Aditya K Kamath",
            "Arkaprava Basu",
            "Ramachandran Ramjee",
            "Ashish Panwar"
        ],
        "comments": "this https URL",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "In LLM inference, the same prompt may yield different outputs across different runs. At the system level, this non-determinism arises from floating-point non-associativity combined with dynamic batching and GPU kernels whose reduction orders vary with batch size. A straightforward way to eliminate non-determinism is to disable dynamic batching during inference, but doing so severely degrades throughput. Another approach is to make kernels batch-invariant; however, this tightly couples determinism to kernel design, requiring new implementations. This coupling also imposes fixed runtime overheads, regardless of how much of the workload actually requires determinism. Inspired by ideas from speculative decoding, we present LLM-42, a scheduling-based approach to enable determinism in LLM inference. Our key observation is that if a sequence is in a consistent state, the next emitted token is likely to be consistent even with dynamic batching. Moreover, most GPU kernels use shape-consistent reductions. Leveraging these insights, LLM-42 decodes tokens using a non-deterministic fast path and enforces determinism via a lightweight verify-rollback loop. The verifier replays candidate tokens under a fixed-shape reduction schedule, commits those that are guaranteed to be consistent across runs, and rolls back those violating determinism. LLM-42 mostly re-uses existing kernels unchanged and incurs overhead only in proportion to the traffic that requires determinism.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 56,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17802",
        "abs_url": "https://arxiv.org/abs/2601.17802",
        "pdf_url": "https://arxiv.org/pdf/2601.17802",
        "title": "Robust Computational Extraction of Non-Enhancing Hypercellular Tumor Regions from Clinical Imaging Data",
        "authors": [
            "A. Brawanski",
            "Th. Schaffer",
            "F. Raab",
            "K.-M. Schebesch",
            "M. Schrey",
            "Chr. Doenitz",
            "A. M. Tomé",
            "E. W. Lang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Accurate identification of non-enhancing hypercellular (NEH) tumor regions is an unmet need in neuro-oncological imaging, with significant implications for patient management and treatment planning. We present a robust computational framework that generates probability maps of NEH regions from routine MRI data, leveraging multiple network architectures to address the inherent variability and lack of clear imaging boundaries. Our approach was validated against independent clinical markers -- relative cerebral blood volume (rCBV) and enhancing tumor recurrence location (ETRL) -- demonstrating both methodological robustness and biological relevance. This framework enables reliable, non-invasive mapping of NEH tumor compartments, supporting their integration as imaging biomarkers in clinical workflows and advancing precision oncology for brain tumor patients.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 57,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17883",
        "abs_url": "https://arxiv.org/abs/2601.17883",
        "pdf_url": "https://arxiv.org/pdf/2601.17883",
        "title": "EEG Foundation Models: Progresses, Benchmarking, and Open Problems",
        "authors": [
            "Dingkun Liu",
            "Yuheng Chen",
            "Zhu Chen",
            "Zhenyao Cui",
            "Yaozhi Wen",
            "Jiayu An",
            "Jingwei Luo",
            "Dongrui Wu"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Electroencephalography (EEG) foundation models have recently emerged as a promising paradigm for brain-computer interfaces (BCIs), aiming to learn transferable neural representations from large-scale heterogeneous recordings. Despite rapid progresses, there lacks fair and comprehensive comparisons of existing EEG foundation models, due to inconsistent pre-training objectives, preprocessing choices, and downstream evaluation protocols. This paper fills this gap. We first review 50 representative models and organize their design choices into a unified taxonomic framework including data standardization, model architectures, and self-supervised pre-training strategies. We then evaluate 12 open-source foundation models and competitive specialist baselines across 13 EEG datasets spanning nine BCI paradigms. Emphasizing real-world deployments, we consider both cross-subject generalization under a leave-one-subject-out protocol and rapid calibration under a within-subject few-shot setting. We further compare full-parameter fine-tuning with linear probing to assess the transferability of pre-trained representations, and examine the relationship between model scale and downstream performance. Our results indicate that: 1) linear probing is frequently insufficient; 2) specialist models trained from scratch remain competitive across many tasks; and, 3) larger foundation models do not necessarily yield better generalization performance under current data regimes and training practices.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 58,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17910",
        "abs_url": "https://arxiv.org/abs/2601.17910",
        "pdf_url": "https://arxiv.org/pdf/2601.17910",
        "title": "Adaptive Weighting in Knowledge Distillation: An Axiomatic Framework for Multi-Scale Teacher Ensemble Optimization",
        "authors": [
            "Aaron R. Flouro",
            "Shawn P. Chadwick"
        ],
        "comments": "12 pages, 1 figure, 1 table",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Knowledge distillation with multiple teachers is increasingly used to improve robustness, efficiency, and safety, yet existing approaches rely largely on heuristic or implementation-specific weighting schemes. This paper develops an operator-agnostic axiomatic framework for adaptive weighting in multi-teacher knowledge distillation across three complementary scales: token, task, and context. We formalize structural conditions under which adaptive weighting operators are well-defined, admit multiple non-equivalent implementations, and can be hierarchically composed via product-structure normalization. Within this framework, we establish existence and non-uniqueness of conforming operators, characterize convergence of gradient-based optimization under standard assumptions, analyze stability and perturbation robustness, and provide an abstract formulation of safety-constrained distillation. The results decouple theoretical guarantees from specific weighting formulas, enabling principled analysis of adaptive distillation methods under heterogeneity, distribution shift, and safety constraints.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 59,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17912",
        "abs_url": "https://arxiv.org/abs/2601.17912",
        "pdf_url": "https://arxiv.org/pdf/2601.17912",
        "title": "Causal Pre-training Under the Fairness Lens: An Empirical Study of TabPFN",
        "authors": [
            "Qinyi Liu",
            "Mohammad Khalil",
            "Naman Goel"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Foundation models for tabular data, such as the Tabular Prior-data Fitted Network (TabPFN), are pre-trained on a massive number of synthetic datasets generated by structural causal models (SCM). They leverage in-context learning to offer high predictive accuracy in real-world tasks. However, the fairness properties of these foundational models, which incorporate ideas from causal reasoning during pre-training, have not yet been explored in sufficient depth. In this work, we conduct a comprehensive empirical evaluation of TabPFN and its fine-tuned variants, assessing predictive performance, fairness, and robustness across varying dataset sizes and distributional shifts. Our results reveal that while TabPFN achieves stronger predictive accuracy compared to baselines and exhibits robustness to spurious correlations, improvements in fairness are moderate and inconsistent, particularly under missing-not-at-random (MNAR) covariate shifts. These findings suggest that the causal pre-training in TabPFN is helpful but insufficient for algorithmic fairness, highlighting implications for deploying such models in practice and the need for further fairness interventions.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 60,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17916",
        "abs_url": "https://arxiv.org/abs/2601.17916",
        "pdf_url": "https://arxiv.org/pdf/2601.17916",
        "title": "UniPACT: A Multimodal Framework for Prognostic Question Answering on Raw ECG and Structured EHR",
        "authors": [
            "Jialu Tang",
            "Tong Xia",
            "Yuan Lu",
            "Aaqib Saeed"
        ],
        "comments": "Accepted to IEEE ICASSP 2026",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Accurate clinical prognosis requires synthesizing structured Electronic Health Records (EHRs) with real-time physiological signals like the Electrocardiogram (ECG). Large Language Models (LLMs) offer a powerful reasoning engine for this task but struggle to natively process these heterogeneous, non-textual data types. To address this, we propose UniPACT (Unified Prognostic Question Answering for Clinical Time-series), a unified framework for prognostic question answering that bridges this modality gap. UniPACT's core contribution is a structured prompting mechanism that converts numerical EHR data into semantically rich text. This textualized patient context is then fused with representations learned directly from raw ECG waveforms, enabling an LLM to reason over both modalities holistically. We evaluate UniPACT on the comprehensive MDS-ED benchmark, it achieves a state-of-the-art mean AUROC of 89.37% across a diverse set of prognostic tasks including diagnosis, deterioration, ICU admission, and mortality, outperforming specialized baselines. Further analysis demonstrates that our multimodal, multi-task approach is critical for performance and provides robustness in missing data scenarios.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 61,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17933",
        "abs_url": "https://arxiv.org/abs/2601.17933",
        "pdf_url": "https://arxiv.org/pdf/2601.17933",
        "title": "Dissipative Learning: A Framework for Viable Adaptive Systems",
        "authors": [
            "Laurent Caraffa"
        ],
        "comments": "68 pages, 14 figures",
        "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "We propose a perspective in which learning is an intrinsically dissipative process. Forgetting and regularization are not heuristic add-ons but structural requirements for adaptive systems. Drawing on information theory, thermodynamics, and information geometry, we introduce the BEDS (Bayesian Emergent Dissipative Structures) framework, modeling learning as the evolution of compressed belief states under dissipation constraints. A central contribution is the Conditional Optimality Theorem, showing that Fisher-Rao regularization measuring change via information divergence rather than Euclidean distance is the unique thermodynamically optimal regularization strategy, achieving minimal dissipation. Euclidean regularization is shown to be structurally suboptimal. The framework unifies existing methods (Ridge, SIGReg, EMA, SAC) as special cases of a single governing equation. Within this view, overfitting corresponds to over-crystallization, while catastrophic forgetting reflects insufficient dissipation control. The framework distinguishes BEDS-crystallizable problems, where beliefs converge to stable equilibria, from BEDS-maintainable problems, which require continual adaptation. It extends naturally to continual and multi-agent systems, where viability, stability under adaptation and finite resources replaces asymptotic optimality as the primary criterion. Overall, this work reframes learning as maintaining viable belief states under dissipation constraints, providing a principled lens on forgetting, regularization, and stability.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 62,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17935",
        "abs_url": "https://arxiv.org/abs/2601.17935",
        "pdf_url": "https://arxiv.org/pdf/2601.17935",
        "title": "FedGraph-VASP: Privacy-Preserving Federated Graph Learning with Post-Quantum Security for Cross-Institutional Anti-Money Laundering",
        "authors": [
            "Daniel Commey",
            "Matilda Nkoom",
            "Yousef Alsenani",
            "Sena G. Hounsinou",
            "Garth V. Crosby"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Cryptography and Security (cs.CR); Social and Information Networks (cs.SI)",
        "abstract": "Virtual Asset Service Providers (VASPs) face a fundamental tension between regulatory compliance and user privacy when detecting cross-institutional money laundering. Current approaches require either sharing sensitive transaction data or operating in isolation, leaving critical cross-chain laundering patterns undetected. We present FedGraph-VASP, a privacy-preserving federated graph learning framework that enables collaborative anti-money laundering (AML) without exposing raw user data. Our key contribution is a Boundary Embedding Exchange protocol that shares only compressed, non-invertible graph neural network representations of boundary accounts. These exchanges are secured using post-quantum cryptography, specifically the NIST-standardized Kyber-512 key encapsulation mechanism combined with AES-256-GCM authenticated encryption. Experiments on the Elliptic Bitcoin dataset with realistic Louvain partitioning show that FedGraph-VASP achieves an F1-score of 0.508, outperforming the state-of-the-art generative baseline FedSage+ (F1 = 0.453) by 12.1 percent on binary fraud detection. We further show robustness under low-connectivity settings where generative imputation degrades performance, while approaching centralized performance (F1 = 0.620) in high-connectivity regimes. We additionally evaluate generalization on an Ethereum fraud detection dataset, where FedGraph-VASP (F1 = 0.635) is less effective under sparse cross-silo connectivity, while FedSage+ excels (F1 = 0.855), outperforming even local training (F1 = 0.785). These results highlight a topology-dependent trade-off: embedding exchange benefits connected transaction graphs, whereas generative imputation can dominate in highly modular sparse graphs. A privacy audit shows embeddings are only partially invertible (R^2 = 0.32), limiting exact feature recovery.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 63,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17954",
        "abs_url": "https://arxiv.org/abs/2601.17954",
        "pdf_url": "https://arxiv.org/pdf/2601.17954",
        "title": "Scaling Effects and Uncertainty Quantification in Neural Actor Critic Algorithms",
        "authors": [
            "Nikos Georgoudios",
            "Konstantinos Spiliopoulos",
            "Justin Sirignano"
        ],
        "comments": "72 pages, 2 figures",
        "subjects": "Machine Learning (cs.LG); Probability (math.PR)",
        "abstract": "We investigate the neural Actor Critic algorithm using shallow neural networks for both the Actor and Critic models. The focus of this work is twofold: first, to compare the convergence properties of the network outputs under various scaling schemes as the network width and the number of training steps tend to infinity; and second, to provide precise control of the approximation error associated with each scaling regime. Previous work has shown convergence to ordinary differential equations with random initial conditions under inverse square root scaling in the network width. In this work, we shift the focus from convergence speed alone to a more comprehensive statistical characterization of the algorithm's output, with the goal of quantifying uncertainty in neural Actor Critic methods. Specifically, we study a general inverse polynomial scaling in the network width, with an exponent treated as a tunable hyperparameter taking values strictly between one half and one. We derive an asymptotic expansion of the network outputs, interpreted as statistical estimators, in order to clarify their structure. To leading order, we show that the variance decays as a power of the network width, with an exponent equal to one half minus the scaling parameter, implying improved statistical robustness as the scaling parameter approaches one. Numerical experiments support this behavior and further suggest faster convergence for this choice of scaling. Finally, our analysis yields concrete guidelines for selecting algorithmic hyperparameters, including learning rates and exploration rates, as functions of the network width and the scaling parameter, ensuring provably favorable statistical behavior.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 64,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17958",
        "abs_url": "https://arxiv.org/abs/2601.17958",
        "pdf_url": "https://arxiv.org/pdf/2601.17958",
        "title": "TensorLens: End-to-End Transformer Analysis via High-Order Attention Tensors",
        "authors": [
            "Ido Andrew Atad",
            "Itamar Zimerman",
            "Shahar Katz",
            "Lior Wolf"
        ],
        "comments": "17 pages, 7 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Attention matrices are fundamental to transformer research, supporting a broad range of applications including interpretability, visualization, manipulation, and distillation. Yet, most existing analyses focus on individual attention heads or layers, failing to account for the model's global behavior. While prior efforts have extended attention formulations across multiple heads via averaging and matrix multiplications or incorporated components such as normalization and FFNs, a unified and complete representation that encapsulates all transformer blocks is still lacking. We address this gap by introducing TensorLens, a novel formulation that captures the entire transformer as a single, input-dependent linear operator expressed through a high-order attention-interaction tensor. This tensor jointly encodes attention, FFNs, activations, normalizations, and residual connections, offering a theoretically coherent and expressive linear representation of the model's computation. TensorLens is theoretically grounded and our empirical validation shows that it yields richer representations than previous attention-aggregation methods. Our experiments demonstrate that the attention tensor can serve as a powerful foundation for developing tools aimed at interpretability and model understanding. Our code is attached as a supplementary.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 65,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17986",
        "abs_url": "https://arxiv.org/abs/2601.17986",
        "pdf_url": "https://arxiv.org/pdf/2601.17986",
        "title": "Federated learning for unpaired multimodal data through a homogeneous transformer model",
        "authors": [
            "Anders Eklund"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Training of multimodal foundation models is currently restricted to centralized data centers containing massive, aligned datasets (e.g., image-text pairs). However, in realistic federated environments, data is often unpaired and fragmented across disjoint nodes; one node may hold sensor data, while another holds textual logs. These datasets are strictly private and share no common samples. Current federated learning (FL) methods fail in this regime, as they assume local clients possess aligned pairs or require sharing raw feature embeddings, which violates data sovereignty. We propose a novel framework to train a global multimodal transformer across decentralized nodes with disjoint modalities. We introduce a small public anchor set to align disjoint private manifolds. Using Gram matrices calculated from these public anchors, we enforce semantic alignment across modalities through centered kernel alignment without ever transmitting private samples, offering a mathematically superior privacy guarantee compared to prototype sharing. Further, we introduce a subspace-stabilized fine-tuning method to handle FL with huge transformer models. We strictly decouple domain-specific magnitude shifts from semantic direction, ensuring that nodes with varying sensor characteristics align geometrically to the global consensus. Lastly, we propose precision weighted averaging, where efficiently obtained uncertainty estimates are used to downweight uncertain nodes. This paper establishes the mathematical backbone for federated unpaired foundation models, enabling a global model to learn a unified representation of the world from fragmented, disjoint, and private data silos without requiring centralized storage or paired samples.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 66,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17995",
        "abs_url": "https://arxiv.org/abs/2601.17995",
        "pdf_url": "https://arxiv.org/pdf/2601.17995",
        "title": "Coding-Enforced Resilient and Secure Aggregation for Hierarchical Federated Learning",
        "authors": [
            "Shudi Weng",
            "Ming Xiao",
            "Mikael Skoglund"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Hierarchical federated learning (HFL) has emerged as an effective paradigm to enhance link quality between clients and the server. However, ensuring model accuracy while preserving privacy under unreliable communication remains a key challenge in HFL, as the coordination among privacy noise can be randomly disrupted. To address this limitation, we propose a robust hierarchical secure aggregation scheme, termed H-SecCoGC, which integrates coding strategies to enforce structured aggregation. The proposed scheme not only ensures accurate global model construction under varying levels of privacy, but also avoids the partial participation issue, thereby significantly improving robustness, privacy preservation, and learning efficiency. Both theoretical analyses and experimental results demonstrate the superiority of our scheme under unreliable communication across arbitrarily strong privacy guarantees",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 67,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18030",
        "abs_url": "https://arxiv.org/abs/2601.18030",
        "pdf_url": "https://arxiv.org/pdf/2601.18030",
        "title": "Spelling Bee Embeddings for Language Modeling",
        "authors": [
            "Markus N. Rabe",
            "Judith Clymo",
            "Zheren Dong"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We introduce a simple modification to the embedding layer. The key change is to infuse token embeddings with information about their spelling. Models trained with these embeddings improve not only on spelling, but also across standard benchmarks. We conduct scaling studies for models with 40M to 800M parameters, which suggest that the improvements are equivalent to needing about 8% less compute and data to achieve the same test loss.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 68,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18032",
        "abs_url": "https://arxiv.org/abs/2601.18032",
        "pdf_url": "https://arxiv.org/pdf/2601.18032",
        "title": "Multimodal Machine Learning for Soft High-k Elastomers under Data Scarcity",
        "authors": [
            "Brijesh FNU",
            "Viet Thanh Duy Nguyen",
            "Ashima Sharma",
            "Md Harun Rashid Molla",
            "Chengyi Xu",
            "Truong-Son Hy"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Materials Science (cond-mat.mtrl-sci)",
        "abstract": "Dielectric materials are critical building blocks for modern electronics such as sensors, actuators, and transistors. With the rapid recent advance in soft and stretchable electronics for emerging human- and robot-interfacing applications, there is a surging need for high-performance dielectric elastomers. However, it remains a grand challenge to develop soft elastomers that simultaneously possess high dielectric constants (k, related to energy storage capacity) and low Young's moduli (E, related to mechanical flexibility). While some new elastomer designs have been reported in individual (mostly one-off) studies, almost no structured dataset is currently available for dielectric elastomers that systematically encompasses their molecular sequence, dielectric, and mechanical properties. Within this context, we curate a compact, high-quality dataset of acrylate-based dielectric elastomers, one of the most widely explored elastomer backbones due to its versatile chemistry and molecular design flexibility, by screening and aggregating experimental results from the literature over the past 10 years. Building on this dataset, we propose a multimodal learning framework that leverages large-scale pretrained polymer representations from graph- and sequence-based encoders. These pretrained embeddings transfer rich chemical and structural knowledge from vast polymer corpora, enabling accurate few-shot prediction of both dielectric and mechanical properties from molecular sequences. Our results represent a new paradigm for transferring knowledge from pretrained multimodal models to overcome severe data scarcity, which can be readily translated to other polymer backbones (e.g., silicones, urethanes) and thus accelerate data-efficient discovery of soft high-k dielectric elastomers. Our source code and dataset are publicly available at this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 69,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18076",
        "abs_url": "https://arxiv.org/abs/2601.18076",
        "pdf_url": "https://arxiv.org/pdf/2601.18076",
        "title": "Comparison requires valid measurement: Rethinking attack success rate comparisons in AI red teaming",
        "authors": [
            "Alexandra Chouldechova",
            "A. Feder Cooper",
            "Solon Barocas",
            "Abhinav Palia",
            "Dan Vann",
            "Hanna Wallach"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We argue that conclusions drawn about relative system safety or attack method efficacy via AI red teaming are often not supported by evidence provided by attack success rate (ASR) comparisons. We show, through conceptual, theoretical, and empirical contributions, that many conclusions are founded on apples-to-oranges comparisons or low-validity measurements. Our arguments are grounded in asking a simple question: When can attack success rates be meaningfully compared? To answer this question, we draw on ideas from social science measurement theory and inferential statistics, which, taken together, provide a conceptual grounding for understanding when numerical values obtained through the quantification of system attributes can be meaningfully compared. Through this lens, we articulate conditions under which ASRs can and cannot be meaningfully compared. Using jailbreaking as a running example, we provide examples and extensive discussion of apples-to-oranges ASR comparisons and measurement validity challenges.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 70,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18081",
        "abs_url": "https://arxiv.org/abs/2601.18081",
        "pdf_url": "https://arxiv.org/pdf/2601.18081",
        "title": "DRPG (Decompose, Retrieve, Plan, Generate): An Agentic Framework for Academic Rebuttal",
        "authors": [
            "Peixuan Han",
            "Yingjie Yu",
            "Jingjun Xu",
            "Jiaxuan You"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Despite the growing adoption of large language models (LLMs) in scientific research workflows, automated support for academic rebuttal, a crucial step in academic communication and peer review, remains largely underexplored. Existing approaches typically rely on off-the-shelf LLMs or simple pipelines, which struggle with long-context understanding and often fail to produce targeted and persuasive responses. In this paper, we propose DRPG, an agentic framework for automatic academic rebuttal generation that operates through four steps: Decompose reviews into atomic concerns, Retrieve relevant evidence from the paper, Plan rebuttal strategies, and Generate responses accordingly. Notably, the Planner in DRPG reaches over 98% accuracy in identifying the most feasible rebuttal direction. Experiments on data from top-tier conferences demonstrate that DRPG significantly outperforms existing rebuttal pipelines and achieves performance beyond the average human level using only an 8B model. Our analysis further demonstrates the effectiveness of the planner design and its value in providing multi-perspective and explainable suggestions. We also showed that DRPG works well in a more complex multi-round setting. These results highlight the effectiveness of DRPG and its potential to provide high-quality rebuttal content and support the scaling of academic discussions. Codes for this work are available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 71,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18091",
        "abs_url": "https://arxiv.org/abs/2601.18091",
        "pdf_url": "https://arxiv.org/pdf/2601.18091",
        "title": "From LLMs to LRMs: Rethinking Pruning for Reasoning-Centric Models",
        "authors": [
            "Longwei Ding",
            "Anhao Zhao",
            "Fanghua Ye",
            "Ziyang Chen",
            "Xiaoyu Shen"
        ],
        "comments": "18 pages, 7 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) are increasingly costly to deploy, motivating extensive research on model pruning. However, most existing studies focus on instruction-following LLMs, leaving it unclear whether established pruning strategies transfer to reasoning-augmented models that explicitly generate long intermediate reasoning traces. In this work, we conduct a controlled study of pruning for both instruction-following ($\\textbf{LLM-instruct}$) and reasoning-augmented ($\\textbf{LLM-think}$) models. To isolate the effects of pruning, we align pruning calibration and post-pruning recovery data with each model's original training distribution, which we show yields more stable and reliable pruning behavior. We evaluate static depth pruning, static width pruning, and dynamic pruning across 17 tasks spanning classification, generation, and reasoning. Our results reveal clear paradigm-dependent differences: depth pruning outperforms width pruning on classification tasks, while width pruning is more robust for generation and reasoning. Moreover, static pruning better preserves reasoning performance, whereas dynamic pruning excels on classification and generation but remains challenging for long-chain reasoning. These findings underscore the need for pruning strategies that explicitly account for the distinct characteristics of reasoning-augmented LLMs. Our code is publicly available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 72,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18107",
        "abs_url": "https://arxiv.org/abs/2601.18107",
        "pdf_url": "https://arxiv.org/pdf/2601.18107",
        "title": "Beyond Static Datasets: Robust Offline Policy Optimization via Vetted Synthetic Transitions",
        "authors": [
            "Pedram Agand",
            "Mo Chen"
        ],
        "comments": "11 pages, 2 figures, 2 tables",
        "subjects": "Machine Learning (cs.LG); Human-Computer Interaction (cs.HC); Robotics (cs.RO)",
        "abstract": "Offline Reinforcement Learning (ORL) holds immense promise for safety-critical domains like industrial robotics, where real-time environmental interaction is often prohibitive. A primary obstacle in ORL remains the distributional shift between the static dataset and the learned policy, which typically mandates high degrees of conservatism that can restrain potential policy improvements. We present MoReBRAC, a model-based framework that addresses this limitation through Uncertainty-Aware latent synthesis. Instead of relying solely on the fixed data, MoReBRAC utilizes a dual-recurrent world model to synthesize high-fidelity transitions that augment the training manifold. To ensure the reliability of this synthetic data, we implement a hierarchical uncertainty pipeline integrating Variational Autoencoder (VAE) manifold detection, model sensitivity analysis, and Monte Carlo (MC) dropout. This multi-layered filtering process guarantees that only transitions residing within high-confidence regions of the learned dynamics are utilized. Our results on D4RL Gym-MuJoCo benchmarks reveal significant performance gains, particularly in ``random'' and ``suboptimal'' data regimes. We further provide insights into the role of the VAE as a geometric anchor and discuss the distributional trade-offs encountered when learning from near-optimal datasets.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 73,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18110",
        "abs_url": "https://arxiv.org/abs/2601.18110",
        "pdf_url": "https://arxiv.org/pdf/2601.18110",
        "title": "AttenMIA: LLM Membership Inference Attack through Attention Signals",
        "authors": [
            "Pedram Zaree",
            "Md Abdullah Al Mamun",
            "Yue Dong",
            "Ihsen Alouani",
            "Nael Abu-Ghazaleh"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large Language Models (LLMs) are increasingly deployed to enable or improve a multitude of real-world applications. Given the large size of their training data sets, their tendency to memorize training data raises serious privacy and intellectual property concerns. A key threat is the membership inference attack (MIA), which aims to determine whether a given sample was included in the model's training set. Existing MIAs for LLMs rely primarily on output confidence scores or embedding-based features, but these signals are often brittle, leading to limited attack success. We introduce AttenMIA, a new MIA framework that exploits self-attention patterns inside the transformer model to infer membership. Attention controls the information flow within the transformer, exposing different patterns for memorization that can be used to identify members of the dataset. Our method uses information from attention heads across layers and combines them with perturbation-based divergence metrics to train an effective MIA classifier. Using extensive experiments on open-source models including LLaMA-2, Pythia, and Opt models, we show that attention-based features consistently outperform baselines, particularly under the important low-false-positive metric (e.g., achieving up to 0.996 ROC AUC & 87.9% TPR@1%FPR on the WikiMIA-32 benchmark with Llama2-13b). We show that attention signals generalize across datasets and architectures, and provide a layer- and head-level analysis of where membership leakage is most pronounced. We also show that using AttenMIA to replace other membership inference attacks in a data extraction framework results in training data extraction attacks that outperform the state of the art. Our findings reveal that attention mechanisms, originally introduced to enhance interpretability, can inadvertently amplify privacy risks in LLMs, underscoring the need for new defenses.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 74,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18115",
        "abs_url": "https://arxiv.org/abs/2601.18115",
        "pdf_url": "https://arxiv.org/pdf/2601.18115",
        "title": "Robust Learning of a Group DRO Neuron",
        "authors": [
            "Guyang Cao",
            "Shuyao Li",
            "Sushrut Karmalkar",
            "Jelena Diakonikolas"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)",
        "abstract": "We study the problem of learning a single neuron under standard squared loss in the presence of arbitrary label noise and group-level distributional shifts, for a broad family of covariate distributions. Our goal is to identify a ''best-fit'' neuron parameterized by $\\mathbf{w}_*$ that performs well under the most challenging reweighting of the groups. Specifically, we address a Group Distributionally Robust Optimization problem: given sample access to $K$ distinct distributions $\\mathcal p_{[1]},\\dots,\\mathcal p_{[K]}$, we seek to approximate $\\mathbf{w}_*$ that minimizes the worst-case objective over convex combinations of group distributions $\\boldsymbol{\\lambda} \\in \\Delta_K$, where the objective is $\\sum_{i \\in [K]}\\lambda_{[i]}\\,\\mathbb E_{(\\mathbf x,y)\\sim\\mathcal p_{[i]}}(\\sigma(\\mathbf w\\cdot\\mathbf x)-y)^2 - \\nu d_f(\\boldsymbol\\lambda,\\frac{1}{K}\\mathbf1)$ and $d_f$ is an $f$-divergence that imposes (optional) penalty on deviations from uniform group weights, scaled by a parameter $\\nu \\geq 0$. We develop a computationally efficient primal-dual algorithm that outputs a vector $\\widehat{\\mathbf w}$ that is constant-factor competitive with $\\mathbf{w}_*$ under the worst-case group weighting. Our analytical framework directly confronts the inherent nonconvexity of the loss function, providing robust learning guarantees in the face of arbitrary label corruptions and group-specific distributional shifts. The implementation of the dual extrapolation update motivated by our algorithmic framework shows promise on LLM pre-training benchmarks.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 75,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18142",
        "abs_url": "https://arxiv.org/abs/2601.18142",
        "pdf_url": "https://arxiv.org/pdf/2601.18142",
        "title": "Enhance the Safety in Reinforcement Learning by ADRC Lagrangian Methods",
        "authors": [
            "Mingxu Zhang",
            "Huicheng Zhang",
            "Jiaming Ji",
            "Yaodong Yang",
            "Ying Sun"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Safe reinforcement learning (Safe RL) seeks to maximize rewards while satisfying safety constraints, typically addressed through Lagrangian-based methods. However, existing approaches, including PID and classical Lagrangian methods, suffer from oscillations and frequent safety violations due to parameter sensitivity and inherent phase lag. To address these limitations, we propose ADRC-Lagrangian methods that leverage Active Disturbance Rejection Control (ADRC) for enhanced robustness and reduced oscillations. Our unified framework encompasses classical and PID Lagrangian methods as special cases while significantly improving safety performance. Extensive experiments demonstrate that our approach reduces safety violations by up to 74%, constraint violation magnitudes by 89%, and average costs by 67\\%, establishing superior effectiveness for Safe RL in complex environments.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 76,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18150",
        "abs_url": "https://arxiv.org/abs/2601.18150",
        "pdf_url": "https://arxiv.org/pdf/2601.18150",
        "title": "FP8-RL: A Practical and Stable Low-Precision Stack for LLM Reinforcement Learning",
        "authors": [
            "Zhaopeng Qiu",
            "Shuang Yu",
            "Jingqi Zhang",
            "Shuai Zhang",
            "Xue Huang",
            "Jingyi Yang",
            "Junjie Lai"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "Reinforcement learning (RL) for large language models (LLMs) is increasingly bottlenecked by rollout (generation), where long output sequence lengths make attention and KV-cache memory dominate end-to-end step time. FP8 offers an attractive lever for accelerating RL by reducing compute cost and memory traffic during rollout, but applying FP8 in RL introduces unique engineering and algorithmic challenges: policy weights change every step (requiring repeated quantization and weight synchronization into the inference engine) and low-precision rollouts can deviate from the higher-precision policy assumed by the trainer, causing train-inference mismatch and potential instability. This report presents a practical FP8 rollout stack for LLM RL, implemented in the veRL ecosystem with support for common training backends (e.g., FSDP/Megatron-LM) and inference engines (e.g., vLLM/SGLang). We (i) enable FP8 W8A8 linear-layer rollout using blockwise FP8 quantization, (ii) extend FP8 to KV-cache to remove long-context memory bottlenecks via per-step QKV scale recalibration, and (iii) mitigate mismatch using importance-sampling-based rollout correction (token-level TIS/MIS variants). Across dense and MoE models, these techniques deliver up to 44% rollout throughput gains while preserving learning behavior comparable to BF16 baselines.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 77,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18171",
        "abs_url": "https://arxiv.org/abs/2601.18171",
        "pdf_url": "https://arxiv.org/pdf/2601.18171",
        "title": "Learning Fair Domain Adaptation with Virtual Label Distribution",
        "authors": [
            "Yuguang Zhang",
            "Lijun Sheng",
            "Jian Liang",
            "Ran He"
        ],
        "comments": "ICASSP 2026",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Unsupervised Domain Adaptation (UDA) aims to mitigate performance degradation when training and testing data are sampled from different distributions. While significant progress has been made in enhancing overall accuracy, most existing methods overlook performance disparities across categories-an issue we refer to as category fairness. Our empirical analysis reveals that UDA classifiers tend to favor certain easy categories while neglecting difficult ones. To address this, we propose Virtual Label-distribution-aware Learning (VILL), a simple yet effective framework designed to improve worst-case performance while preserving high overall accuracy. The core of VILL is an adaptive re-weighting strategy that amplifies the influence of hard-to-classify categories. Furthermore, we introduce a KL-divergence-based re-balancing strategy, which explicitly adjusts decision boundaries to enhance category fairness. Experiments on commonly used datasets demonstrate that VILL can be seamlessly integrated as a plug-and-play module into existing UDA methods, significantly improving category fairness.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 78,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18189",
        "abs_url": "https://arxiv.org/abs/2601.18189",
        "pdf_url": "https://arxiv.org/pdf/2601.18189",
        "title": "Smooth, Sparse, and Stable: Finite-Time Exact Skeleton Recovery via Smoothed Proximal Gradients",
        "authors": [
            "Rui Wu",
            "Yongjun Li"
        ],
        "comments": "20 pages, 8 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Continuous optimization has significantly advanced causal discovery, yet existing methods (e.g., NOTEARS) generally guarantee only asymptotic convergence to a stationary point. This often yields dense weighted matrices that require arbitrary post-hoc thresholding to recover a DAG. This gap between continuous optimization and discrete graph structures remains a fundamental challenge. In this paper, we bridge this gap by proposing the Hybrid-Order Acyclicity Constraint (AHOC) and optimizing it via the Smoothed Proximal Gradient (SPG-AHOC). Leveraging the Manifold Identification Property of proximal algorithms, we provide a rigorous theoretical guarantee: the Finite-Time Oracle Property. We prove that under standard identifiability assumptions, SPG-AHOC recovers the exact DAG support (structure) in finite iterations, even when optimizing a smoothed approximation. This result eliminates structural ambiguity, as our algorithm returns graphs with exact zero entries without heuristic truncation. Empirically, SPG-AHOC achieves state-of-the-art accuracy and strongly corroborates the finite-time identification theory.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 79,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18200",
        "abs_url": "https://arxiv.org/abs/2601.18200",
        "pdf_url": "https://arxiv.org/pdf/2601.18200",
        "title": "HeterCSI: Channel-Adaptive Heterogeneous CSI Pretraining Framework for Generalized Wireless Foundation Models",
        "authors": [
            "Chenyu Zhang",
            "Xinchen Lyu",
            "Chenshan Ren",
            "Shuhan Liu",
            "Qimei Cui",
            "Xiaofeng Tao"
        ],
        "comments": "13 pages, 8 figures",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Wireless foundation models promise transformative capabilities for channel state information (CSI) processing across diverse 6G network applications, yet face fundamental challenges due to the inherent dual heterogeneity of CSI across both scale and scenario dimensions. However, current pretraining approaches either constrain inputs to fixed dimensions or isolate training by scale, limiting the generalization and scalability of wireless foundation models. In this paper, we propose HeterCSI, a channel-adaptive pretraining framework that reconciles training efficiency with robust cross-scenario generalization via a new understanding of gradient dynamics in heterogeneous CSI pretraining. Our key insight reveals that CSI scale heterogeneity primarily causes destructive gradient interference, while scenario diversity actually promotes constructive gradient alignment when properly managed. Specifically, we formulate heterogeneous CSI batch construction as a partitioning optimization problem that minimizes zero-padding overhead while preserving scenario diversity. To solve this, we develop a scale-aware adaptive batching strategy that aligns CSI samples of similar scales, and design a double-masking mechanism to isolate valid signals from padding artifacts. Extensive experiments on 12 datasets demonstrate that HeterCSI establishes a generalized foundation model without scenario-specific finetuning, achieving superior average performance over full-shot baselines. Compared to the state-of-the-art zero-shot benchmark WiFo, it reduces NMSE by 7.19 dB, 4.08 dB, and 5.27 dB for CSI reconstruction, time-domain, and frequency-domain prediction, respectively. The proposed HeterCSI framework also reduces training latency by 53% compared to existing approaches while improving generalization performance by 1.53 dB on average.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 80,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18231",
        "abs_url": "https://arxiv.org/abs/2601.18231",
        "pdf_url": "https://arxiv.org/pdf/2601.18231",
        "title": "Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting",
        "authors": [
            "Trong Khiem Tran",
            "Manh Cuong Dao",
            "Phi Le Nguyen",
            "Thao Nguyen Truong",
            "Trong Nghia Hoang"
        ],
        "comments": "Accepted AISTATS 20226. Preprint version",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration.~A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer.~This requires combining feature alignment with target fine-tuning, but uncalibrated combinations can exacerbate misalignment between the source and target feature-label structures and reduce target generalization.~Existing work however lacks a theoretical understanding of this critical interaction between feature alignment and target fitting.~To bridge this gap, we develop a principled framework that establishes a provable generalization bound on the target error, which explains the interaction between feature alignment and target fitting through a novel concept of feature-label distortion.~This bound offers actionable insights into how this interaction should be optimized for practical algorithm design. The resulting approach achieves significantly improved performance over state-of-the-art methods across a wide range of benchmark datasets.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 81,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18245",
        "abs_url": "https://arxiv.org/abs/2601.18245",
        "pdf_url": "https://arxiv.org/pdf/2601.18245",
        "title": "Tractable Gaussian Phase Retrieval with Heavy Tails and Adversarial Corruption with Near-Linear Sample Complexity",
        "authors": [
            "Santanu Das",
            "Jatin Batra"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Phase retrieval is the classical problem of recovering a signal $x^* \\in \\mathbb{R}^n$ from its noisy phaseless measurements $y_i = \\langle a_i, x^* \\rangle^2 + \\zeta_i$ (where $\\zeta_i$ denotes noise, and $a_i$ is the sensing vector) for $i \\in [m]$. The problem of phase retrieval has a rich history, with a variety of applications such as optics, crystallography, heteroscedastic regression, astrophysics, etc. A major consideration in algorithms for phase retrieval is robustness against measurement errors. In recent breakthroughs in algorithmic robust statistics, efficient algorithms have been developed for several parameter estimation tasks such as mean estimation, covariance estimation, robust principal component analysis (PCA), etc. in the presence of heavy-tailed noise and adversarial corruptions. In this paper, we study efficient algorithms for robust phase retrieval with heavy-tailed noise when a constant fraction of both the measurements $y_i$ and the sensing vectors $a_i$ may be arbitrarily adversarially corrupted. For this problem, Buna and Rebeschini (AISTATS 2025) very recently gave an exponential time algorithm with sample complexity $O(n \\log n)$. Their algorithm needs a robust spectral initialization, specifically, a robust estimate of the top eigenvector of a covariance matrix, which they deemed to be beyond known efficient algorithmic techniques (similar spectral initializations are a key ingredient of a large family of phase retrieval algorithms). In this work, we make a connection between robust spectral initialization and recent algorithmic advances in robust PCA, yielding the first polynomial-time algorithms for robust phase retrieval with both heavy-tailed noise and adversarial corruptions, in fact with near-linear (in $n$) sample complexity.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 82,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18261",
        "abs_url": "https://arxiv.org/abs/2601.18261",
        "pdf_url": "https://arxiv.org/pdf/2601.18261",
        "title": "FGGM: Fisher-Guided Gradient Masking for Continual Learning",
        "authors": [
            "Chao-Hong Tan",
            "Qian Chen",
            "Wen Wang",
            "Yukun Ma",
            "Chong Zhang",
            "Chong Deng",
            "Qinglin Zhang",
            "Xiangang Li",
            "Jieping Ye"
        ],
        "comments": "Accepted by ICASSP 2026",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "Catastrophic forgetting impairs the continuous learning of large language models. We propose Fisher-Guided Gradient Masking (FGGM), a framework that mitigates this by strategically selecting parameters for updates using diagonal Fisher Information. FGGM dynamically generates binary masks with adaptive thresholds, preserving critical parameters to balance stability and plasticity without requiring historical data. Unlike magnitude-based methods such as MIGU, our approach offers a mathematically principled parameter importance estimation. On the TRACE benchmark, FGGM shows a 9.6% relative improvement in retaining general capabilities over supervised fine-tuning (SFT) and a 4.4% improvement over MIGU on TRACE tasks. Additional analysis on code generation tasks confirms FGGM's superior performance and reduced forgetting, establishing it as an effective solution.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 83,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18278",
        "abs_url": "https://arxiv.org/abs/2601.18278",
        "pdf_url": "https://arxiv.org/pdf/2601.18278",
        "title": "What Do Learned Models Measure?",
        "authors": [
            "Indrė Žliobaitė"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "In many scientific and data-driven applications, machine learning models are increasingly used as measurement instruments, rather than merely as predictors of predefined labels. When the measurement function is learned from data, the mapping from observations to quantities is determined implicitly by the training distribution and inductive biases, allowing multiple inequivalent mappings to satisfy standard predictive evaluation criteria. We formalize learned measurement functions as a distinct focus of evaluation and introduce measurement stability, a property capturing invariance of the measured quantity across admissible realizations of the learning process and across contexts. We show that standard evaluation criteria in machine learning, including generalization error, calibration, and robustness, do not guarantee measurement stability. Through a real-world case study, we show that models with comparable predictive performance can implement systematically inequivalent measurement functions, with distribution shift providing a concrete illustration of this failure. Taken together, our results highlight a limitation of existing evaluation frameworks in settings where learned model outputs are identified as measurements, motivating the need for an additional evaluative dimension.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 84,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18314",
        "abs_url": "https://arxiv.org/abs/2601.18314",
        "pdf_url": "https://arxiv.org/pdf/2601.18314",
        "title": "A Master Class on Reproducibility: A Student Hackathon on Advanced MRI Reconstruction Methods",
        "authors": [
            "Lina Felsner",
            "Sevgi G. Kafali",
            "Hannah Eichhorn",
            "Agnes A. J. Leth",
            "Aidas Batvinskas",
            "Andre Datchev",
            "Fabian Klemm",
            "Jan Aulich",
            "Puntika Leepagorn",
            "Ruben Klinger",
            "Daniel Rueckert",
            "Julia A. Schnabel"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We report the design, protocol, and outcomes of a student reproducibility hackathon focused on replicating the results of three influential MRI reconstruction papers: (a) MoDL, an unrolled model-based network with learned denoising; (b) HUMUS-Net, a hybrid unrolled multiscale CNN+Transformer architecture; and (c) an untrained, physics-regularized dynamic MRI method that uses a quantitative MR model for early stopping. We describe the setup of the hackathon and present reproduction outcomes alongside additional experiments, and we detail fundamental practices for building reproducible codebases.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 85,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18326",
        "abs_url": "https://arxiv.org/abs/2601.18326",
        "pdf_url": "https://arxiv.org/pdf/2601.18326",
        "title": "Cognitive Fusion of ZC Sequences and Time-Frequency Images for Out-of-Distribution Detection of Drone Signals",
        "authors": [
            "Jie Li",
            "Jing Li",
            "Lu Lv",
            "Zhanyu Ju",
            "Fengkui Gong"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We propose a drone signal out-of-distribution detection (OODD) algorithm based on the cognitive fusion of Zadoff-Chu (ZC) sequences and time-frequency images (TFI). ZC sequences are identified by analyzing the communication protocols of DJI drones, while TFI capture the time-frequency characteristics of drone signals with unknown or non-standard communication protocols. Both modalities are used jointly to enable OODD in the drone remote identification (RID) task. Specifically, ZC sequence features and TFI features are generated from the received radio frequency signals, which are then processed through dedicated feature extraction module to enhance and align them. The resultant multi-modal features undergo multi-modal feature interaction, single-modal feature fusion, and multi-modal feature fusion to produce features that integrate and complement information across modalities. Discrimination scores are computed from the fused features along both spatial and channel dimensions to capture time-frequency characteristic differences dictated by the communication protocols, and these scores will be transformed into adaptive attention weights. The weighted features are then passed through a Softmax function to produce the signal classification results. Simulation results demonstrate that the proposed algorithm outperforms existing algorithms and achieves 1.7% and 7.5% improvements in RID and OODD metrics, respectively. The proposed algorithm also performs strong robustness under varying flight conditions and across different drone types.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 86,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18329",
        "abs_url": "https://arxiv.org/abs/2601.18329",
        "pdf_url": "https://arxiv.org/pdf/2601.18329",
        "title": "Discriminability-Driven Spatial-Channel Selection with Gradient Norm for Drone Signal OOD Detection",
        "authors": [
            "Chuhan Feng",
            "Jing Li",
            "Jie Li",
            "Lu Lv",
            "Fengkui Gong"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We propose a drone signal out-of-distribution (OOD) detection algorithm based on discriminability-driven spatial-channel selection with a gradient norm. Time-frequency image features are adaptively weighted along both spatial and channel dimensions by quantifying inter-class similarity and variance based on protocol-specific time-frequency characteristics. Subsequently, a gradient-norm metric is introduced to measure perturbation sensitivity for capturing the inherent instability of OOD samples, which is then fused with energy-based scores for joint inference. Simulation results demonstrate that the proposed algorithm provides superior discriminative power and robust performance via SNR and various drone types.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 87,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18342",
        "abs_url": "https://arxiv.org/abs/2601.18342",
        "pdf_url": "https://arxiv.org/pdf/2601.18342",
        "title": "Structural Gender Bias in Credit Scoring: Proxy Leakage",
        "authors": [
            "Navya SD",
            "Sreekanth D",
            "SS Uma Sankari"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "As financial institutions increasingly adopt machine learning for credit risk assessment, the persistence of algorithmic bias remains a critical barrier to equitable financial inclusion. This study provides a comprehensive audit of structural gender bias within the Taiwan Credit Default dataset, specifically challenging the prevailing doctrine of \"fairness through blindness.\" Despite the removal of explicit protected attributes and the application of industry standard fairness interventions, our results demonstrate that gendered predictive signals remain deeply embedded within non-sensitive features. Utilizing SHAP (SHapley Additive exPlanations), we identify that variables such as Marital Status, Age, and Credit Limit function as potent proxies for gender, allowing models to maintain discriminatory pathways while appearing statistically fair. To mathematically quantify this leakage, we employ an adversarial inverse modeling framework. Our findings reveal that the protected gender attribute can be reconstructed from purely non-sensitive financial features with an ROC AUC score of 0.65, demonstrating that traditional fairness audits are insufficient for detecting implicit structural bias. These results advocate for a shift from surface-level statistical parity toward causal-aware modeling and structural accountability in financial AI.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 88,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18356",
        "abs_url": "https://arxiv.org/abs/2601.18356",
        "pdf_url": "https://arxiv.org/pdf/2601.18356",
        "title": "Making medical vision-language models think causally across modalities with retrieval-augmented cross-modal reasoning",
        "authors": [
            "Weiqin Yang",
            "Haowen Xue",
            "Qingyi Peng",
            "Hexuan Hu",
            "Qian Huang",
            "Tingbo Zhang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Medical vision-language models (VLMs) achieve strong performance in diagnostic reporting and image-text alignment, yet their underlying reasoning mechanisms remain fundamentally correlational, exhibiting reliance on superficial statistical associations that fail to capture the causal pathophysiological mechanisms central to clinical decision-making. This limitation makes them fragile, prone to hallucinations, and sensitive to dataset biases. Retrieval-augmented generation (RAG) offers a partial remedy by grounding predictions in external knowledge. However, conventional RAG depends on semantic similarity, introducing new spurious correlations. We propose Multimodal Causal Retrieval-Augmented Generation, a framework that integrates causal inference principles with multimodal retrieval. It retrieves clinically relevant exemplars and causal graphs from external sources, conditioning model reasoning on counterfactual and interventional evidence rather than correlations alone. Applied to radiology report generation, diagnosis prediction, and visual question answering, it improves factual accuracy, robustness to distribution shifts, and interpretability. Our results highlight causal retrieval as a scalable path toward medical VLMs that think beyond pattern matching, enabling trustworthy multimodal reasoning in high-stakes clinical settings.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 89,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18399",
        "abs_url": "https://arxiv.org/abs/2601.18399",
        "pdf_url": "https://arxiv.org/pdf/2601.18399",
        "title": "Estimating Dense-Packed Zone Height in Liquid-Liquid Separation: A Physics-Informed Neural Network Approach",
        "authors": [
            "Mehmet Velioglu",
            "Song Zhai",
            "Alexander Mitsos",
            "Adel Mhamdi",
            "Andreas Jupke",
            "Manuel Dahmen"
        ],
        "comments": "37 pages, 13 figures, 3 tables",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Separating liquid-liquid dispersions in gravity settlers is critical in chemical, pharmaceutical, and recycling processes. The dense-packed zone height is an important performance and safety indicator but it is often expensive and impractical to measure due to optical limitations. We propose to estimate phase heights using only inexpensive volume flow measurements. To this end, a physics-informed neural network (PINN) is first pretrained on synthetic data and physics equations derived from a low-fidelity (approximate) mechanistic model to reduce the need for extensive experimental data. While the mechanistic model is used to generate synthetic training data, only volume balance equations are used in the PINN, since the integration of submodels describing droplet coalescence and sedimentation into the PINN would be computationally prohibitive. The pretrained PINN is then fine-tuned with scarce experimental data to capture the actual dynamics of the separator. We then employ the differentiable PINN as a predictive model in an Extended Kalman Filter inspired state estimation framework, enabling the phase heights to be tracked and updated from flow-rate measurements. We first test the two-stage trained PINN by forward simulation from a known initial state against the mechanistic model and a non-pretrained PINN. We then evaluate phase height estimation performance with the filter, comparing the two-stage trained PINN with a two-stage trained purely data-driven neural network. All model types are trained and evaluated using ensembles to account for model parameter uncertainty. In all evaluations, the two-stage trained PINN yields the most accurate phase-height estimates.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 90,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18401",
        "abs_url": "https://arxiv.org/abs/2601.18401",
        "pdf_url": "https://arxiv.org/pdf/2601.18401",
        "title": "Superlinear Multi-Step Attention",
        "authors": [
            "Yufeng Huang"
        ],
        "comments": "30 pages, 6 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this paper, we propose \\textbf{Superlinear attention}, a fully trainable multi-step attention architecture that achieves subquadratic complexity for long sequences while preserving \\textbf{random context access} (a.k.a.\\ structural non-exclusion): no eligible token position is structurally excluded from being selected for attention. Superlinear attention reformulates standard causal self-attention as a multi-step search problem with $N$ steps, yielding an overall complexity of $O(L^{1+\\frac{1}{N}})$. To illustrate the architecture, we present a baseline $N=2$ implementation, which is algorithmically analogous to standard jump search. In this $O(L^{3/2})$ instantiation, the first step performs $O(L^{3/2})$ span-search to select relevant spans of the sequence, and the second step applies $O(L^{3/2})$ span-attention (standard attention restricted to the selected spans). In an upscaled $O(L^{1.54})$ configuration for robustness, we achieve an average decoding throughput of 114 tokens/sec at 1M context length and 80 tokens/sec at 10M context in our implementation on a modified 30B hybrid MoE model on a single B200 GPU. With limited training, we also obtain strong performance on the NIAH (Needle In A Haystack) task up to 256K context length, demonstrating that the routed span selection is learnable end-to-end. This paper emphasizes architectural formulation, scaling analysis, and systems feasibility, and presents initial validation; comprehensive quality evaluations across diverse long-context tasks are left to future work.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 91,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18409",
        "abs_url": "https://arxiv.org/abs/2601.18409",
        "pdf_url": "https://arxiv.org/pdf/2601.18409",
        "title": "Frequency-Based Hyperparameter Selection in Games",
        "authors": [
            "Aniket Sanyal",
            "Baraah A.M. Sidahmed",
            "Rebekka Burkholz",
            "Tatjana Chavdarova"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Learning in smooth games fundamentally differs from standard minimization due to rotational dynamics, which invalidate classical hyperparameter tuning strategies. Despite their practical importance, effective methods for tuning in games remain underexplored. A notable example is LookAhead (LA), which achieves strong empirical performance but introduces additional parameters that critically influence performance. We propose a principled approach to hyperparameter selection in games by leveraging frequency estimation of oscillatory dynamics. Specifically, we analyze oscillations both in continuous-time trajectories and through the spectrum of the discrete dynamics in the associated frequency-based space. Building on this analysis, we introduce \\emph{Modal LookAhead (MoLA)}, an extension of LA that selects the hyperparameters adaptively to a given problem. We provide convergence guarantees and demonstrate in experiments that MoLA accelerates training in both purely rotational games and mixed regimes, all with minimal computational overhead.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 92,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18447",
        "abs_url": "https://arxiv.org/abs/2601.18447",
        "pdf_url": "https://arxiv.org/pdf/2601.18447",
        "title": "GCFX: Generative Counterfactual Explanations for Deep Graph Models at the Model Level",
        "authors": [
            "Jinlong Hu",
            "Jiacheng Liu"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Deep graph learning models have demonstrated remarkable capabilities in processing graph-structured data and have been widely applied across various fields. However, their complex internal architectures and lack of transparency make it difficult to explain their decisions, resulting in opaque models that users find hard to understand and trust. In this paper, we explore model-level explanation techniques for deep graph learning models, aiming to provide users with a comprehensive understanding of the models' overall decision-making processes and underlying mechanisms. Specifically, we address the problem of counterfactual explanations for deep graph learning models by introducing a generative model-level counterfactual explanation approach called GCFX, which is based on deep graph generation. This approach generates a set of high-quality counterfactual explanations that reflect the model's global predictive behavior by leveraging an enhanced deep graph generation framework and a global summarization algorithm. GCFX features an architecture that combines dual encoders, structure-aware taggers, and Message Passing Neural Network decoders, enabling it to accurately learn the true latent distribution of input data and generate high-quality, closely related counterfactual examples. Subsequently, a global counterfactual summarization algorithm selects the most representative and comprehensive explanations from numerous candidate counterfactuals, providing broad insights into the model's global predictive patterns. Experiments on a synthetic dataset and several real-world datasets demonstrate that GCFX outperforms existing methods in terms of counterfactual validity and coverage while maintaining low explanation costs, thereby offering crucial support for enhancing the practicality and trustworthiness of global counterfactual explanations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 93,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18479",
        "abs_url": "https://arxiv.org/abs/2601.18479",
        "pdf_url": "https://arxiv.org/pdf/2601.18479",
        "title": "Enhancing Control Policy Smoothness by Aligning Actions with Predictions from Preceding States",
        "authors": [
            "Kyoleen Kwak",
            "Hyoseok Hwang"
        ],
        "comments": "Accepted at AAAI-26. 7 pages (excluding references), 3 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep reinforcement learning has proven to be a powerful approach to solving control tasks, but its characteristic high-frequency oscillations make it difficult to apply in real-world environments. While prior methods have addressed action oscillations via architectural or loss-based methods, the latter typically depend on heuristic or synthetic definitions of state similarity to promote action consistency, which often fail to accurately reflect the underlying system dynamics. In this paper, we propose a novel loss-based method by introducing a transition-induced similar state. The transition-induced similar state is defined as the distribution of next states transitioned from the previous state. Since it utilizes only environmental feedback and actually collected data, it better captures system dynamics. Building upon this foundation, we introduce Action Smoothing by Aligning Actions with Predictions from Preceding States (ASAP), an action smoothing method that effectively mitigates action oscillations. ASAP enforces action smoothness by aligning the actions with those taken in transition-induced similar states and by penalizing second-order differences to suppress high-frequency oscillations. Experiments in Gymnasium and Isaac-Lab environments demonstrate that ASAP yields smoother control and improved policy performance over existing methods.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 94,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18500",
        "abs_url": "https://arxiv.org/abs/2601.18500",
        "pdf_url": "https://arxiv.org/pdf/2601.18500",
        "title": "Nearly Optimal Bayesian Inference for Structural Missingness",
        "authors": [
            "Chen Liang",
            "Donghua Yang",
            "Yutong Wang",
            "Tianle Zhang",
            "Shenghe Zhou",
            "Zhiyu Liang",
            "Hengtong Zhang",
            "Hongzhi Wang",
            "Ziqi Li",
            "Xiyang Zhang",
            "Zheng Liang",
            "Yifei Li"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Structural missingness breaks 'just impute and train': values can be undefined by causal or logical constraints, and the mask may depend on observed variables, unobserved variables (MNAR), and other missingness indicators. It simultaneously brings (i) a catch-22 situation with causal loop, prediction needs the missing features, yet inferring them depends on the missingness mechanism, (ii) under MNAR, the unseen are different, the missing part can come from a shifted distribution, and (iii) plug-in imputation, a single fill-in can lock in uncertainty and yield overconfident, biased decisions. In the Bayesian view, prediction via the posterior predictive distribution integrates over the full model posterior uncertainty, rather than relying on a single point estimate. This framework decouples (i) learning an in-model missing-value posterior from (ii) label prediction by optimizing the predictive posterior distribution, enabling posterior integration. This decoupling yields an in-model almost-free-lunch: once the posterior is learned, prediction is plug-and-play while preserving uncertainty propagation. It achieves SOTA on 43 classification and 15 imputation benchmarks, with finite-sample near Bayes-optimality guarantees under our SCM prior.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 95,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18509",
        "abs_url": "https://arxiv.org/abs/2601.18509",
        "pdf_url": "https://arxiv.org/pdf/2601.18509",
        "title": "Conformal Prediction Algorithms for Time Series Forecasting: Methods and Benchmark",
        "authors": [
            "Andro Sabashvili"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Reliable uncertainty quantification is of critical importance in time series forecasting, yet traditional methods often rely on restrictive distributional assumptions. Conformal prediction (CP) has emerged as a promising distribution-free framework for generating prediction intervals with rigorous theoretical guarantees. However, applying CP to sequential data presents a primary challenge: the temporal dependencies inherent in time series fundamentally violate the core assumption of data exchangeability, upon which standard CP guarantees are built. This review critically examines the main categories of algorithmic solutions designed to address this conflict. We survey and benchmark methods that relax the exchangeability assumption, those that redefine the data unit to be a collection of independent time series, approaches that explicitly model the dynamics of the prediction residuals, and online learning algorithms that adapt to distribution shifts to maintain long-run coverage. By synthesizing these approaches, we highlight computational efficiency and practical performance on real-world data.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 96,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18513",
        "abs_url": "https://arxiv.org/abs/2601.18513",
        "pdf_url": "https://arxiv.org/pdf/2601.18513",
        "title": "LipNeXt: Scaling up Lipschitz-based Certified Robustness to Billion-parameter Models",
        "authors": [
            "Kai Hu",
            "Haoqi Hu",
            "Matt Fredrikson"
        ],
        "comments": "ICLR 2026. 17 pages",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Lipschitz-based certification offers efficient, deterministic robustness guarantees but has struggled to scale in model size, training efficiency, and ImageNet performance. We introduce \\emph{LipNeXt}, the first \\emph{constraint-free} and \\emph{convolution-free} 1-Lipschitz architecture for certified robustness. LipNeXt is built using two techniques: (1) a manifold optimization procedure that updates parameters directly on the orthogonal manifold and (2) a \\emph{Spatial Shift Module} to model spatial pattern without convolutions. The full network uses orthogonal projections, spatial shifts, a simple 1-Lipschitz $\\beta$-Abs nonlinearity, and $L_2$ spatial pooling to maintain tight Lipschitz control while enabling expressive feature mixing. Across CIFAR-10/100 and Tiny-ImageNet, LipNeXt achieves state-of-the-art clean and certified robust accuracy (CRA), and on ImageNet it scales to 1-2B large models, improving CRA over prior Lipschitz models (e.g., up to $+8\\%$ at $\\varepsilon{=}1$) while retaining efficient, stable low-precision training. These results demonstrate that Lipschitz-based certification can benefit from modern scaling trends without sacrificing determinism or efficiency.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 97,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18524",
        "abs_url": "https://arxiv.org/abs/2601.18524",
        "pdf_url": "https://arxiv.org/pdf/2601.18524",
        "title": "From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale",
        "authors": [
            "Yongqi Jin",
            "Yecheng Wang",
            "Jun-jie Wang",
            "Rong Zhu",
            "Guolin Ke",
            "Weinan E"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 98,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18546",
        "abs_url": "https://arxiv.org/abs/2601.18546",
        "pdf_url": "https://arxiv.org/pdf/2601.18546",
        "title": "Information Hidden in Gradients of Regression with Target Noise",
        "authors": [
            "Arash Jamshidi",
            "Katsiaryna Haitsiukevich",
            "Kai Puolamäki"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $\\Sigma$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $\\Omega(1)$ factor. The proposed method is practical (a \"set target-noise variance to $n$\" rule) and robust (variance $\\mathcal{O}(n)$ suffices to recover $\\Sigma$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 99,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18580",
        "abs_url": "https://arxiv.org/abs/2601.18580",
        "pdf_url": "https://arxiv.org/pdf/2601.18580",
        "title": "K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents",
        "authors": [
            "Vincenzo De Paola",
            "Mirco Mutti",
            "Riccardo Zamboni",
            "Marcello Restelli"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 100,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18604",
        "abs_url": "https://arxiv.org/abs/2601.18604",
        "pdf_url": "https://arxiv.org/pdf/2601.18604",
        "title": "LaCoGSEA: Unsupervised deep learning for pathway analysis via latent correlation",
        "authors": [
            "Zhiwei Zheng",
            "Kevin Bryson"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Genomics (q-bio.GN)",
        "abstract": "Motivation: Pathway enrichment analysis is widely used to interpret gene expression data. Standard approaches, such as GSEA, rely on predefined phenotypic labels and pairwise comparisons, which limits their applicability in unsupervised settings. Existing unsupervised extensions, including single-sample methods, provide pathway-level summaries but primarily capture linear relationships and do not explicitly model gene-pathway associations. More recently, deep learning models have been explored to capture non-linear transcriptomic structure. However, their interpretation has typically relied on generic explainable AI (XAI) techniques designed for feature-level attribution. As these methods are not designed for pathway-level interpretation in unsupervised transcriptomic analyses, their effectiveness in this setting remains limited. Results: To bridge this gap, we introduce LaCoGSEA (Latent Correlation GSEA), an unsupervised framework that integrates deep representation learning with robust pathway statistics. LaCoGSEA employs an autoencoder to capture non-linear manifolds and proposes a global gene-latent correlation metric as a proxy for differential expression, generating dense gene rankings without prior labels. We demonstrate that LaCoGSEA offers three key advantages: (i) it achieves improved clustering performance in distinguishing cancer subtypes compared to existing unsupervised baselines; (ii) it recovers a broader range of biologically meaningful pathways at higher ranks compared with linear dimensionality reduction and gradient-based XAI methods; and (iii) it maintains high robustness and consistency across varying experimental protocols and dataset sizes. Overall, LaCoGSEA provides state-of-the-art performance in unsupervised pathway enrichment analysis. Availability and implementation: this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 101,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18615",
        "abs_url": "https://arxiv.org/abs/2601.18615",
        "pdf_url": "https://arxiv.org/pdf/2601.18615",
        "title": "Geometry-Free Conditional Diffusion Modeling for Solving the Inverse Electrocardiography Problem",
        "authors": [
            "Ramiro Valdes Jara",
            "Adam Meyers"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper proposes a data-driven model for solving the inverse problem of electrocardiography, the mathematical problem that forms the basis of electrocardiographic imaging (ECGI). We present a conditional diffusion framework that learns a probabilistic mapping from noisy body surface signals to heart surface electric potentials. The proposed approach leverages the generative nature of diffusion models to capture the non-unique and underdetermined nature of the ECGI inverse problem, enabling probabilistic sampling of multiple reconstructions rather than a single deterministic estimate. Unlike traditional methods, the proposed framework is geometry-free and purely data-driven, alleviating the need for patient-specific mesh construction. We evaluate the method on a real ECGI dataset and compare it against strong deterministic baselines, including a convolutional neural network, long short-term memory network, and transformer-based model. The results demonstrate that the proposed diffusion approach achieves improved reconstruction accuracy, highlighting the potential of diffusion models as a robust tool for noninvasive cardiac electrophysiology imaging.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 102,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18620",
        "abs_url": "https://arxiv.org/abs/2601.18620",
        "pdf_url": "https://arxiv.org/pdf/2601.18620",
        "title": "CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling",
        "authors": [
            "Panagiotis Lymperopoulos",
            "Abhiramon Rajasekharan",
            "Ian Berlot-Attwell",
            "Stéphane Aroca-Ouellette",
            "Kaheer Suleman"
        ],
        "comments": "28 pages, 2 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 103,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18638",
        "abs_url": "https://arxiv.org/abs/2601.18638",
        "pdf_url": "https://arxiv.org/pdf/2601.18638",
        "title": "Physics-Informed Uncertainty Enables Reliable AI-driven Design",
        "authors": [
            "Tingkai Xue",
            "Chin Chun Ooi",
            "Yang Jiang",
            "Luu Trung Pham Duong",
            "Pao-Hsiung Chiu",
            "Weijiang Zhao",
            "Nagarajan Raghavan",
            "My Ha Dao"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Computational Physics (physics.comp-ph)",
        "abstract": "Inverse design is a central goal in much of science and engineering, including frequency-selective surfaces (FSS) that are critical to microelectronics for telecommunications and optical metamaterials. Traditional surrogate-assisted optimization methods using deep learning can accelerate the design process but do not usually incorporate uncertainty quantification, leading to poorer optimization performance due to erroneous predictions in data-sparse regions. Here, we introduce and validate a fundamentally different paradigm of Physics-Informed Uncertainty, where the degree to which a model's prediction violates fundamental physical laws serves as a computationally-cheap and effective proxy for predictive uncertainty. By integrating physics-informed uncertainty into a multi-fidelity uncertainty-aware optimization workflow to design complex frequency-selective surfaces within the 20 - 30 GHz range, we increase the success rate of finding performant solutions from less than 10% to over 50%, while simultaneously reducing computational cost by an order of magnitude compared to the sole use of a high-fidelity solver. These results highlight the necessity of incorporating uncertainty quantification in machine-learning-driven inverse design for high-dimensional problems, and establish physics-informed uncertainty as a viable alternative to quantifying uncertainty in surrogate models for physical systems, thereby setting the stage for autonomous scientific discovery systems that can efficiently and robustly explore and evaluate candidate designs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 104,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18640",
        "abs_url": "https://arxiv.org/abs/2601.18640",
        "pdf_url": "https://arxiv.org/pdf/2601.18640",
        "title": "TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning",
        "authors": [
            "Zhiwei Zheng",
            "Kevin Bryson"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Molecular Networks (q-bio.MN)",
        "abstract": "Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation. Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as \"background\" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference. Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 105,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18672",
        "abs_url": "https://arxiv.org/abs/2601.18672",
        "pdf_url": "https://arxiv.org/pdf/2601.18672",
        "title": "A Dynamic Framework for Grid Adaptation in Kolmogorov-Arnold Networks",
        "authors": [
            "Spyros Rigas",
            "Thanasis Papaioannou",
            "Panagiotis Trakadas",
            "Georgios Alexandridis"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Kolmogorov-Arnold Networks (KANs) have recently demonstrated promising potential in scientific machine learning, partly due to their capacity for grid adaptation during training. However, existing adaptation strategies rely solely on input data density, failing to account for the geometric complexity of the target function or metrics calculated during network training. In this work, we propose a generalized framework that treats knot allocation as a density estimation task governed by Importance Density Functions (IDFs), allowing training dynamics to determine grid resolution. We introduce a curvature-based adaptation strategy and evaluate it across synthetic function fitting, regression on a subset of the Feynman dataset and different instances of the Helmholtz PDE, demonstrating that it significantly outperforms the standard input-based baseline. Specifically, our method yields average relative error reductions of 25.3% on synthetic functions, 9.4% on the Feynman dataset, and 23.3% on the PDE benchmark. Statistical significance is confirmed via Wilcoxon signed-rank tests, establishing curvature-based adaptation as a robust and computationally efficient alternative for KAN training.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 106,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18676",
        "abs_url": "https://arxiv.org/abs/2601.18676",
        "pdf_url": "https://arxiv.org/pdf/2601.18676",
        "title": "Quasi Monte Carlo methods enable extremely low-dimensional deep generative models",
        "authors": [
            "Miles Martinez",
            "Alex H. Williams"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 107,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18681",
        "abs_url": "https://arxiv.org/abs/2601.18681",
        "pdf_url": "https://arxiv.org/pdf/2601.18681",
        "title": "ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule",
        "authors": [
            "Yilie Huang",
            "Wenpin Tang",
            "Xunyu Zhou"
        ],
        "comments": "17 pages, 7 figures",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Systems and Control (eess.SY); Optimization and Control (math.OC)",
        "abstract": "We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fréchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 108,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18696",
        "abs_url": "https://arxiv.org/abs/2601.18696",
        "pdf_url": "https://arxiv.org/pdf/2601.18696",
        "title": "Explainability Methods for Hardware Trojan Detection: A Systematic Comparison",
        "authors": [
            "Paul Whitten",
            "Francis Wolff",
            "Chris Papachristou"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient). Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like \"high fanin complexity near outputs indicates potential triggers.\" Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation. XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights. This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 109,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18699",
        "abs_url": "https://arxiv.org/abs/2601.18699",
        "pdf_url": "https://arxiv.org/pdf/2601.18699",
        "title": "Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning",
        "authors": [
            "Olaf Yunus Laitinen Imanov"
        ],
        "comments": "16 pages, 16 figures (6 main + 10 supplementary)",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 110,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18707",
        "abs_url": "https://arxiv.org/abs/2601.18707",
        "pdf_url": "https://arxiv.org/pdf/2601.18707",
        "title": "SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model",
        "authors": [
            "Jan Hagnberger",
            "Mathias Niepert"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 111,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18728",
        "abs_url": "https://arxiv.org/abs/2601.18728",
        "pdf_url": "https://arxiv.org/pdf/2601.18728",
        "title": "Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data",
        "authors": [
            "Willem Diepeveen",
            "Oscar Leong"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Differential Geometry (math.DG); Optimization and Control (math.OC); Statistics Theory (math.ST)",
        "abstract": "Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 112,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18734",
        "abs_url": "https://arxiv.org/abs/2601.18734",
        "pdf_url": "https://arxiv.org/pdf/2601.18734",
        "title": "Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models",
        "authors": [
            "Siyan Zhao",
            "Zhihui Xie",
            "Mengchen Liu",
            "Jing Huang",
            "Guan Pang",
            "Feiyu Chen",
            "Aditya Grover"
        ],
        "comments": "13 pages",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 113,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18736",
        "abs_url": "https://arxiv.org/abs/2601.18736",
        "pdf_url": "https://arxiv.org/pdf/2601.18736",
        "title": "Benchmarking Machine Learning Models for IoT Malware Detection under Data Scarcity and Drift",
        "authors": [
            "Jake Lyon",
            "Ehsan Saeedizade",
            "Shamik Sengupta"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)",
        "abstract": "The rapid expansion of the Internet of Things (IoT) in domains such as smart cities, transportation, and industrial systems has heightened the urgency of addressing their security vulnerabilities. IoT devices often operate under limited computational resources, lack robust physical safeguards, and are deployed in heterogeneous and dynamic networks, making them prime targets for cyberattacks and malware applications. Machine learning (ML) offers a promising approach to automated malware detection and classification, but practical deployment requires models that are both effective and lightweight. The goal of this study is to investigate the effectiveness of four supervised learning models (Random Forest, LightGBM, Logistic Regression, and a Multi-Layer Perceptron) for malware detection and classification using the IoT-23 dataset. We evaluate model performance in both binary and multiclass classification tasks, assess sensitivity to training data volume, and analyze temporal robustness to simulate deployment in evolving threat landscapes. Our results show that tree-based models achieve high accuracy and generalization, even with limited training data, while performance deteriorates over time as malware diversity increases. These findings underscore the importance of adaptive, resource-efficient ML models for securing IoT systems in real-world environments.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 114,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18753",
        "abs_url": "https://arxiv.org/abs/2601.18753",
        "pdf_url": "https://arxiv.org/pdf/2601.18753",
        "title": "HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs",
        "authors": [
            "Xinyue Zeng",
            "Junhong Lin",
            "Yujun Yan",
            "Feng Guo",
            "Liang Shi",
            "Jun Wu",
            "Dawei Zhou"
        ],
        "comments": "Have been accepted by ICLR'26",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 115,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18760",
        "abs_url": "https://arxiv.org/abs/2601.18760",
        "pdf_url": "https://arxiv.org/pdf/2601.18760",
        "title": "Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values",
        "authors": [
            "Henry Bell",
            "Lara Neubauer da Costa Schertel",
            "Bochu Ding",
            "Brandon Fain"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \\textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \\textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 116,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18778",
        "abs_url": "https://arxiv.org/abs/2601.18778",
        "pdf_url": "https://arxiv.org/pdf/2601.18778",
        "title": "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability",
        "authors": [
            "Shobhita Sundaram",
            "John Quan",
            "Ariel Kwiatkowski",
            "Kartik Ahuja",
            "Yann Ollivier",
            "Julia Kempe"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 117,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18783",
        "abs_url": "https://arxiv.org/abs/2601.18783",
        "pdf_url": "https://arxiv.org/pdf/2601.18783",
        "title": "Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic",
        "authors": [
            "Deepthi Pathare",
            "Leo Laine",
            "Morteza Haghir Chehreghani"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)",
        "abstract": "Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 118,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.16986",
        "abs_url": "https://arxiv.org/abs/2601.16986",
        "pdf_url": "https://arxiv.org/pdf/2601.16986",
        "title": "Crystal-KV: Efficient KV Cache Management for Chain-of-Thought LLMs via Answer-First Principle",
        "authors": [
            "Zihan Wang",
            "Cheng Tang",
            "Lei Gong",
            "Cheng Li",
            "Chao Wang",
            "teng wang",
            "Wenqi Lou",
            "Xuehai Zhou"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Chain-of-Thought (CoT) reasoning in large language models (LLMs) significantly improves accuracy on complex tasks, yet incurs excessive memory overhead due to the long think-stage sequences stored in the Key-Value (KV) cache. Unlike traditional generation tasks where all tokens are uniformly important, CoT emphasizes the final answer, rendering conventional KV compression strategies ineffective. In this paper, we present Crystal-KV, an efficient KV cache management framework tailored for CoT reasoning. Our key insight is the answer-first principle. By mapping answer preferences into think-stage attention map, we distinguish between SlipKV, which mainly maintains the reasoning flow but may occasionally introduce misleading context, and CrystalKV, which truly contributes to the correctness of the final answer. Next, we propose an attention-based Least Recently Frequently Used algorithm. It precisely identifies when a SlipKV entry's utility expires and evicts it, retaining CrystalKV without disrupting reasoning flow. Finally, we introduce an adaptive cache budget allocation algorithm. Based on the dynamic proportion of CrystalKV, it estimates the importance of each layer/head and adjusts the KV cache budget during inference, amplifying critical components to improve budget utilization. Results show that Crystal-KV achieves state-of-the-art KV cache compression, significantly improves throughput, and enables faster response time, while maintaining, or even improving, answer accuracy for CoT reasoning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 119,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.16999",
        "abs_url": "https://arxiv.org/abs/2601.16999",
        "pdf_url": "https://arxiv.org/pdf/2601.16999",
        "title": "Uncertainty Quantification for Named Entity Recognition via Full-Sequence and Subsequence Conformal Prediction",
        "authors": [
            "Matthew Singer",
            "Srijan Sengupta",
            "Karl Pazdernik"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)",
        "abstract": "Named Entity Recognition (NER) serves as a foundational component in many natural language processing (NLP) pipelines. However, current NER models typically output a single predicted label sequence without any accompanying measure of uncertainty, leaving downstream applications vulnerable to cascading errors. In this paper, we introduce a general framework for adapting sequence-labeling-based NER models to produce uncertainty-aware prediction sets. These prediction sets are collections of full-sentence labelings that are guaranteed to contain the correct labeling with a user-specified confidence level. This approach serves a role analogous to confidence intervals in classical statistics by providing formal guarantees about the reliability of model predictions. Our method builds on conformal prediction, which offers finite-sample coverage guarantees under minimal assumptions. We design efficient nonconformity scoring functions to construct efficient, well-calibrated prediction sets that support both unconditional and class-conditional coverage. This framework accounts for heterogeneity across sentence length, language, entity type, and number of entities within a sentence. Empirical experiments on four NER models across three benchmark datasets demonstrate the broad applicability, validity, and efficiency of the proposed methods.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 120,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17021",
        "abs_url": "https://arxiv.org/abs/2601.17021",
        "pdf_url": "https://arxiv.org/pdf/2601.17021",
        "title": "Regret-Driven Portfolios: LLM-Guided Smart Clustering for Optimal Allocation",
        "authors": [
            "Muhammad Abro",
            "Hassan Jaleel"
        ],
        "comments": "",
        "subjects": "Portfolio Management (q-fin.PM); Machine Learning (cs.LG); Multiagent Systems (cs.MA)",
        "abstract": "We attempt to mitigate the persistent tradeoff between risk and return in medium- to long-term portfolio management. This paper proposes a novel LLM-guided no-regret portfolio allocation framework that integrates online learning dynamics, market sentiment indicators, and large language model (LLM)-based hedging to construct high-Sharpe ratio portfolios tailored for risk-averse investors and institutional fund managers. Our approach builds on a follow-the-leader approach, enriched with sentiment-based trade filtering and LLM-driven downside protection. Empirical results demonstrate that our method outperforms a SPY buy-and-hold baseline by 69% in annualized returns and 119% in Sharpe ratio.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 121,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17038",
        "abs_url": "https://arxiv.org/abs/2601.17038",
        "pdf_url": "https://arxiv.org/pdf/2601.17038",
        "title": "Hybrid Deep Feature Extraction and ML for Construction and Demolition Debris Classification",
        "authors": [
            "Obai Alashram",
            "Nejad Alagha",
            "Mahmoud AlKakuri",
            "Zeeshan Swaveel",
            "Abigail Copiaco"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
        "abstract": "The construction industry produces significant volumes of debris, making effective sorting and classification critical for sustainable waste management and resource recovery. This study presents a hybrid vision-based pipeline that integrates deep feature extraction with classical machine learning (ML) classifiers for automated construction and demolition (C\\&D) debris classification. A novel dataset comprising 1,800 balanced, high-quality images representing four material categories, Ceramic/Tile, Concrete, Trash/Waste, and Wood was collected from real construction sites in the UAE, capturing diverse real-world conditions. Deep features were extracted using a pre-trained Xception network, and multiple ML classifiers, including SVM, kNN, Bagged Trees, LDA, and Logistic Regression, were systematically evaluated. The results demonstrate that hybrid pipelines using Xception features with simple classifiers such as Linear SVM, kNN, and Bagged Trees achieve state-of-the-art performance, with up to 99.5\\% accuracy and macro-F1 scores, surpassing more complex or end-to-end deep learning approaches. The analysis highlights the operational benefits of this approach for robust, field-deployable debris identification and provides pathways for future integration with robotics and onsite automation systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 122,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17047",
        "abs_url": "https://arxiv.org/abs/2601.17047",
        "pdf_url": "https://arxiv.org/pdf/2601.17047",
        "title": "A Contrastive Pre-trained Foundation Model for Deciphering Imaging Noisomics across Modalities",
        "authors": [
            "Yuanjie Gu",
            "Yiqun Wang",
            "Chaohui Yu",
            "Ang Xuan",
            "Fan Wang",
            "Zhi Lu",
            "Biqin Dong"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
        "abstract": "Characterizing imaging noise is notoriously data-intensive and device-dependent, as modern sensors entangle physical signals with complex algorithmic artifacts. Current paradigms struggle to disentangle these factors without massive supervised datasets, often reducing noise to mere interference rather than an information resource. Here, we introduce \"Noisomics\", a framework shifting the focus from suppression to systematic noise decoding via the Contrastive Pre-trained (CoP) Foundation Model. By leveraging the manifold hypothesis and synthetic noise genome, CoP employs contrastive learning to disentangle semantic signals from stochastic perturbations. Crucially, CoP breaks traditional deep learning scaling laws, achieving superior performance with only 100 training samples, outperforming supervised baselines trained on 100,000 samples, thereby reducing data and computational dependency by three orders of magnitude. Extensive benchmarking across 12 diverse out-of-domain datasets confirms its robust zero-shot generalization, demonstrating a 63.8% reduction in estimation error and an 85.1% improvement in the coefficient of determination compared to the conventional training strategy. We demonstrate CoP's utility across scales: from deciphering non-linear hardware-noise interplay in consumer photography to optimizing photon-efficient protocols for deep-tissue microscopy. By decoding noise as a multi-parametric footprint, our work redefines stochastic degradation as a vital information resource, empowering precise imaging diagnostics without prior device calibration.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 123,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17058",
        "abs_url": "https://arxiv.org/abs/2601.17058",
        "pdf_url": "https://arxiv.org/pdf/2601.17058",
        "title": "Can LLMs Clean Up Your Mess? A Survey of Application-Ready Data Preparation with LLMs",
        "authors": [
            "Wei Zhou",
            "Jun Zhou",
            "Haoyu Wang",
            "Zhenghao Li",
            "Qikang He",
            "Shaokun Han",
            "Guoliang Li",
            "Xuanhe Zhou",
            "Yeye He",
            "Chunwei Liu",
            "Zirui Tang",
            "Bin Wang",
            "Shen Tang",
            "Kai Zuo",
            "Yuyu Luo",
            "Zhenzhe Zheng",
            "Conghui He",
            "Jingren Zhou",
            "Fan Wu"
        ],
        "comments": "Please refer to our repository for more details: this https URL",
        "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Data preparation aims to denoise raw datasets, uncover cross-dataset relationships, and extract valuable insights from them, which is essential for a wide range of data-centric applications. Driven by (i) rising demands for application-ready data (e.g., for analytics, visualization, decision-making), (ii) increasingly powerful LLM techniques, and (iii) the emergence of infrastructures that facilitate flexible agent construction (e.g., using Databricks Unity Catalog), LLM-enhanced methods are rapidly becoming a transformative and potentially dominant paradigm for data preparation. By investigating hundreds of recent literature works, this paper presents a systematic review of this evolving landscape, focusing on the use of LLM techniques to prepare data for diverse downstream tasks. First, we characterize the fundamental paradigm shift, from rule-based, model-specific pipelines to prompt-driven, context-aware, and agentic preparation workflows. Next, we introduce a task-centric taxonomy that organizes the field into three major tasks: data cleaning (e.g., standardization, error processing, imputation), data integration (e.g., entity matching, schema matching), and data enrichment (e.g., data annotation, profiling). For each task, we survey representative techniques, and highlight their respective strengths (e.g., improved generalization, semantic understanding) and limitations (e.g., the prohibitive cost of scaling LLMs, persistent hallucinations even in advanced agents, the mismatch between advanced methods and weak evaluation). Moreover, we analyze commonly used datasets and evaluation metrics (the empirical part). Finally, we discuss open research challenges and outline a forward-looking roadmap that emphasizes scalable LLM-data systems, principled designs for reliable agentic workflows, and robust evaluation protocols.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 124,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17082",
        "abs_url": "https://arxiv.org/abs/2601.17082",
        "pdf_url": "https://arxiv.org/pdf/2601.17082",
        "title": "Do VLMs Have a Moral Backbone? A Study on the Fragile Morality of Vision-Language Models",
        "authors": [
            "Zhining Liu",
            "Tianyi Wang",
            "Xiao Lin",
            "Penghao Ouyang",
            "Gaotang Li",
            "Ze Yang",
            "Hui Liu",
            "Sumit Keswani",
            "Vishwa Pardeshi",
            "Huijun Zhao",
            "Wei Fan",
            "Hanghang Tong"
        ],
        "comments": "",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
        "abstract": "Despite substantial efforts toward improving the moral alignment of Vision-Language Models (VLMs), it remains unclear whether their ethical judgments are stable in realistic settings. This work studies moral robustness in VLMs, defined as the ability to preserve moral judgments under textual and visual perturbations that do not alter the underlying moral context. We systematically probe VLMs with a diverse set of model-agnostic multimodal perturbations and find that their moral stances are highly fragile, frequently flipping under simple manipulations. Our analysis reveals systematic vulnerabilities across perturbation types, moral domains, and model scales, including a sycophancy trade-off where stronger instruction-following models are more susceptible to persuasion. We further show that lightweight inference-time interventions can partially restore moral stability. These results demonstrate that moral alignment alone is insufficient and that moral robustness is a necessary criterion for the responsible deployment of VLMs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 125,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17085",
        "abs_url": "https://arxiv.org/abs/2601.17085",
        "pdf_url": "https://arxiv.org/pdf/2601.17085",
        "title": "Recovering Performance in Speech Emotion Recognition from Discrete Tokens via Multi-Layer Fusion and Paralinguistic Feature Integration",
        "authors": [
            "Esther Sun",
            "Abinay Reddy Naini",
            "Carlos Busso"
        ],
        "comments": "Accepted to ICASSP 2026",
        "subjects": "Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD)",
        "abstract": "Discrete speech tokens offer significant advantages for storage and language model integration, but their application in speech emotion recognition (SER) is limited by paralinguistic information loss during quantization. This paper presents a comprehensive investigation of discrete tokens for SER. Using a fine-tuned WavLM-Large model, we systematically quantify performance degradation across different layer configurations and k-means quantization granularities. To recover the information loss, we propose two key strategies: (1) attention-based multi-layer fusion to recapture complementary information from different layers, and (2) integration of openSMILE features to explicitly reintroduce paralinguistic cues. We also compare mainstream neural codec tokenizers (SpeechTokenizer, DAC, EnCodec) and analyze their behaviors when fused with acoustic features. Our findings demonstrate that through multi-layer fusion and acoustic feature integration, discrete tokens can close the performance gap with continuous representations in SER tasks.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 126,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17103",
        "abs_url": "https://arxiv.org/abs/2601.17103",
        "pdf_url": "https://arxiv.org/pdf/2601.17103",
        "title": "Performance uncertainty in medical image analysis: a large-scale investigation of confidence intervals",
        "authors": [
            "Pascaline André",
            "Charles Heitz",
            "Evangelia Christodoulou",
            "Annika Reinke",
            "Carole H. Sudre",
            "Michela Antonelli",
            "Patrick Godau",
            "M. Jorge Cardoso",
            "Antoine Gilson",
            "Sophie Tezenas du Montcel",
            "Gaël Varoquaux",
            "Lena Maier-Hein",
            "Olivier Colliot"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
        "abstract": "Performance uncertainty quantification is essential for reliable validation and eventual clinical translation of medical imaging artificial intelligence (AI). Confidence intervals (CIs) play a central role in this process by indicating how precise a reported performance estimate is. Yet, due to the limited amount of work examining CI behavior in medical imaging, the community remains largely unaware of how many diverse CI methods exist and how they behave in specific settings. The purpose of this study is to close this gap. To this end, we conducted a large-scale empirical analysis across a total of 24 segmentation and classification tasks, using 19 trained models per task group, a broad spectrum of commonly used performance metrics, multiple aggregation strategies, and several widely adopted CI methods. Reliability (coverage) and precision (width) of each CI method were estimated across all settings to characterize their dependence on study characteristics. Our analysis revealed five principal findings: 1) the sample size required for reliable CIs varies from a few dozens to several thousands of cases depending on study parameters; 2) CI behavior is strongly affected by the choice of performance metric; 3) aggregation strategy substantially influences the reliability of CIs, e.g. they require more observations for macro than for micro; 4) the machine learning problem (segmentation versus classification) modulates these effects; 5) different CI methods are not equally reliable and precise depending on the use case. These results form key components for the development of future guidelines on reporting performance uncertainty in medical imaging AI.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 127,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17126",
        "abs_url": "https://arxiv.org/abs/2601.17126",
        "pdf_url": "https://arxiv.org/pdf/2601.17126",
        "title": "EveNet: A Foundation Model for Particle Collision Data Analysis",
        "authors": [
            "Ting-Hsiang Hsu",
            "Bai-Hong Zhou",
            "Qibin Liu",
            "Yue Xu",
            "Shu Li",
            "George Wei-Shu Hou",
            "Benjamin Nachman",
            "Shih-Chieh Hsu",
            "Vinicius Mikuni",
            "Yuan-Tang Chou",
            "Yulei Zhang"
        ],
        "comments": "26 pages, 8 figures",
        "subjects": "High Energy Physics - Experiment (hep-ex); Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph)",
        "abstract": "While deep learning is transforming data analysis in high-energy physics, computational challenges limit its potential. We address these challenges in the context of collider physics by introducing EveNet, an event-level foundation model pretrained on 500 million simulated collision events using a hybrid objective of self-supervised learning and physics-informed supervision. By leveraging a shared particle-cloud representation, EveNet outperforms state-of-the-art baselines across diverse tasks, including searches for heavy resonances and exotic Higgs decays, and demonstrates exceptional data efficiency in low-statistics regimes. Crucially, we validate the transferability of the model to experimental data by rediscovering the $\\Upsilon$ meson in CMS Open Data and show its capacity for precision physics through the robust extraction of quantum correlation observables stable against systematic uncertainties. These results indicate that EveNet can successfully encode the fundamental physical structure of particle interactions, which offers a unified and resource-efficient framework to accelerate discovery at current and future colliders.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 128,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17136",
        "abs_url": "https://arxiv.org/abs/2601.17136",
        "pdf_url": "https://arxiv.org/pdf/2601.17136",
        "title": "Communication-Avoiding Linear Algebraic Kernel K-Means on GPUs",
        "authors": [
            "Julian Bellavita",
            "Matthew Rubino",
            "Nakul Iyer",
            "Andrew Chang",
            "Aditya Devarakonda",
            "Flavio Vella",
            "Giulia Guidi"
        ],
        "comments": "",
        "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)",
        "abstract": "Clustering is an important tool in data analysis, with K-means being popular for its simplicity and versatility. However, it cannot handle non-linearly separable clusters. Kernel K-means addresses this limitation but requires a large kernel matrix, making it computationally and memory intensive. Prior work has accelerated Kernel K-means by formulating it using sparse linear algebra primitives and implementing it on a single GPU. However, that approach cannot run on datasets with more than approximately 80,000 samples due to limited GPU memory. In this work, we address this issue by presenting a suite of distributed-memory parallel algorithms for large-scale Kernel K-means clustering on multi-GPU systems. Our approach maps the most computationally expensive components of Kernel K-means onto communication-efficient distributed linear algebra primitives uniquely tailored for Kernel K-means, enabling highly scalable implementations that efficiently cluster million-scale datasets. Central to our work is the design of partitioning schemes that enable communication-efficient composition of the linear algebra primitives that appear in Kernel K-means. Our 1.5D algorithm consistently achieves the highest performance, enabling Kernel K-means to scale to data one to two orders of magnitude larger than previously practical. On 256 GPUs, it achieves a geometric mean weak scaling efficiency of $79.7\\%$ and a geometric mean strong scaling speedup of $4.2\\times$. Compared to our 1D algorithm, the 1.5D approach achieves up to a $3.6\\times$ speedup on 256 GPUs and reduces clustering time from over an hour to under two seconds relative to a single-GPU sliding window implementation. Our results show that distributed algorithms designed with application-specific linear algebraic formulations can achieve substantial performance improvement.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 129,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17146",
        "abs_url": "https://arxiv.org/abs/2601.17146",
        "pdf_url": "https://arxiv.org/pdf/2601.17146",
        "title": "Falsifying Predictive Algorithm",
        "authors": [
            "Amanda Coston"
        ],
        "comments": "",
        "subjects": "Methodology (stat.ME); Computers and Society (cs.CY); Machine Learning (cs.LG); Machine Learning (stat.ML)",
        "abstract": "Empirical investigations into unintended model behavior often show that the algorithm is predicting another outcome than what was intended. These exposes highlight the need to identify when algorithms predict unintended quantities - ideally before deploying them into consequential settings. We propose a falsification framework that provides a principled statistical test for discriminant validity: the requirement that an algorithm predict intended outcomes better than impermissible ones. Drawing on falsification practices from causal inference, econometrics, and psychometrics, our framework compares calibrated prediction losses across outcomes to assess whether the algorithm exhibits discriminant validity with respect to a specified impermissible proxy. In settings where the target outcome is difficult to observe, multiple permissible proxy outcomes may be available; our framework accommodates both this setting and the case with a single permissible proxy. Throughout we use nonparametric hypothesis testing methods that make minimal assumptions on the data-generating process. We illustrate the method in an admissions setting, where the framework establishes discriminant validity with respect to gender but fails to establish discriminant validity with respect to race. This demonstrates how falsification can serve as an early validity check, prior to fairness or robustness analyses. We also provide analysis in a criminal justice setting, where we highlight the limitations of our framework and emphasize the need for complementary approaches to assess other aspects of construct validity and external validity.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 130,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17160",
        "abs_url": "https://arxiv.org/abs/2601.17160",
        "pdf_url": "https://arxiv.org/pdf/2601.17160",
        "title": "Data-Driven Information-Theoretic Causal Bounds under Unmeasured Confounding",
        "authors": [
            "Yonghan Jung",
            "Bogyeong Kang"
        ],
        "comments": "",
        "subjects": "Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)",
        "abstract": "We develop a data-driven information-theoretic framework for sharp partial identification of causal effects under unmeasured confounding. Existing approaches often rely on restrictive assumptions, such as bounded or discrete outcomes; require external inputs (for example, instrumental variables, proxies, or user-specified sensitivity parameters); necessitate full structural causal model specifications; or focus solely on population-level averages while neglecting covariate-conditional treatment effects. We overcome all four limitations simultaneously by establishing novel information-theoretic, data-driven divergence bounds. Our key theoretical contribution shows that the f-divergence between the observational distribution P(Y | A = a, X = x) and the interventional distribution P(Y | do(A = a), X = x) is upper bounded by a function of the propensity score alone. This result enables sharp partial identification of conditional causal effects directly from observational data, without requiring external sensitivity parameters, auxiliary variables, full structural specifications, or outcome boundedness assumptions. For practical implementation, we develop a semiparametric estimator satisfying Neyman orthogonality (Chernozhukov et al., 2018), which ensures square-root-n consistent inference even when nuisance functions are estimated using flexible machine learning methods. Simulation studies and real-world data applications, implemented in the GitHub repository (this https URL), demonstrate that our framework provides tight and valid causal bounds across a wide range of data-generating processes.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 131,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17172",
        "abs_url": "https://arxiv.org/abs/2601.17172",
        "pdf_url": "https://arxiv.org/pdf/2601.17172",
        "title": "Who Gets Which Message? Auditing Demographic Bias in LLM-Generated Targeted Text",
        "authors": [
            "Tunazzina Islam"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs behave when tasked with demographic-conditioned targeted messaging. We introduce a controlled evaluation framework using three leading models -- GPT-4o, Llama-3.3, and Mistral-Large 2.1 -- across two generation settings: Standalone Generation, which isolates intrinsic demographic effects, and Context-Rich Generation, which incorporates thematic and regional context to emulate realistic targeting. We evaluate generated messages along three dimensions: lexical content, language style, and persuasive framing. We instantiate this framework on climate communication and find consistent age- and gender-based asymmetries across models: male- and youth-targeted messages emphasize agency, innovation, and assertiveness, while female- and senior-targeted messages stress warmth, care, and tradition. Contextual prompts systematically amplify these disparities, with persuasion scores significantly higher for messages tailored to younger or male audiences. Our findings demonstrate how demographic stereotypes can surface and intensify in LLM-generated targeted communication, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks that explicitly account for demographic conditioning in socially sensitive applications.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 132,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17184",
        "abs_url": "https://arxiv.org/abs/2601.17184",
        "pdf_url": "https://arxiv.org/pdf/2601.17184",
        "title": "FASTR: Reimagining FASTQ via Compact Image-inspired Representation",
        "authors": [
            "Adrian Tkachenko",
            "Sepehr Salem",
            "Ayotomiwa Ezekiel Adeniyi",
            "Zulal Bingol",
            "Mohammed Nayeem Uddin",
            "Akshat Prasanna",
            "Alexander Zelikovsky",
            "Serghei Mangul",
            "Can Alkan",
            "Mohammed Alser"
        ],
        "comments": "",
        "subjects": "Genomics (q-bio.GN); Machine Learning (cs.LG)",
        "abstract": "Motivation: High-throughput sequencing (HTS) enables population-scale genomics but generates massive datasets, creating bottlenecks in storage, transfer, and analysis. FASTQ, the standard format for over two decades, stores one byte per base and one byte per quality score, leading to inefficient I/O, high storage costs, and redundancy. Existing compression tools can mitigate some issues, but often introduce costly decompression or complex dependency issues. Results: We introduce FASTR, a lossless, computation-native successor to FASTQ that encodes each nucleotide together with its base quality score into a single 8-bit value. FASTR reduces file size by at least 2x while remaining fully reversible and directly usable for downstream analyses. Applying general-purpose compression tools on FASTR consistently yields higher compression ratios, 2.47, 3.64, and 4.8x faster compression, and 2.34, 1.96, 1.75x faster decompression than on FASTQ across Illumina, HiFi, and ONT reads. FASTR is machine-learning-ready, allowing reads to be consumed directly as numerical vectors or image-like representations. We provide a highly parallel software ecosystem for FASTQ-FASTR conversion and show that FASTR integrates with existing tools, such as minimap2, with minimal interface changes and no performance overhead. By eliminating decompression costs and reducing data movement, FASTR lays the foundation for scalable genomics analyses and real-time sequencing workflows. Availability and Implementation: this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 133,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17197",
        "abs_url": "https://arxiv.org/abs/2601.17197",
        "pdf_url": "https://arxiv.org/pdf/2601.17197",
        "title": "Reasoning Beyond Literal: Cross-style Multimodal Reasoning for Figurative Language Understanding",
        "authors": [
            "Seyyed Saeid Cheshmi",
            "Hahnemann Ortiz",
            "James Mooney",
            "Dongyeop Kang"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Vision-language models (VLMs) have demonstrated strong reasoning abilities in literal multimodal tasks such as visual mathematics and science question answering. However, figurative language, such as sarcasm, humor, and metaphor, remains a significant challenge, as it conveys intent and emotion through subtle incongruities between expressed and intended meanings. In multimodal settings, accompanying images can amplify or invert textual meaning, demanding models that reason across modalities and account for subjectivity. We propose a three-step framework for developing efficient multimodal reasoning models that can (i) interpret multimodal figurative language, (ii) provide transparent reasoning traces, and (iii) generalize across multiple figurative styles. Experiments across four styles show that (1) incorporating reasoning traces substantially improves multimodal figurative understanding, (2) reasoning learned in one style can transfer to others, especially between related styles like sarcasm and humor, and (3) training jointly across styles yields a generalized reasoning VLM that outperforms much larger open- and closed-source models. Our findings show that lightweight VLMs with verifiable reasoning achieve robust cross-style generalization while providing inspectable reasoning traces for multimodal tasks. The code and implementation are available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 134,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17218",
        "abs_url": "https://arxiv.org/abs/2601.17218",
        "pdf_url": "https://arxiv.org/pdf/2601.17218",
        "title": "Evaluation on Entity Matching in Recommender Systems",
        "authors": [
            "Zihan Huang",
            "Rohan Surana",
            "Zhouhang Xie",
            "Junda Wu",
            "Yu Xia",
            "Julian McAuley"
        ],
        "comments": "",
        "subjects": "Information Retrieval (cs.IR); Machine Learning (cs.LG)",
        "abstract": "Entity matching is a crucial component in various recommender systems, including conversational recommender systems (CRS) and knowledge-based recommender systems. However, the lack of rigorous evaluation frameworks for cross-dataset entity matching impedes progress in areas such as LLM-driven conversational recommendations and knowledge-grounded dataset construction. In this paper, we introduce Reddit-Amazon-EM, a novel dataset comprising naturally occurring items from Reddit and the Amazon '23 dataset. Through careful manual annotation, we identify corresponding movies across Reddit-Movies and Amazon'23, two existing recommender system datasets with inherently overlapping catalogs. Leveraging Reddit-Amazon-EM, we conduct a comprehensive evaluation of state-of-the-art entity matching methods, including rule-based, graph-based, lexical-based, embedding-based, and LLM-based approaches. For reproducible research, we release our manually annotated entity matching gold set and provide the mapping between the two datasets using the best-performing method from our experiments. This serves as a valuable resource for advancing future work on entity matching in recommender systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 135,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17222",
        "abs_url": "https://arxiv.org/abs/2601.17222",
        "pdf_url": "https://arxiv.org/pdf/2601.17222",
        "title": "Improving Generalization and Uncertainty Quantification of Photometric Redshift Models",
        "authors": [
            "Jonathan Soriano",
            "Tuan Do",
            "Srinath Saikrishnan",
            "Vikram Seenivasan",
            "Bernie Boscoe",
            "Jack Singal",
            "Evan Jones"
        ],
        "comments": "27 pages, 16 figures, 7 Tables, accepted for publication in AJ",
        "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Machine Learning (cs.LG)",
        "abstract": "Accurate redshift estimates are a vital component in understanding galaxy evolution and precision cosmology. In this paper, we explore approaches to increase the applicability of machine learning models for photometric redshift estimation on a broader range of galaxy types. Typical models are trained with ground-truth redshifts from spectroscopy. We test the utility and effectiveness of two approaches for combining spectroscopic redshifts and redshifts derived from multiband ($\\sim$35 filters) photometry, which sample different types of galaxies compared to spectroscopic surveys. The two approaches are (1) training on a composite dataset and (2) transfer learning from one dataset to another. We compile photometric redshifts from the COSMOS2020 catalog (TransferZ) to complement an established spectroscopic redshift dataset (GalaxiesML). We used two architectures, deterministic neural networks (NN) and Bayesian neural networks (BNN), to examine and evaluate their performance with respect to the Legacy Survey of Space and Time (LSST) photo-$z$ science requirements. We also use split conformal prediction for calibrating uncertainty estimates and producing prediction intervals for the BNN and NN, respectively. We find that a NN trained on a composite dataset predicts photo-$z$'s that are 4.5 times less biased within the redshift range $0.3<z<1.5$, 1.1 times less scattered, and has a 1.4 times lower outlier rate than a model trained on only spectroscopic ground truths. We also find that BNNs produce reliable uncertainty estimates, but are sensitive to the different ground truths. This investigation leverages different sources of ground truths to develop models that can accurately predict photo-$z$'s for a broader population of galaxies crucial for surveys such as Euclid and LSST.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 136,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17230",
        "abs_url": "https://arxiv.org/abs/2601.17230",
        "pdf_url": "https://arxiv.org/pdf/2601.17230",
        "title": "CaseFacts: A Benchmark for Legal Fact-Checking and Precedent Retrieval",
        "authors": [
            "Akshith Reddy Putta",
            "Jacob Devasier",
            "Chengkai Li"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Automated Fact-Checking has largely focused on verifying general knowledge against static corpora, overlooking high-stakes domains like law where truth is evolving and technically complex. We introduce CaseFacts, a benchmark for verifying colloquial legal claims against U.S. Supreme Court precedents. Unlike existing resources that map formal texts to formal texts, CaseFacts challenges systems to bridge the semantic gap between layperson assertions and technical jurisprudence while accounting for temporal validity. The dataset consists of 6,294 claims categorized as Supported, Refuted, or Overruled. We construct this benchmark using a multi-stage pipeline that leverages Large Language Models (LLMs) to synthesize claims from expert case summaries, employing a novel semantic similarity heuristic to efficiently identify and verify complex legal overrulings. Experiments with state-of-the-art LLMs reveal that the task remains challenging; notably, augmenting models with unrestricted web search degrades performance compared to closed-book baselines due to the retrieval of noisy, non-authoritative precedents. We release CaseFacts to spur research into legal fact verification systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 137,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17295",
        "abs_url": "https://arxiv.org/abs/2601.17295",
        "pdf_url": "https://arxiv.org/pdf/2601.17295",
        "title": "Structure-Aware NL-to-SQL for SFC Provisioning via AST-Masking Empowered Language Models",
        "authors": [
            "Xinyu Zhu",
            "Parisa Fard Moshiri",
            "Poonam Lohan",
            "Burak Kantarci",
            "Emil Janulewicz"
        ],
        "comments": "6 pages, 3 figures, accepted to IEEE International Conference on Communications (ICC) 2026",
        "subjects": "Networking and Internet Architecture (cs.NI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Effective Service Function Chain (SFC) provisioning requires precise orchestration in dynamic and latency-sensitive networks. Reinforcement Learning (RL) improves adaptability but often ignores structured domain knowledge, which limits generalization and interpretability. Large Language Models (LLMs) address this gap by translating natural language (NL) specifications into executable Structured Query Language (SQL) commands for specification-driven SFC management. Conventional fine-tuning, however, can cause syntactic inconsistencies and produce inefficient queries. To overcome this, we introduce Abstract Syntax Tree (AST)-Masking, a structure-aware fine-tuning method that uses SQL ASTs to assign weights to key components and enforce syntax-aware learning without adding inference overhead. Experiments show that AST-Masking significantly improves SQL generation accuracy across multiple language models. FLAN-T5 reaches an Execution Accuracy (EA) of 99.6%, while Gemma achieves the largest absolute gain from 7.5% to 72.0%. These results confirm the effectiveness of structure-aware fine-tuning in ensuring syntactically correct and efficient SQL generation for interpretable SFC orchestration.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 138,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17374",
        "abs_url": "https://arxiv.org/abs/2601.17374",
        "pdf_url": "https://arxiv.org/pdf/2601.17374",
        "title": "Error Analysis of Bayesian Inverse Problems with Generative Priors",
        "authors": [
            "Bamdad Hosseini",
            "Ziqi Huang"
        ],
        "comments": "30 pages, 8 figures",
        "subjects": "Machine Learning (stat.ML); Machine Learning (cs.LG); Numerical Analysis (math.NA)",
        "abstract": "Data-driven methods for the solution of inverse problems have become widely popular in recent years thanks to the rise of machine learning techniques. A popular approach concerns the training of a generative model on additional data to learn a bespoke prior for the problem at hand. In this article we present an analysis for such problems by presenting quantitative error bounds for minimum Wasserstein-2 generative models for the prior. We show that under some assumptions, the error in the posterior due to the generative prior will inherit the same rate as the prior with respect to the Wasserstein-1 distance. We further present numerical experiments that verify that aspects of our error analysis manifests in some benchmarks followed by an elliptic PDE inverse problem where a generative prior is used to model a non-stationary field.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 139,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17438",
        "abs_url": "https://arxiv.org/abs/2601.17438",
        "pdf_url": "https://arxiv.org/pdf/2601.17438",
        "title": "UniGRec: Unified Generative Recommendation with Soft Identifiers for End-to-End Optimization",
        "authors": [
            "Jialei Li",
            "Yang Zhang",
            "Yimeng Bai",
            "Shuai Zhu",
            "Ziqi Xue",
            "Xiaoyan Zhao",
            "Dingxian Wang",
            "Frank Yang",
            "Andrew Rabinovich",
            "Xiangnan He"
        ],
        "comments": "11 pages, 6 figures",
        "subjects": "Information Retrieval (cs.IR); Machine Learning (cs.LG)",
        "abstract": "Generative recommendation has recently emerged as a transformative paradigm that directly generates target items, surpassing traditional cascaded approaches. It typically involves two components: a tokenizer that learns item identifiers and a recommender trained on them. Existing methods often decouple tokenization from recommendation or rely on asynchronous alternating optimization, limiting full end-to-end alignment. To address this, we unify the tokenizer and recommender under the ultimate recommendation objective via differentiable soft item identifiers, enabling joint end-to-end training. However, this introduces three challenges: training-inference discrepancy due to soft-to-hard mismatch, item identifier collapse from codeword usage imbalance, and collaborative signal deficiency due to an overemphasis on fine-grained token-level semantics. To tackle these challenges, we propose UniGRec, a unified generative recommendation framework that addresses them from three perspectives. UniGRec employs Annealed Inference Alignment during tokenization to smoothly bridge soft training and hard inference, a Codeword Uniformity Regularization to prevent identifier collapse and encourage codebook diversity, and a Dual Collaborative Distillation mechanism that distills collaborative priors from a lightweight teacher model to jointly guide both the tokenizer and the recommender. Extensive experiments on real-world datasets demonstrate that UniGRec consistently outperforms state-of-the-art baseline methods. Our codes are available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 140,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17442",
        "abs_url": "https://arxiv.org/abs/2601.17442",
        "pdf_url": "https://arxiv.org/pdf/2601.17442",
        "title": "A new approach for combined model class selection and parameters learning for auto-regressive neural models",
        "authors": [
            "Corrado Sgadari",
            "Alessio La Bella",
            "Marcello Farina"
        ],
        "comments": "",
        "subjects": "Systems and Control (eess.SY); Machine Learning (cs.LG)",
        "abstract": "This work introduces a novel approach for the joint selection of model structure and parameter learning for nonlinear dynamical systems identification. Focusing on a specific Recurrent Neural Networks (RNNs) family, i.e., Nonlinear Auto-Regressive with eXogenous inputs Echo State Networks (NARXESNs), the method allows to simultaneously select the optimal model class and learn model parameters from data through a new set-membership (SM) based procedure. The results show the effectiveness of the approach in identifying parsimonious yet accurate models suitable for control applications. Moreover, the proposed framework enables a robust training strategy that explicitly accounts for bounded measurement noise and enhances model robustness by allowing data-consistent evaluation of simulation performance during parameter learning, a process generally NP-hard for models with autoregressive components.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 141,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17454",
        "abs_url": "https://arxiv.org/abs/2601.17454",
        "pdf_url": "https://arxiv.org/pdf/2601.17454",
        "title": "Embodiment-Induced Coordination Regimes in Tabular Multi-Agent Q-Learning",
        "authors": [
            "Muhammad Ahmed Atif",
            "Nehal Naeem Haji",
            "Mohammad Shahid Shaikh",
            "Muhammad Ebad Atif"
        ],
        "comments": "",
        "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Centralized value learning is often assumed to improve coordination and stability in multi-agent reinforcement learning, yet this assumption is rarely tested under controlled conditions. We directly evaluate it in a fully tabular predator-prey gridworld by comparing independent and centralized Q-learning under explicit embodiment constraints on agent speed and stamina. Across multiple kinematic regimes and asymmetric agent roles, centralized learning fails to provide a consistent advantage and is frequently outperformed by fully independent learning, even under full observability and exact value estimation. Moreover, asymmetric centralized-independent configurations induce persistent coordination breakdowns rather than transient learning instability. By eliminating confounding effects from function approximation and representation learning, our tabular analysis isolates coordination structure as the primary driver of these effects. The results show that increased coordination can become a liability under embodiment constraints, and that the effectiveness of centralized learning is fundamentally regime and role dependent rather than universal.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 142,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17465",
        "abs_url": "https://arxiv.org/abs/2601.17465",
        "pdf_url": "https://arxiv.org/pdf/2601.17465",
        "title": "Bayesian quantum sensing using graybox machine learning",
        "authors": [
            "Akram Youssry",
            "Stefan Todd",
            "Patrick Murton",
            "Muhammad Junaid Arshad",
            "Alberto Peruzzo",
            "Cristian Bonato"
        ],
        "comments": "",
        "subjects": "Quantum Physics (quant-ph); Machine Learning (cs.LG); Signal Processing (eess.SP)",
        "abstract": "Quantum sensors offer significant advantages over classical devices in spatial resolution and sensitivity, enabling transformative applications across materials science, healthcare, and beyond. Their practical performance, however, is often constrained by unmodelled effects, including noise, imperfect state preparation, and non-ideal control fields. In this work, we report the first experimental implementation of a graybox modelling strategy for a solid-state open quantum system. The graybox framework integrates a physics-based system model with a data-driven description of experimental imperfections, achieving higher fidelity than purely analytical (whitebox) approaches while requiring fewer training resources than fully deep-learning models. We experimentally validate the method on the task of estimating a static magnetic field using a single-spin quantum sensor, performing Bayesian inference with a graybox model trained on prior experimental data. Using roughly 10,000 training datapoints, the graybox model yields several orders of magnitude improvement in mean squared error over the corresponding physics-only model. These results are broadly applicable to a wide range of quantum sensing platforms, not limited to single-spin systems, and are particularly valuable for real-time adaptive protocols, where model inaccuracies can otherwise lead to suboptimal control and degraded performance.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 143,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17517",
        "abs_url": "https://arxiv.org/abs/2601.17517",
        "pdf_url": "https://arxiv.org/pdf/2601.17517",
        "title": "EuleroDec: A Complex-Valued RVQ-VAE for Efficient and Robust Audio Coding",
        "authors": [
            "Luca Cerovaz",
            "Michele Mancusi",
            "Emanuele Rodolà"
        ],
        "comments": "Accepted at ICASSP 2026",
        "subjects": "Sound (cs.SD); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)",
        "abstract": "Audio codecs power discrete music generative modelling, music streaming, and immersive media by shrinking PCM audio to bandwidth-friendly bitrates. Recent works have gravitated towards processing in the spectral domain; however, spectrogram domains typically struggle with phase modeling, which is naturally complex-valued. Most frequency-domain neural codecs either disregard phase information or encode it as two separate real-valued channels, limiting spatial fidelity. This entails the need to introduce adversarial discriminators at the expense of convergence speed and training stability to compensate for the inadequate representation power of the audio signal. In this work we introduce an end-to-end complex-valued RVQ-VAE audio codec that preserves magnitude-phase coupling across the entire analysis-quantization-synthesis pipeline and removes adversarial discriminators and diffusion post-filters. Without GANs or diffusion, we match or surpass much longer-trained baselines in-domain and reach SOTA out-of-domain performance on phase coherence and waveform fidelity. Compared to standard baselines that train for hundreds of thousands of steps, our model, which reduces the training budget by an order of magnitude, is markedly more compute-efficient while preserving high perceptual quality.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 144,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17536",
        "abs_url": "https://arxiv.org/abs/2601.17536",
        "pdf_url": "https://arxiv.org/pdf/2601.17536",
        "title": "OTI: A Model-free and Visually Interpretable Measure of Image Attackability",
        "authors": [
            "Jiaming Liang",
            "Haowei Liu",
            "Chi-Man Pun"
        ],
        "comments": "",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
        "abstract": "Despite the tremendous success of neural networks, benign images can be corrupted by adversarial perturbations to deceive these models. Intriguingly, images differ in their attackability. Specifically, given an attack configuration, some images are easily corrupted, whereas others are more resistant. Evaluating image attackability has important applications in active learning, adversarial training, and attack enhancement. This prompts a growing interest in developing attackability measures. However, existing methods are scarce and suffer from two major limitations: (1) They rely on a model proxy to provide prior knowledge (e.g., gradients or minimal perturbation) to extract model-dependent image features. Unfortunately, in practice, many task-specific models are not readily accessible. (2) Extracted features characterizing image attackability lack visual interpretability, obscuring their direct relationship with the images. To address these, we propose a novel Object Texture Intensity (OTI), a model-free and visually interpretable measure of image attackability, which measures image attackability as the texture intensity of the image's semantic object. Theoretically, we describe the principles of OTI from the perspectives of decision boundaries as well as the mid- and high-frequency characteristics of adversarial perturbations. Comprehensive experiments demonstrate that OTI is effective and computationally efficient. In addition, our OTI provides the adversarial machine learning community with a visual understanding of attackability.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 145,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17551",
        "abs_url": "https://arxiv.org/abs/2601.17551",
        "pdf_url": "https://arxiv.org/pdf/2601.17551",
        "title": "GreenServ: Energy-Efficient Context-Aware Dynamic Routing for Multi-Model LLM Inference",
        "authors": [
            "Thomas Ziller",
            "Shashikant Ilager",
            "Alessandro Tundo",
            "Ezio Bartocci",
            "Leonardo Mariani",
            "Ivona Brandic"
        ],
        "comments": "Paper under submisison",
        "subjects": "Performance (cs.PF); Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) demonstrate remarkable capabilities, but their broad deployment is limited by significant computational resource demands, particularly energy consumption during inference. Static, one-model-fits-all inference strategies are often inefficient, as they do not exploit the diverse range of available models or adapt to varying query requirements. This paper presents GreenServ, a dynamic, context-aware routing framework that optimizes the trade-off between inference accuracy and energy efficiency. GreenServ extracts lightweight contextual features from each query, including task type, semantic cluster, and text complexity, and routes queries to the most suitable model from a heterogeneous pool, based on observed accuracy and energy usage. We employ a multi-armed bandit approach to learn adaptive routing policies online. This approach operates under partial feedback, eliminates the need for extensive offline calibration, and streamlines the integration of new models into the inference pipeline. We evaluated GreenServ across five benchmark tasks and a pool of 16 contemporary open-access LLMs. Experimental results show that GreenServ consistently outperforms static (single-model) and random baselines. In particular, compared to random routing, GreenServ achieved a 22% increase in accuracy while reducing cumulative energy consumption by 31%. Finally, we evaluated GreenServ with RouterBench, achieving an average accuracy of 71.7% with a peak accuracy of 75.7%. All artifacts are open-source and available as an anonymous repository for review purposes here: this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 146,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17562",
        "abs_url": "https://arxiv.org/abs/2601.17562",
        "pdf_url": "https://arxiv.org/pdf/2601.17562",
        "title": "Sparse RBF Networks for PDEs and nonlocal equations: function space theory, operator calculus, and training algorithms",
        "authors": [
            "Zihan Shao",
            "Konstantin Pieper",
            "Xiaochuan Tian"
        ],
        "comments": "30 pages, 7 figures",
        "subjects": "Numerical Analysis (math.NA); Machine Learning (cs.LG)",
        "abstract": "This work presents a systematic analysis and extension of the sparse radial basis function network (SparseRBFnet) previously introduced for solving nonlinear partial differential equations (PDEs). Based on its adaptive-width shallow kernel network formulation, we further investigate its function-space characterization, operator evaluation, and computational algorithm. We provide a unified description of the solution space for a broad class of radial basis functions (RBFs). Under mild assumptions, this space admits a characterization as a Besov space, independent of the specific kernel choice. We further demonstrate how the explicit kernel-based structure enables quasi-analytical evaluation of both differential and nonlocal operators, including fractional Laplacians. On the computational end, we study the adaptive-width network and related three-phase training strategy through a comparison with variants concerning the modeling and algorithmic details. In particular, we assess the roles of second-order optimization, inner-weight training, network adaptivity, and anisotropic kernel parameterizations. Numerical experiments on high-order, fractional, and anisotropic PDE benchmarks illustrate the empirical insensitivity to kernel choice, as well as the resulting trade-offs between accuracy, sparsity, and computational cost. Collectively, these results consolidate and generalize the theoretical and computational framework of SparseRBFnet, supporting accurate sparse representations with efficient operator evaluation and offering theory-grounded guidance for algorithmic and modeling choices.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 147,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17571",
        "abs_url": "https://arxiv.org/abs/2601.17571",
        "pdf_url": "https://arxiv.org/pdf/2601.17571",
        "title": "ME-WARD: A multimodal ergonomic analysis tool for musculoskeletal risk assessment from inertial and video data in working plac",
        "authors": [
            "Javier González-Alonso",
            "Paula Martín-Tapia",
            "David González-Ortega",
            "Míriam Antón-Rodríguez",
            "Francisco Javier Díaz-Pernas",
            "Mario Martínez-Zarzuela"
        ],
        "comments": "19 pages",
        "subjects": "Signal Processing (eess.SP); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
        "abstract": "This study presents ME-WARD (Multimodal Ergonomic Workplace Assessment and Risk from Data), a novel system for ergonomic assessment and musculoskeletal risk evaluation that implements the Rapid Upper Limb Assessment (RULA) method. ME-WARD is designed to process joint angle data from motion capture systems, including inertial measurement unit (IMU)-based setups, and deep learning human body pose tracking models. The tool's flexibility enables ergonomic risk assessment using any system capable of reliably measuring joint angles, extending the applicability of RULA beyond proprietary setups. To validate its performance, the tool was tested in an industrial setting during the assembly of conveyor belts, which involved high-risk tasks such as inserting rods and pushing conveyor belt components. The experiments leveraged gold standard IMU systems alongside a state-of-the-art monocular 3D pose estimation system. The results confirmed that ME-WARD produces reliable RULA scores that closely align with IMU-derived metrics for flexion-dominated movements and comparable performance with the monocular system, despite limitations in tracking lateral and rotational motions. This work highlights the potential of integrating multiple motion capture technologies into a unified and accessible ergonomic assessment pipeline. By supporting diverse input sources, including low-cost video-based systems, the proposed multimodal approach offers a scalable, cost-effective solution for ergonomic assessments, paving the way for broader adoption in resource-constrained industrial environments.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 148,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17586",
        "abs_url": "https://arxiv.org/abs/2601.17586",
        "pdf_url": "https://arxiv.org/pdf/2601.17586",
        "title": "Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization",
        "authors": [
            "Sebastian Doerrich",
            "Francesco Di Salvo",
            "Jonas Alle",
            "Christian Ledig"
        ],
        "comments": "Accepted at 23rd IEEE International Symposium on Biomedical Imaging (IEEE ISBI 2026)",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Image and Video Processing (eess.IV)",
        "abstract": "Deep learning models in medical image analysis often struggle with generalizability across domains and demographic groups due to data heterogeneity and scarcity. Traditional augmentation improves robustness, but fails under substantial domain shifts. Recent advances in stylistic augmentation enhance domain generalization by varying image styles but fall short in terms of style diversity or by introducing artifacts into the generated images. To address these limitations, we propose Stylizing ViT, a novel Vision Transformer encoder that utilizes weight-shared attention blocks for both self- and cross-attention. This design allows the same attention block to maintain anatomical consistency through self-attention while performing style transfer via cross-attention. We assess the effectiveness of our method for domain generalization by employing it for data augmentation on three distinct image classification tasks in the context of histopathology and dermatology. Results demonstrate an improved robustness (up to +13% accuracy) over the state of the art while generating perceptually convincing images without artifacts. Additionally, we show that Stylizing ViT is effective beyond training, achieving a 17% performance improvement during inference when used for test-time augmentation. The source code is available at this https URL .",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 149,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17598",
        "abs_url": "https://arxiv.org/abs/2601.17598",
        "pdf_url": "https://arxiv.org/pdf/2601.17598",
        "title": "Deep Intrinsic Surprise-Regularized Control (DISRC): A Biologically Inspired Mechanism for Efficient Deep Q-Learning in Sparse Environments",
        "authors": [
            "Yash Kini",
            "Shiv Davay",
            "Shreya Polavarapu"
        ],
        "comments": "5 pages, 3 figures, 1 table. Preprint version of work submitted, accepted, and presented at IEEE URTC. Accepted and pending publication in IEEE Xplore",
        "subjects": "Neural and Evolutionary Computing (cs.NE); Machine Learning (cs.LG)",
        "abstract": "Deep reinforcement learning (DRL) has driven major advances in autonomous control. Still, standard Deep Q-Network (DQN) agents tend to rely on fixed learning rates and uniform update scaling, even as updates are modulated by temporal-difference (TD) error. This rigidity destabilizes convergence, especially in sparse-reward settings where feedback is infrequent. We introduce Deep Intrinsic Surprise-Regularized Control (DISRC), a biologically inspired augmentation to DQN that dynamically scales Q-updates based on latent-space surprise. DISRC encodes states via a LayerNorm-based encoder and computes a deviation-based surprise score relative to a moving latent setpoint. Each update is then scaled in proportion to both TD error and surprise intensity, promoting plasticity during early exploration and stability as familiarity increases. We evaluate DISRC on two sparse-reward MiniGrid environments, which included MiniGrid-DoorKey-8x8 and MiniGrid-LavaCrossingS9N1, under identical settings as a vanilla DQN baseline. In DoorKey, DISRC reached the first successful episode (reward > 0.8) 33% faster than the vanilla DQN baseline (79 vs. 118 episodes), with lower reward standard deviation (0.25 vs. 0.34) and higher reward area under the curve (AUC: 596.42 vs. 534.90). These metrics reflect faster, more consistent learning - critical for sparse, delayed reward settings. In LavaCrossing, DISRC achieved a higher final reward (0.95 vs. 0.93) and the highest AUC of all agents (957.04), though it converged more gradually. These preliminary results establish DISRC as a novel mechanism for regulating learning intensity in off-policy agents, improving both efficiency and stability in sparse-reward domains. By treating surprise as an intrinsic learning signal, DISRC enables agents to modulate updates based on expectation violations, enhancing decision quality when conventional value-based methods fall short.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 150,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17611",
        "abs_url": "https://arxiv.org/abs/2601.17611",
        "pdf_url": "https://arxiv.org/pdf/2601.17611",
        "title": "ToS: A Team of Specialists ensemble framework for Stereo Sound Event Localization and Detection with distance estimation in Video",
        "authors": [
            "Davide Berghi",
            "Philip J. B. Jackson"
        ],
        "comments": "",
        "subjects": "Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD); Image and Video Processing (eess.IV); Signal Processing (eess.SP)",
        "abstract": "Sound event localization and detection with distance estimation (3D SELD) in video involves identifying active sound events at each time frame while estimating their spatial coordinates. This multimodal task requires joint reasoning across semantic, spatial, and temporal dimensions, a challenge that single models often struggle to address effectively. To tackle this, we introduce the Team of Specialists (ToS) ensemble framework, which integrates three complementary sub-networks: a spatio-linguistic model, a spatio-temporal model, and a tempo-linguistic model. Each sub-network specializes in a unique pair of dimensions, contributing distinct insights to the final prediction, akin to a collaborative team with diverse expertise. ToS has been benchmarked against state-of-the-art audio-visual models for 3D SELD on the DCASE2025 Task 3 Stereo SELD development set, consistently outperforming existing methods across key metrics. Future work will extend this proof of concept by strengthening the specialists with appropriate tasks, training, and pre-training curricula.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 151,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17615",
        "abs_url": "https://arxiv.org/abs/2601.17615",
        "pdf_url": "https://arxiv.org/pdf/2601.17615",
        "title": "Athena: Synergizing Data Prefetching and Off-Chip Prediction via Online Reinforcement Learning",
        "authors": [
            "Rahul Bera",
            "Zhenrong Lang",
            "Caroline Hengartner",
            "Konstantinos Kanellopoulos",
            "Rakesh Kumar",
            "Mohammad Sadrosadati",
            "Onur Mutlu"
        ],
        "comments": "",
        "subjects": "Hardware Architecture (cs.AR); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)",
        "abstract": "Prefetching and off-chip prediction are two techniques proposed to hide long memory access latencies in high-performance processors. In this work, we demonstrate that: (1) prefetching and off-chip prediction often provide complementary performance benefits, yet (2) naively combining them often fails to realize their full performance potential, and (3) existing prefetcher control policies leave significant room for performance improvement behind. Our goal is to design a holistic framework that can autonomously learn to coordinate an off-chip predictor with multiple prefetchers employed at various cache levels. To this end, we propose a new technique called Athena, which models the coordination between prefetchers and off-chip predictor (OCP) as a reinforcement learning (RL) problem. Athena acts as the RL agent that observes multiple system-level features (e.g., prefetcher/OCP accuracy, bandwidth usage) over an epoch of program execution, and uses them as state information to select a coordination action (i.e., enabling the prefetcher and/or OCP, and adjusting prefetcher aggressiveness). At the end of every epoch, Athena receives a numerical reward that measures the change in multiple system-level metrics (e.g., number of cycles taken to execute an epoch). Athena uses this reward to autonomously and continuously learn a policy to coordinate prefetchers with OCP. Our extensive evaluation using a diverse set of memory-intensive workloads shows that Athena consistently outperforms prior state-of-the-art coordination policies across a wide range of system configurations with various combinations of underlying prefetchers, OCPs, and main memory bandwidths, while incurring only modest storage overhead. Athena is freely available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 152,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17690",
        "abs_url": "https://arxiv.org/abs/2601.17690",
        "pdf_url": "https://arxiv.org/pdf/2601.17690",
        "title": "Segment Length Matters: A Study of Segment Lengths on Audio Fingerprinting Performance",
        "authors": [
            "Ziling Gong",
            "Yunyan Ouyang",
            "Iram Kamdar",
            "Melody Ma",
            "Hongjie Chen",
            "Franck Dernoncourt",
            "Ryan A. Rossi",
            "Nesreen K. Ahmed"
        ],
        "comments": "",
        "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)",
        "abstract": "Audio fingerprinting provides an identifiable representation of acoustic signals, which can be later used for identification and retrieval systems. To obtain a discriminative representation, the input audio is usually segmented into shorter time intervals, allowing local acoustic features to be extracted and analyzed. Modern neural approaches typically operate on short, fixed-duration audio segments, yet the choice of segment duration is often made heuristically and rarely examined in depth. In this paper, we study how segment length affects audio fingerprinting performance. We extend an existing neural fingerprinting architecture to adopt various segment lengths and evaluate retrieval accuracy across different segment lengths and query durations. Our results show that short segment lengths (0.5-second) generally achieve better performance. Moreover, we evaluate LLM capacity in recommending the best segment length, which shows that GPT-5-mini consistently gives the best suggestions across five considerations among three studied LLMs. Our findings provide practical guidance for selecting segment duration in large-scale neural audio retrieval systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 153,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17702",
        "abs_url": "https://arxiv.org/abs/2601.17702",
        "pdf_url": "https://arxiv.org/pdf/2601.17702",
        "title": "S$^3$-Attention:Attention-Aligned Endogenous Retrieval for Memory-Bounded Long-Context Inference",
        "authors": [
            "Qingsen Ma",
            "Dianyun Wang",
            "Yaoye Wang",
            "Lechen Ning",
            "Sujie Zhu",
            "Xiaohang Zhang",
            "Jiaming Lyu",
            "Linhao Ren",
            "Zhenbo Xu",
            "Zhaofeng He"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages. We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size. At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 154,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17749",
        "abs_url": "https://arxiv.org/abs/2601.17749",
        "pdf_url": "https://arxiv.org/pdf/2601.17749",
        "title": "Over-The-Air Extreme Learning Machines with XL Reception via Nonlinear Cascaded Metasurfaces",
        "authors": [
            "Kyriakos Stylianopoulos",
            "Mattia Fabiani",
            "Giulia Torcolacci",
            "Davide Dardari",
            "George C. Alexandropoulos"
        ],
        "comments": "6 pages, 5 figures, to be presented at a conference",
        "subjects": "Signal Processing (eess.SP); Emerging Technologies (cs.ET); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
        "abstract": "The recently envisioned goal-oriented communications paradigm calls for the application of inference on wirelessly transferred data via Machine Learning (ML) tools. An emerging research direction deals with the realization of inference ML models directly in the physical layer of Multiple-Input Multiple-Output (MIMO) systems, which, however, entails certain significant challenges. In this paper, leveraging the technology of programmable MetaSurfaces (MSs), we present an eXtremely Large (XL) MIMO system that acts as an Extreme Learning Machine (ELM) performing binary classification tasks completely Over-The-Air (OTA), which can be trained in closed form. The proposed system comprises a receiver architecture consisting of densely parallel placed diffractive layers of XL MSs followed by a single reception radio-frequency chain. The front layer facing the MIMO channel consists of identical unit cells of a fixed NonLinear (NL) response, while the remaining layers of elements of tunable linear responses are utilized to approximate OTA the trained ELM weights. Our numerical investigations showcase that, in the XL regime of MS elements, the proposed XL-MIMO-ELM system achieves performance comparable to that of digital and idealized ML models across diverse datasets and wireless scenarios, thereby demonstrating the feasibility of embedding OTA learning capabilities into future communication systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 155,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17773",
        "abs_url": "https://arxiv.org/abs/2601.17773",
        "pdf_url": "https://arxiv.org/pdf/2601.17773",
        "title": "MarketGANs: Multivariate financial time-series data augmentation using generative adversarial networks",
        "authors": [
            "Jeonggyu Huh",
            "Seungwon Jeong",
            "Hyun-Gyoon Kim",
            "Hyeng Keun Koo",
            "Byung Hwa Lim"
        ],
        "comments": "",
        "subjects": "Statistical Finance (q-fin.ST); Machine Learning (cs.LG); Econometrics (econ.EM)",
        "abstract": "This paper introduces MarketGAN, a factor-based generative framework for high-dimensional asset return generation under severe data scarcity. We embed an explicit asset-pricing factor structure as an economic inductive bias and generate returns as a single joint vector, thereby preserving cross-sectional dependence and tail co-movement alongside inter-temporal dynamics. MarketGAN employs generative adversarial learning with a temporal convolutional network (TCN) backbone, which models stochastic, time-varying factor loadings and volatilities and captures long-range temporal dependence. Using daily returns of large U.S. equities, we find that MarketGAN more closely matches empirical stylized facts of asset returns, including heavy-tailed marginal distributions, volatility clustering, leverage effects, and, most notably, high-dimensional cross-sectional correlation structures and tail co-movement across assets, than conventional factor-model-based bootstrap approaches. In portfolio applications, covariance estimates derived from MarketGAN-generated samples outperform those derived from other methods when factor information is at least weakly informative, demonstrating tangible economic value.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 156,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17786",
        "abs_url": "https://arxiv.org/abs/2601.17786",
        "pdf_url": "https://arxiv.org/pdf/2601.17786",
        "title": "Beyond a Single Perspective: Text Anomaly Detection with Multi-View Language Representations",
        "authors": [
            "Yixin Liu",
            "Kehan Yan",
            "Shiyuan Li",
            "Qingfeng Chen",
            "Shirui Pan"
        ],
        "comments": "17 pages, 7 tables, and 5 figures",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Text anomaly detection (TAD) plays a critical role in various language-driven real-world applications, including harmful content moderation, phishing detection, and spam review filtering. While two-step \"embedding-detector\" TAD methods have shown state-of-the-art performance, their effectiveness is often limited by the use of a single embedding model and the lack of adaptability across diverse datasets and anomaly types. To address these limitations, we propose to exploit the embeddings from multiple pretrained language models and integrate them into $MCA^2$, a multi-view TAD framework. $MCA^2$ adopts a multi-view reconstruction model to effectively extract normal textual patterns from multiple embedding perspectives. To exploit inter-view complementarity, a contrastive collaboration module is designed to leverage and strengthen the interactions across different views. Moreover, an adaptive allocation module is developed to automatically assign the contribution weight of each view, thereby improving the adaptability to diverse datasets. Extensive experiments on 10 benchmark datasets verify the effectiveness of $MCA^2$ against strong baselines. The source code of $MCA^2$ is available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 157,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17800",
        "abs_url": "https://arxiv.org/abs/2601.17800",
        "pdf_url": "https://arxiv.org/pdf/2601.17800",
        "title": "Differentiable Integer Linear Programming is not Differentiable & it's not a mere technical problem",
        "authors": [
            "Thanawat Sornwanee"
        ],
        "comments": "",
        "subjects": "Optimization and Control (math.OC); Machine Learning (cs.LG)",
        "abstract": "We show how the differentiability method employed in the paper ``Differentiable Integer Linear Programming'', Geng, et al., 2025 as shown in its theorem 5 is incorrect. Moreover, there already exists some downstream work that inherits the same error. The underlying reason comes from that, though being continuous in expectation, the surrogate loss is discontinuous in almost every realization of the randomness, for the stochastic gradient descent.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 158,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17807",
        "abs_url": "https://arxiv.org/abs/2601.17807",
        "pdf_url": "https://arxiv.org/pdf/2601.17807",
        "title": "An autonomous living database for perovskite photovoltaics",
        "authors": [
            "Sherjeel Shabih",
            "Hampus Näsström",
            "Sharat Patil",
            "Asmin Askin",
            "Keely Dodd-Clements",
            "Jessica Helisa Hautrive Rossato",
            "Hugo Gajardoni de Lemos",
            "Yuxin Liu",
            "Florian Mathies",
            "Natalia Maticiuc",
            "Rico Meitzner",
            "Edgar Nandayapa",
            "Juan José Patiño López",
            "Yaru Wang",
            "Lauri Himanen",
            "Eva Unger",
            "T. Jesper Jacobsson",
            "José A. Márquez",
            "Kevin Maik Jablonka"
        ],
        "comments": "",
        "subjects": "Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)",
        "abstract": "Scientific discovery is severely bottlenecked by the inability of manual curation to keep pace with exponential publication rates. This creates a widening knowledge gap. This is especially stark in photovoltaics, where the leading database for perovskite solar cells has been stagnant since 2021 despite massive ongoing research output. Here, we resolve this challenge by establishing an autonomous, self-updating living database (PERLA). Our pipeline integrates large language models with physics-aware validation to extract complex device data from the continuous literature stream, achieving human-level precision (>90%) and eliminating annotator variance. By employing this system on the previously inaccessible post-2021 literature, we uncover critical evolutionary trends hidden by data lag: the field has decisively shifted toward inverted architectures employing self-assembled monolayers and formamidinium-rich compositions, driving a clear trajectory of sustained voltage loss reduction. PERLA transforms static publications into dynamic knowledge resources that enable data-driven discovery to operate at the speed of publication.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 159,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17869",
        "abs_url": "https://arxiv.org/abs/2601.17869",
        "pdf_url": "https://arxiv.org/pdf/2601.17869",
        "title": "On the Emergence and Test-Time Use of Structural Information in Large Language Models",
        "authors": [
            "Michelle Chao Chen",
            "Moritz Miller",
            "Bernhard Schölkopf",
            "Siyuan Guo"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Learning structural information from observational data is central to producing new knowledge outside the training corpus. This holds for mechanistic understanding in scientific discovery as well as flexible test-time compositional generation. We thus study how language models learn abstract structures and utilize the learnt structural information at test-time. To ensure a controlled setup, we design a natural language dataset based on linguistic structural transformations. We empirically show that the emergence of learning structural information correlates with complex reasoning tasks, and that the ability to perform test-time compositional generation remains limited.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 160,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17877",
        "abs_url": "https://arxiv.org/abs/2601.17877",
        "pdf_url": "https://arxiv.org/pdf/2601.17877",
        "title": "Comparative Algorithmic Governance of Public Health Instruments across India, EU, US and LMICs",
        "authors": [
            "Sahibpreet Singh"
        ],
        "comments": "Chapter in \"Law and Medicine\" (Pacific Books International, 2025), pp. 409-423",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "The study investigates the juridico-technological architecture of international public health instruments, focusing on their implementation across India, the European Union, the United States and low- and middle-income countries (LMICs), particularly in Sub-Saharan Africa. It addresses a research lacuna: the insufficient harmonisation between normative health law and algorithmic public health infrastructures in resource-constrained jurisdictions. The principal objective is to assess how artificial intelligence augments implementation of instruments grounded in IHR 2005 and the WHO FCTC while identifying doctrinal and infrastructural bottlenecks. Using comparative doctrinal analysis and legal-normative mapping, the study triangulates legislative instruments, WHO monitoring frameworks, AI systems including BlueDot, Aarogya Setu and EIOS, and compliance metrics. Preliminary results show that AI has improved early detection, surveillance precision and responsiveness in high-capacity jurisdictions, whereas LMICs face infrastructural deficits, data privacy gaps and fragmented legal scaffolding. The findings highlight the relevance of the EU Artificial Intelligence Act and GDPR as regulatory prototypes for health-oriented algorithmic governance and contrast them with embryonic AI integration and limited internet penetration in many LMICs. The study argues for embedding AI within a rights-compliant, supranationally coordinated regulatory framework to secure equitable health outcomes and stronger compliance. It proposes a model for algorithmic treaty-making inspired by FCTC architecture and calls for WHO-led compliance mechanisms modelled on the WTO Dispute Settlement Body to enhance pandemic preparedness, surveillance equity and transnational governance resilience.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 161,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17892",
        "abs_url": "https://arxiv.org/abs/2601.17892",
        "pdf_url": "https://arxiv.org/pdf/2601.17892",
        "title": "Artificial Intelligence and Intellectual Property Rights: Comparative Transnational Policy Analysis",
        "authors": [
            "Sahibpreet Singh",
            "Manjit Singh"
        ],
        "comments": "Published in Journal of University Institute of Legal Studies, Vol. 19, Issue 1, pp. 182-208, 2025",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Artificial intelligence's rapid integration with intellectual property rights necessitates assessment of its impact on trade secrets, copyrights and patents. This study addresses lacunae in existing laws where India lacks AI-specific provisions, creating doctrinal inconsistencies and enforcement inefficacies. Global discourse on AI-IPR protections remains nascent. The research identifies gaps in Indian IP laws' adaptability to AI-generated outputs: trade secret protection is inadequate against AI threats; standardized inventorship criteria are absent. Employing doctrinal and comparative methodology, it scrutinizes legislative texts, judicial precedents and policy instruments across India, US, UK and EU. Preliminary findings reveal shortcomings: India's contract law creates fragmented trade secret regime; Section 3(k) of Indian Patents Act blocks AI invention patenting; copyright varies in authorship attribution. The study proposes harmonized legal taxonomy accommodating AI's role while preserving innovation incentives. India's National AI Strategy (2024) shows progress but legislative clarity is imperative. This contributes to global discourse with AI-specific IP protections ensuring resilience and equitable innovation. Promising results underscore recalibrating India's IP jurisprudence for global alignment.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 162,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17907",
        "abs_url": "https://arxiv.org/abs/2601.17907",
        "pdf_url": "https://arxiv.org/pdf/2601.17907",
        "title": "FARM: Few-shot Adaptive Malware Family Classification under Concept Drift",
        "authors": [
            "Numan Halit Guldemir",
            "Oluwafemi Olukoya",
            "Jesús Martínez-del-Rincón"
        ],
        "comments": "This work has been submitted to the IEEE for possible publication",
        "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)",
        "abstract": "Malware classification models often face performance degradation due to concept drift, arising from evolving threat landscapes and the emergence of novel malware families. This paper presents FARM (Few-shot Adaptive Recognition of Malware), a framework designed to detect and adapt to both covariate and label drift in Windows Portable Executable (PE) malware classification. FARM leverages a triplet autoencoder to project samples into a discriminative latent space, enabling unsupervised drift detection via DBSCAN clustering and dynamic thresholding. For rapid adaptation, it employs few-shot learning using prototype-based classification, requiring only a handful of labeled samples. FARM also supports full retraining when enough drifted samples accumulate, updating the latent space for long-term integration. Experiments on the BenchMFC dataset demonstrate that FARM improves classification performance under covariate drift by 5.6\\%, and achieves an average F1 score of 0.85 on unseen malware families using only few-shot adaptation, which further increases to 0.94 after retraining. These results highlight FARM's robustness and adaptability in dynamic malware detection environments under limited supervision.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 163,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17973",
        "abs_url": "https://arxiv.org/abs/2601.17973",
        "pdf_url": "https://arxiv.org/pdf/2601.17973",
        "title": "Boosting methods for interval-censored data with regression and classification",
        "authors": [
            "Yuan Bian",
            "Grace Y. Yi",
            "Wenqing He"
        ],
        "comments": "In The 13th International Conference on Learning Representations (2025)",
        "subjects": "Machine Learning (stat.ML); Machine Learning (cs.LG)",
        "abstract": "Boosting has garnered significant interest across both machine learning and statistical communities. Traditional boosting algorithms, designed for fully observed random samples, often struggle with real-world problems, particularly with interval-censored data. This type of data is common in survival analysis and time-to-event studies where exact event times are unobserved but fall within known intervals. Effective handling of such data is crucial in fields like medical research, reliability engineering, and social sciences. In this work, we introduce novel nonparametric boosting methods for regression and classification tasks with interval-censored data. Our approaches leverage censoring unbiased transformations to adjust loss functions and impute transformed responses while maintaining model accuracy. Implemented via functional gradient descent, these methods ensure scalability and adaptability. We rigorously establish their theoretical properties, including optimality and mean squared error trade-offs. Our proposed methods not only offer a robust framework for enhancing predictive accuracy in domains where interval-censored data are common but also complement existing work, expanding the applicability of existing boosting techniques. Empirical studies demonstrate robust performance across various finite-sample scenarios, highlighting the practical utility of our approaches.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 164,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.17990",
        "abs_url": "https://arxiv.org/abs/2601.17990",
        "pdf_url": "https://arxiv.org/pdf/2601.17990",
        "title": "A Cherry-Picking Approach to Large Load Shaping for More Effective Carbon Reduction",
        "authors": [
            "Bokan Chen",
            "Raiden Hasegawa",
            "Adriaan Hilbers",
            "Ross Koningstein",
            "Ana Radovanović",
            "Utkarsh Shah",
            "Gabriela Volpato",
            "Mohamed Ahmed",
            "Tim Cary",
            "Rod Frowd"
        ],
        "comments": "",
        "subjects": "Machine Learning (stat.ML); Machine Learning (cs.LG); Systems and Control (eess.SY)",
        "abstract": "Shaping multi-megawatt loads, such as data centers, impacts generator dispatch on the electric grid, which in turn affects system CO2 emissions and energy cost. Substantiating the effectiveness of prevalent load shaping strategies, such as those based on grid-level average carbon intensity, locational marginal price, or marginal emissions, is challenging due to the lack of detailed counterfactual data required for accurate attribution. This study uses a series of calibrated granular ERCOT day-ahead direct current optimal power flow (DC-OPF) simulations for counterfactual analysis of a broad set of load shaping strategies on grid CO2 emissions and cost of electricity. In terms of annual grid level CO2 emissions reductions, LMP-based shaping outperforms other common strategies, but can be significantly improved upon. Examining the performance of practicable strategies under different grid conditions motivates a more effective load shaping approach: one that \"cherry-picks\" a daily strategy based on observable grid signals and historical data. The cherry-picking approach to power load shaping is applicable to any large flexible consumer on the electricity grid, such as data centers, distributed energy resources and Virtual Power Plants (VPPs).",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 165,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18005",
        "abs_url": "https://arxiv.org/abs/2601.18005",
        "pdf_url": "https://arxiv.org/pdf/2601.18005",
        "title": "Flow-based Extremal Mathematical Structure Discovery",
        "authors": [
            "Gergely Bérczi",
            "Baran Hashemi",
            "Jonas Klüver"
        ],
        "comments": "32 pages",
        "subjects": "Combinatorics (math.CO); Machine Learning (cs.LG)",
        "abstract": "The discovery of extremal structures in mathematics requires navigating vast and nonconvex landscapes where analytical methods offer little guidance and brute-force search becomes intractable. We introduce FlowBoost, a closed-loop generative framework that learns to discover rare and extremal geometric structures by combining three components: (i) a geometry-aware conditional flow-matching model that learns to sample high-quality configurations, (ii) reward-guided policy optimization with action exploration that directly optimizes the generation process toward the objective while maintaining diversity, and (iii) stochastic local search for both training-data generation and final refinement. Unlike prior open-loop approaches, such as PatternBoost that retrains on filtered discrete samples, or AlphaEvolve which relies on frozen Large Language Models (LLMs) as evolutionary mutation operators, FlowBoost enforces geometric feasibility during sampling, and propagates reward signal directly into the generative model, closing the optimization loop and requiring much smaller training sets and shorter training times, and reducing the required outer-loop iterations by orders of magnitude, while eliminating dependence on LLMs. We demonstrate the framework on four geometric optimization problems: sphere packing in hypercubes, circle packing maximizing sum of radii, the Heilbronn triangle problem, and star discrepancy minimization. In several cases, FlowBoost discovers configurations that match or exceed the best known results. For circle packings, we improve the best known lower bounds, surpassing the LLM-based system AlphaEvolve while using substantially fewer computational resources.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 166,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18007",
        "abs_url": "https://arxiv.org/abs/2601.18007",
        "pdf_url": "https://arxiv.org/pdf/2601.18007",
        "title": "Memory-Efficient FPGA Implementation of Stochastic Simulated Annealing",
        "authors": [
            "Duckgyu Shin",
            "Naoya Onizawa",
            "Warren J. Gross",
            "Takahiro Hanyu"
        ],
        "comments": "11 pages",
        "subjects": "Hardware Architecture (cs.AR); Machine Learning (cs.LG)",
        "abstract": "Simulated annealing (SA) is a well-known algorithm for solving combinatorial optimization problems. However, the computation time of SA increases rapidly, as the size of the problem grows. Recently, a stochastic simulated annealing (SSA) algorithm that converges faster than conventional SA has been reported. In this paper, we present a hardware-aware SSA (HA- SSA) algorithm for memory-efficient FPGA implementations. HA-SSA can reduce the memory usage of storing intermediate results while maintaining the computing speed of SSA. For evaluation purposes, the proposed algorithm is compared with the conventional SSA and SA approaches on maximum cut combinatorial optimization problems. HA-SSA achieves a convergence speed that is up to 114-times faster than that of the conventional SA algorithm depending on the maximum cut problem selected from the G-set which is a dataset of the maximum cut problems. HA-SSA is implemented on a field-programmable gate array (FPGA) (Xilinx Kintex-7), and it achieves up to 6-times the memory efficiency of conventional SSA while maintaining high solution quality for optimization problems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 167,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18021",
        "abs_url": "https://arxiv.org/abs/2601.18021",
        "pdf_url": "https://arxiv.org/pdf/2601.18021",
        "title": "MlPET: A Localized Neural Network Approach for Probabilistic Post-Reconstruction PET Image Analysis Using Informed Priors",
        "authors": [
            "Thomas Mejer Hansen",
            "Nana Christensen",
            "Mikkel Vendelbo"
        ],
        "comments": "",
        "subjects": "Medical Physics (physics.med-ph); Machine Learning (cs.LG)",
        "abstract": "We develop and evaluate MlPET, a fast localized machine learning approach for probabilistic PET image analysis addressing the noise-resolution trade-off in conventional reconstructions. MlPET replaces computationally demanding Markov chain Monte Carlo sampling with a localized neural network trained to estimate posterior mean voxel activity from small image neighborhoods. The method incorporates scanner-specific point spread functions, spatially correlated noise modeling, and flexible priors. Performance was evaluated on NEMA IEC phantom data from three PET systems (GE Discovery MI, Siemens Biograph Vision 600, and Quadra) under varying reconstruction settings and acquisition times. On phantom data, MlPET achieved contrast recovery coefficients consistently higher than standard PET and close to 1.0 (including 10 mm spheres), while reducing background noise and improving spatial definition. Effective pointspread function full width at half maximum decreased from approximately 2 mm in standard PET to below 1 mm with MlPET, a 2.5 fold reduction in blur. Comparable image quality was obtained at 40-80 s acquisition time with MlPET versus 900 s with conventional PET. MlPET provides an efficient approach for quantitative probabilistic post-reconstruction PET analysis. By combining informed priors with neural network speed, it achieves noise suppression and resolution enhancement without altering reconstruction algorithms. The method shows promise for improved small-lesion detectability and quantitative reliability in clinical PET imaging. Future studies will evaluate performance on patient data.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 168,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18047",
        "abs_url": "https://arxiv.org/abs/2601.18047",
        "pdf_url": "https://arxiv.org/pdf/2601.18047",
        "title": "Laser interferometry as a robust neuromorphic platform for machine learning",
        "authors": [
            "Amanuel Anteneh",
            "Kyungeun Kim",
            "J. M. Schwarz",
            "Israel Klich",
            "Olivier Pfister"
        ],
        "comments": "",
        "subjects": "Optics (physics.optics); Emerging Technologies (cs.ET); Machine Learning (cs.LG)",
        "abstract": "We present a method for implementing an optical neural network using only linear optical resources, namely field displacement and interferometry applied to coherent states of light. The nonlinearity required for learning in a neural network is realized via an encoding of the input into phase shifts allowing for far more straightforward experimental implementation compared to previous proposals for, and demonstrations of, $\\textit{in situ}$ inference. Beyond $\\textit{in situ}$ inference, the method enables $\\textit{in situ}$ training by utilizing established techniques like parameter shift rules or physical backpropagation to extract gradients directly from measurements of the linear optical circuit. We also investigate the effect of photon losses and find the model to be very resilient to these.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 169,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18053",
        "abs_url": "https://arxiv.org/abs/2601.18053",
        "pdf_url": "https://arxiv.org/pdf/2601.18053",
        "title": "Addressing LLM Diversity by Infusing Random Concepts",
        "authors": [
            "Pulin Agrawal",
            "Prasoon Goyal"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form \"Name 10 Hollywood actors\", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 170,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18068",
        "abs_url": "https://arxiv.org/abs/2601.18068",
        "pdf_url": "https://arxiv.org/pdf/2601.18068",
        "title": "XGuardian: Towards Explainable and Generalized AI Anti-Cheat on FPS Games",
        "authors": [
            "Jiayi Zhang",
            "Chenxin Sun",
            "Chenxiong Qian"
        ],
        "comments": "Accepted by USENIX Security 2026",
        "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)",
        "abstract": "Aim-assist cheats are the most prevalent and infamous form of cheating in First-Person Shooter (FPS) games, which help cheaters illegally reveal the opponent's location and auto-aim and shoot, and thereby pose significant threats to the game industry. Although a considerable research effort has been made to automatically detect aim-assist cheats, existing works suffer from unreliable frameworks, limited generalizability, high overhead, low detection performance, and a lack of explainability of detection results. In this paper, we propose XGuardian, a server-side generalized and explainable system for detecting aim-assist cheats to overcome these limitations. It requires only two raw data inputs, pitch and yaw, which are all FPS games' must-haves, to construct novel temporal features and describe aim trajectories, which are essential for distinguishing cheaters and normal players. XGuardian is evaluated with the latest mainstream FPS game CS2, and validates its generalizability with another two different games. It achieves high detection performance and low overhead compared to prior works across different games with real-world and large-scale datasets, demonstrating wide generalizability and high effectiveness. It is able to justify its predictions and thereby shorten the ban cycle. We make XGuardian as well as our datasets publicly available.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 171,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18080",
        "abs_url": "https://arxiv.org/abs/2601.18080",
        "pdf_url": "https://arxiv.org/pdf/2601.18080",
        "title": "Use of operator defect identities in multi-channel signal plus residual-analysis via iterated products and telescoping energy-residuals: Applications to kernels in machine learning",
        "authors": [
            "Palle E. T. Jorgensen",
            "Myung-Sin Song",
            "James F. Tian"
        ],
        "comments": "30 pages",
        "subjects": "Functional Analysis (math.FA); Machine Learning (cs.LG); Operator Algebras (math.OA)",
        "abstract": "We present a new operator theoretic framework for analysis of complex systems with intrinsic subdivisions into components, taking the form of \"residuals\" in general, and \"telescoping energy residuals\" in particular. We prove new results which yield admissibility/effectiveness, and new a priori bounds on energy residuals. Applications include infinite-dimensional Kaczmarz theory for $\\lambda_{n}$-relaxed variants, and $\\lambda_{n}$-effectiveness. And we give applications of our framework to generalized machine learning algorithms, greedy Kernel Principal Component Analysis (KPCA), proving explicit convergence results, residual energy decomposition, and criteria for stability under noise.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 172,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18128",
        "abs_url": "https://arxiv.org/abs/2601.18128",
        "pdf_url": "https://arxiv.org/pdf/2601.18128",
        "title": "Nonlinear multi-study factor analysis",
        "authors": [
            "Gemma E. Moran",
            "Anandi Krishnan"
        ],
        "comments": "",
        "subjects": "Machine Learning (stat.ML); Machine Learning (cs.LG)",
        "abstract": "High-dimensional data often exhibit variation that can be captured by lower dimensional factors. For high-dimensional data from multiple studies or environments, one goal is to understand which underlying factors are common to all studies, and which factors are study or environment-specific. As a particular example, we consider platelet gene expression data from patients in different disease groups. In this data, factors correspond to clusters of genes which are co-expressed; we may expect some clusters (or biological pathways) to be active for all diseases, while some clusters are only active for a specific disease. To learn these factors, we consider a nonlinear multi-study factor model, which allows for both shared and specific factors. To fit this model, we propose a multi-study sparse variational autoencoder. The underlying model is sparse in that each observed feature (i.e. each dimension of the data) depends on a small subset of the latent factors. In the genomics example, this means each gene is active in only a few biological processes. Further, the model implicitly induces a penalty on the number of latent factors, which helps separate the shared factors from the group-specific factors. We prove that the latent factors are identified, and demonstrate our method recovers meaningful factors in the platelet gene expression data.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 173,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18145",
        "abs_url": "https://arxiv.org/abs/2601.18145",
        "pdf_url": "https://arxiv.org/pdf/2601.18145",
        "title": "Exact Minimum-Volume Confidence Set Intersection for Multinomial Outcomes",
        "authors": [
            "Heguang Lin",
            "Binhao Chen",
            "Mengze Li",
            "Daniel Pimentel-Alarcón",
            "Matthew L. Malloy"
        ],
        "comments": "15 pages, 1 figure",
        "subjects": "Machine Learning (stat.ML); Machine Learning (cs.LG); Computation (stat.CO)",
        "abstract": "Computation of confidence sets is central to data science and machine learning, serving as the workhorse of A/B testing and underpinning the operation and analysis of reinforcement learning algorithms. Among all valid confidence sets for the multinomial parameter, minimum-volume confidence sets (MVCs) are optimal in that they minimize average volume, but they are defined as level sets of an exact p-value that is discontinuous and difficult to compute. Rather than attempting to characterize the geometry of MVCs directly, this paper studies a practically motivated decision problem: given two observed multinomial outcomes, can one certify whether their MVCs intersect? We present a certified, tolerance-aware algorithm for this intersection problem. The method exploits the fact that likelihood ordering induces halfspace constraints in log-odds coordinates, enabling adaptive geometric partitioning of parameter space and computable lower and upper bounds on p-values over each cell. For three categories, this yields an efficient and provably sound algorithm that either certifies intersection, certifies disjointness, or returns an indeterminate result when the decision lies within a prescribed margin. We further show how the approach extends to higher dimensions. The results demonstrate that, despite their irregular geometry, MVCs admit reliable certified decision procedures for core tasks in A/B testing.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 174,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18175",
        "abs_url": "https://arxiv.org/abs/2601.18175",
        "pdf_url": "https://arxiv.org/pdf/2601.18175",
        "title": "Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success",
        "authors": [
            "Daniel Russo"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY); Machine Learning (stat.ML)",
        "abstract": "A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $\\chi^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 175,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18219",
        "abs_url": "https://arxiv.org/abs/2601.18219",
        "pdf_url": "https://arxiv.org/pdf/2601.18219",
        "title": "Automated HER2 scoring with uncertainty quantification using lensfree holography and deep learning",
        "authors": [
            "Che-Yung Shen",
            "Xilin Yang",
            "Yuzhu Li",
            "Leon Lenk",
            "Aydogan Ozcan"
        ],
        "comments": "23 Pages, 6 Figures, 1 Table",
        "subjects": "Medical Physics (physics.med-ph); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
        "abstract": "Accurate assessment of human epidermal growth factor receptor 2 (HER2) expression is critical for breast cancer diagnosis, prognosis, and therapy selection; yet, most existing digital HER2 scoring methods rely on bulky and expensive optical systems. Here, we present a compact and cost-effective lensfree holography platform integrated with deep learning for automated HER2 scoring of immunohistochemically stained breast tissue sections. The system captures lensfree diffraction patterns of stained HER2 tissue sections under RGB laser illumination and acquires complex field information over a sample area of ~1,250 mm^2 at an effective throughput of ~84 mm^2 per minute. To enhance diagnostic reliability, we incorporated an uncertainty quantification strategy based on Bayesian Monte Carlo dropout, which provides autonomous uncertainty estimates for each prediction and supports reliable, robust HER2 scoring, with an overall correction rate of 30.4%. Using a blinded test set of 412 unique tissue samples, our approach achieved a testing accuracy of 84.9% for 4-class (0, 1+, 2+, 3+) HER2 classification and 94.8% for binary (0/1+ vs. 2+/3+) HER2 scoring with uncertainty quantification. Overall, this lensfree holography approach provides a practical pathway toward portable, high-throughput, and cost-effective HER2 scoring, particularly suited for resource-limited settings, where traditional digital pathology infrastructure is unavailable.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 176,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18238",
        "abs_url": "https://arxiv.org/abs/2601.18238",
        "pdf_url": "https://arxiv.org/pdf/2601.18238",
        "title": "TechING: Towards Real World Technical Image Understanding via VLMs",
        "authors": [
            "Tafazzul Nadeem",
            "Bhavik Shangari",
            "Manish Rai",
            "Gagan Raj Gupta",
            "Ashutosh Modi"
        ],
        "comments": "Accepted at Findings of EACL 2026, 30 Pages (9 Pages main paper + 4 pages references + 17 pages appendix)",
        "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
        "abstract": "Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 177,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18273",
        "abs_url": "https://arxiv.org/abs/2601.18273",
        "pdf_url": "https://arxiv.org/pdf/2601.18273",
        "title": "Toward Scalable Normalizing Flows for the Hubbard Model",
        "authors": [
            "Janik Kreit",
            "Andrea Bulgarelli",
            "Lena Funcke",
            "Thomas Luu",
            "Dominic Schuh",
            "Simran Singh",
            "Lorenzo Verzichelli"
        ],
        "comments": "10 pages, 5 figues, The 42nd International Symposium on Lattice Field Theory",
        "subjects": "Strongly Correlated Electrons (cond-mat.str-el); Machine Learning (cs.LG); High Energy Physics - Lattice (hep-lat)",
        "abstract": "Normalizing flows have recently demonstrated the ability to learn the Boltzmann distribution of the Hubbard model, opening new avenues for generative modeling in condensed matter physics. In this work, we investigate the steps required to extend such simulations to larger lattice sizes and lower temperatures, with a focus on enhancing stability and efficiency. Additionally, we present the scaling behavior of stochastic normalizing flows and non-equilibrium Markov chain Monte Carlo methods for this fermionic system.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 178,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18296",
        "abs_url": "https://arxiv.org/abs/2601.18296",
        "pdf_url": "https://arxiv.org/pdf/2601.18296",
        "title": "Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning",
        "authors": [
            "Zhaoyan Gong",
            "Zhiqiang Liu",
            "Songze Li",
            "Xiaoke Guo",
            "Yuanxiang Liu",
            "Xinle Deng",
            "Zhizhen Liu",
            "Lei Liang",
            "Huajun Chen",
            "Wen Zhang"
        ],
        "comments": "Work in progress",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 179,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18313",
        "abs_url": "https://arxiv.org/abs/2601.18313",
        "pdf_url": "https://arxiv.org/pdf/2601.18313",
        "title": "Convex Chance-Constrained Stochastic Control under Uncertain Specifications with Application to Learning-Based Hybrid Powertrain Control",
        "authors": [
            "Teruki Kato",
            "Ryotaro Shima",
            "Kenji Kashima"
        ],
        "comments": "Submitted to IEEE Transactions on Control Systems Technology (TCST)",
        "subjects": "Systems and Control (eess.SY); Machine Learning (cs.LG); Optimization and Control (math.OC)",
        "abstract": "This paper presents a strictly convex chance-constrained stochastic control framework that accounts for uncertainty in control specifications such as reference trajectories and operational constraints. By jointly optimizing control inputs and risk allocation under general (possibly non-Gaussian) uncertainties, the proposed method guarantees probabilistic constraint satisfaction while ensuring strict convexity, leading to uniqueness and continuity of the optimal solution. The formulation is further extended to nonlinear model-based control using exactly linearizable models identified through machine learning. The effectiveness of the proposed approach is demonstrated through model predictive control applied to a hybrid powertrain system.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 180,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18339",
        "abs_url": "https://arxiv.org/abs/2601.18339",
        "pdf_url": "https://arxiv.org/pdf/2601.18339",
        "title": "A Dataset for Automatic Vocal Mode Classification",
        "authors": [
            "Reemt Hinrichs",
            "Sonja Stephan",
            "Alexander Lange",
            "Jörn Ostermann"
        ],
        "comments": "Part of the proceedings of the EvoMUSART 2026: 15th International Conference on Artificial Intelligence in Music, Sound, Art and Design",
        "subjects": "Sound (cs.SD); Machine Learning (cs.LG)",
        "abstract": "The Complete Vocal Technique (CVT) is a school of singing developed in the past decades by Cathrin Sadolin et al.. CVT groups the use of the voice into so called vocal modes, namely Neutral, Curbing, Overdrive and Edge. Knowledge of the desired vocal mode can be helpful for singing students. Automatic classification of vocal modes can thus be important for technology-assisted singing teaching. Previously, automatic classification of vocal modes has been attempted without major success, potentially due to a lack of data. Therefore, we recorded a novel vocal mode dataset consisting of sustained vowels recorded from four singers, three of which professional singers with more than five years of CVT-experience. The dataset covers the entire vocal range of the subjects, totaling 3,752 unique samples. By using four microphones, thereby offering a natural data augmentation, the dataset consists of more than 13,000 samples combined. An annotation was created using three CVT-experienced annotators, each providing an individual annotation. The merged annotation as well as the three individual annotations come with the published dataset. Additionally, we provide some baseline classification results. The best balanced accuracy across a 5-fold cross validation of 81.3\\,\\% was achieved with a ResNet18. The dataset can be downloaded under this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 181,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18419",
        "abs_url": "https://arxiv.org/abs/2601.18419",
        "pdf_url": "https://arxiv.org/pdf/2601.18419",
        "title": "Emergent Cooperation in Quantum Multi-Agent Reinforcement Learning Using Communication",
        "authors": [
            "Michael Kölle",
            "Christian Reff",
            "Leo Sünkel",
            "Julian Hager",
            "Gerhard Stenzel",
            "Claudia Linnhoff-Popien"
        ],
        "comments": "Accepted at IEEE ICC 2026",
        "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)",
        "abstract": "Emergent cooperation in classical Multi-Agent Reinforcement Learning has gained significant attention, particularly in the context of Sequential Social Dilemmas (SSDs). While classical reinforcement learning approaches have demonstrated capability for emergent cooperation, research on extending these methods to Quantum Multi-Agent Reinforcement Learning remains limited, particularly through communication. In this paper, we apply communication approaches to quantum Q-Learning agents: the Mutual Acknowledgment Token Exchange (MATE) protocol, its extension Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange (MEDIATE), the peer rewarding mechanism Gifting, and Reinforced Inter-Agent Learning (RIAL). We evaluate these approaches in three SSDs: the Iterated Prisoner's Dilemma, Iterated Stag Hunt, and Iterated Game of Chicken. Our experimental results show that approaches using MATE with temporal-difference measure (MATE\\textsubscript{TD}), AutoMATE, MEDIATE-I, and MEDIATE-S achieved high cooperation levels across all dilemmas, demonstrating that communication is a viable mechanism for fostering emergent cooperation in Quantum Multi-Agent Reinforcement Learning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 182,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18424",
        "abs_url": "https://arxiv.org/abs/2601.18424",
        "pdf_url": "https://arxiv.org/pdf/2601.18424",
        "title": "Fusion of Spatio-Temporal and Multi-Scale Frequency Features for Dry Electrodes MI-EEG Decoding",
        "authors": [
            "Tianyi Gong",
            "Can Han",
            "Junxi Wu",
            "Dahong Qian"
        ],
        "comments": "",
        "subjects": "Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)",
        "abstract": "Dry-electrode Motor Imagery Electroencephalography (MI-EEG) enables fast, comfortable, real-world Brain Computer Interface by eliminating gels and shortening setup for at-home and wearable this http URL, dry recordings pose three main issues: lower Signal-to-Noise Ratio with more baseline drift and sudden transients; weaker and noisier data with poor phase alignment across trials; and bigger variances between sessions. These drawbacks lead to larger data distribution shift, making features less stable for MI-EEG this http URL address these problems, we introduce STGMFM, a tri-branch framework tailored for dry-electrode MI-EEG, which models complementary spatio-temporal dependencies via dual graph orders, and captures robust envelope dynamics with a multi-scale frequency mixing branch, motivated by the observation that amplitude envelopes are less sensitive to contact variability than instantaneous waveforms. Physiologically meaningful connectivity priors guide learning, and decision-level fusion consolidates a noise-tolerant consensus. On our collected dry-electrode MI-EEG, STGMFM consistently surpasses competitive CNN/Transformer/graph baselines. Codes are available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 183,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18451",
        "abs_url": "https://arxiv.org/abs/2601.18451",
        "pdf_url": "https://arxiv.org/pdf/2601.18451",
        "title": "3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control",
        "authors": [
            "Xuanmeng Sha",
            "Liyun Zhang",
            "Tomohiro Mashita",
            "Naoya Chiba",
            "Yuki Uranishi"
        ],
        "comments": "13 pages, 5 figures",
        "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD)",
        "abstract": "Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 184,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18491",
        "abs_url": "https://arxiv.org/abs/2601.18491",
        "pdf_url": "https://arxiv.org/pdf/2601.18491",
        "title": "AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security",
        "authors": [
            "Dongrui Liu",
            "Qihan Ren",
            "Chen Qian",
            "Shuai Shao",
            "Yuejin Xie",
            "Yu Li",
            "Zhonghao Yang",
            "Haoyu Luo",
            "Peng Wang",
            "Qingyu Liu",
            "Binxin Hu",
            "Ling Tang",
            "Jilin Mei",
            "Dadi Guo",
            "Leitao Yuan",
            "Junyao Yang",
            "Guanxu Chen",
            "Qihao Lin",
            "Yi Yu",
            "Bo Zhang",
            "Jiaxuan Guo",
            "Jie Zhang",
            "Wenqi Shao",
            "Huiqi Deng",
            "Zhiheng Xi",
            "Wenjie Wang",
            "Wenxuan Wang",
            "Wen Shen",
            "Zhikai Chen",
            "Haoyu Xie",
            "Jialing Tao",
            "Juntao Dai",
            "Jiaming Ji",
            "Zhongjie Ba",
            "Linfeng Zhang",
            "Yong Liu",
            "Quanshi Zhang",
            "Lei Zhu",
            "Zhihua Wei",
            "Hui Xue",
            "Chaochao Lu",
            "Jing Shao",
            "Xia Hu"
        ],
        "comments": "40 pages, 26 figures",
        "subjects": "Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
        "abstract": "The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 185,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18552",
        "abs_url": "https://arxiv.org/abs/2601.18552",
        "pdf_url": "https://arxiv.org/pdf/2601.18552",
        "title": "Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection",
        "authors": [
            "Devansh Srivastav",
            "David Pape",
            "Lea Schönherr"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 186,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18569",
        "abs_url": "https://arxiv.org/abs/2601.18569",
        "pdf_url": "https://arxiv.org/pdf/2601.18569",
        "title": "Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation",
        "authors": [
            "Seokju Lee",
            "Kyung-Soo Kim"
        ],
        "comments": "8 pages, 6 figures, Accepted to IEEE Robotics and Automation Letters (RA-L)",
        "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 187,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18588",
        "abs_url": "https://arxiv.org/abs/2601.18588",
        "pdf_url": "https://arxiv.org/pdf/2601.18588",
        "title": "Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs",
        "authors": [
            "Xianzhe Meng",
            "Qiangsheng Zeng",
            "Ling Luo",
            "Qinghan Yang",
            "Jiarui Hao",
            "Wenbo Wu",
            "Qinyu Wang",
            "Rui Yin",
            "Lin Qi",
            "Renzhi Lu"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 188,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18608",
        "abs_url": "https://arxiv.org/abs/2601.18608",
        "pdf_url": "https://arxiv.org/pdf/2601.18608",
        "title": "PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression",
        "authors": [
            "Fabian Fumagalli",
            "R. Teal Witter",
            "Christopher Musco"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets. In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent. Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 189,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18637",
        "abs_url": "https://arxiv.org/abs/2601.18637",
        "pdf_url": "https://arxiv.org/pdf/2601.18637",
        "title": "Universality of Many-body Projected Ensemble for Learning Quantum Data Distribution",
        "authors": [
            "Quoc Hoan Tran",
            "Koki Chinzei",
            "Yasuhiro Endo",
            "Hirotaka Oshima"
        ],
        "comments": "21 pages, 6 figures",
        "subjects": "Quantum Physics (quant-ph); Machine Learning (cs.LG); Machine Learning (stat.ML)",
        "abstract": "Generating quantum data by learning the underlying quantum distribution poses challenges in both theoretical and practical scenarios, yet it is a critical task for understanding quantum systems. A fundamental question in quantum machine learning (QML) is the universality of approximation: whether a parameterized QML model can approximate any quantum distribution. We address this question by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework, a method for quantum state design that uses a single many-body wave function to prepare random states. This demonstrates that MPE can approximate any distribution of pure states within a 1-Wasserstein distance error. This theorem provides a rigorous guarantee of universal expressivity, addressing key theoretical gaps in QML. For practicality, we propose an Incremental MPE variant with layer-wise training to improve the trainability. Numerical experiments on clustered quantum states and quantum chemistry datasets validate MPE's efficacy in learning complex quantum data distributions.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 190,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18663",
        "abs_url": "https://arxiv.org/abs/2601.18663",
        "pdf_url": "https://arxiv.org/pdf/2601.18663",
        "title": "Uniform Computability of PAC Learning",
        "authors": [
            "Vasco Brattka",
            "Guillaume Chirache"
        ],
        "comments": "",
        "subjects": "Logic (math.LO); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)",
        "abstract": "We study uniform computability properties of PAC learning using Weihrauch complexity. We focus on closed concept classes, which are either represented by positive, by negative or by full information. Among other results, we prove that proper PAC learning from positive information is equivalent to the limit operation on Baire space, whereas improper PAC learning from positive information is closely related to Weak Kőnig's Lemma and even equivalent to it, when we have some negative information about the admissible hypotheses. If arbitrary hypotheses are allowed, then improper PAC learning from positive information is still in a finitary DNC range, which implies that it is non-deterministically computable, but does not allow for probabilistic algorithms. These results can also be seen as a classification of the degree of constructivity of the Fundamental Theorem of Statistical Learning. All the aforementioned results hold if an upper bound of the VC dimension is provided as an additional input information. We also study the question of how these results are affected if the VC dimension is not given, but only promised to be finite or if concept classes are represented by negative or full information. Finally, we also classify the complexity of the VC dimension operation itself, which is a problem that is of independent interest. For positive or full information it turns out to be equivalent to the binary sorting problem, for negative information it is equivalent to the jump of sorting. This classification allows also conclusions regarding the Borel complexity of PAC learnability.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 191,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18677",
        "abs_url": "https://arxiv.org/abs/2601.18677",
        "pdf_url": "https://arxiv.org/pdf/2601.18677",
        "title": "Out-of-Distribution Radar Detection with Complex VAEs: Theory, Whitening, and ANMF Fusion",
        "authors": [
            "Yadang Alexis Rouzoumka",
            "Jean Pinsolle",
            "Eugénie Terreaux",
            "Christèle Morisseau",
            "Jean-Philippe Ovarlez",
            "Chengfang Ren"
        ],
        "comments": "13 pages, 12 figures, submitted to IEEE Transactions on Signal Processing",
        "subjects": "Machine Learning (stat.ML); Machine Learning (cs.LG)",
        "abstract": "We investigate the detection of weak complex-valued signals immersed in non-Gaussian, range-varying interference, with emphasis on maritime radar scenarios. The proposed methodology exploits a Complex-valued Variational AutoEncoder (CVAE) trained exclusively on clutter-plus-noise to perform Out-Of-Distribution detection. By operating directly on in-phase / quadrature samples, the CVAE preserves phase and Doppler structure and is assessed in two configurations: (i) using unprocessed range profiles and (ii) after local whitening, where per-range covariance estimates are obtained from neighboring profiles. Using extensive simulations together with real sea-clutter data from the CSIR maritime dataset, we benchmark performance against classical and adaptive detectors (MF, NMF, AMF-SCM, ANMF-SCM, ANMF-Tyler). In both configurations, the CVAE yields a higher detection probability Pd at matched false-alarm rate Pfa, with the most notable improvements observed under whitening. We further integrate the CVAE with the ANMF through a weighted log-p fusion rule at the decision level, attaining enhanced robustness in strongly non-Gaussian clutter and enabling empirically calibrated Pfa control under H0. Overall, the results demonstrate that statistical normalization combined with complex-valued generative modeling substantively improves detection in realistic sea-clutter conditions, and that the fused CVAE-ANMF scheme constitutes a competitive alternative to established model-based detectors.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 192,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18683",
        "abs_url": "https://arxiv.org/abs/2601.18683",
        "pdf_url": "https://arxiv.org/pdf/2601.18683",
        "title": "Learned harmonic mean estimation of the marginal likelihood for multimodal posteriors with flow matching",
        "authors": [
            "Alicja Polanska",
            "Jason D. McEwen"
        ],
        "comments": "Submitted to 44th International Workshop on Bayesian Inference and Maximum Entropy Methods in Science and Engineering",
        "subjects": "Methodology (stat.ME); Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)",
        "abstract": "The marginal likelihood, or Bayesian evidence, is a crucial quantity for Bayesian model comparison but its computation can be challenging for complex models, even in parameters space of moderate dimension. The learned harmonic mean estimator has been shown to provide accurate and robust estimates of the marginal likelihood simply using posterior samples. It is agnostic to the sampling strategy, meaning that the samples can be obtained using any method. This enables marginal likelihood calculation and model comparison with whatever sampling is most suitable for the task. However, the internal density estimators considered previously for the learned harmonic mean can struggle with highly multimodal posteriors. In this work we introduce flow matching-based continuous normalizing flows as a powerful architecture for the internal density estimation of the learned harmonic mean. We demonstrate the ability to handle challenging multimodal posteriors, including an example in 20 parameter dimensions, showcasing the method's ability to handle complex posteriors without the need for fine-tuning or heuristic modifications to the base distribution.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 193,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18685",
        "abs_url": "https://arxiv.org/abs/2601.18685",
        "pdf_url": "https://arxiv.org/pdf/2601.18685",
        "title": "LLAMA LIMA: A Living Meta-Analysis on the Effects of Generative AI on Learning Mathematics",
        "authors": [
            "Anselm Strohmaier",
            "Samira Bödefeld",
            "Frank Reinhold"
        ],
        "comments": "",
        "subjects": "History and Overview (math.HO); Machine Learning (cs.LG)",
        "abstract": "The capabilities of generative AI in mathematics education are rapidly evolving, posing significant challenges for research to keep pace. Research syntheses remain scarce and risk being outdated by the time of publication. To address this issue, we present a Living Meta-Analysis (LIMA) on the effects of generative AI-based interventions for learning mathematics. Following PRISMA-LSR guidelines, we continuously update the literature base, apply a Bayesian multilevel meta-regression model to account for cumulative data, and publish updated versions on a preprint server at regular intervals. This paper reports results from the first version, including 15 studies. The analyses indicate a small positive effect (g = 0.31) with a wide credible interval [0.06, 0.58], reflecting the still limited evidence base.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 194,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18704",
        "abs_url": "https://arxiv.org/abs/2601.18704",
        "pdf_url": "https://arxiv.org/pdf/2601.18704",
        "title": "Data-Driven Qubit Characterization and Optimal Control using Deep Learning",
        "authors": [
            "Paul Surrey",
            "Julian D. Teske",
            "Tobias Hangleiter",
            "Hendrik Bluhm",
            "Pascal Cerfontaine"
        ],
        "comments": "",
        "subjects": "Quantum Physics (quant-ph); Machine Learning (cs.LG)",
        "abstract": "Quantum computing requires the optimization of control pulses to achieve high-fidelity quantum gates. We propose a machine learning-based protocol to address the challenges of evaluating gradients and modeling complex system dynamics. By training a recurrent neural network (RNN) to predict qubit behavior, our approach enables efficient gradient-based pulse optimization without the need for a detailed system model. First, we sample qubit dynamics using random control pulses with weak prior assumptions. We then train the RNN on the system's observed responses, and use the trained model to optimize high-fidelity control pulses. We demonstrate the effectiveness of this approach through simulations on a single $ST_0$ qubit.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 195,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18710",
        "abs_url": "https://arxiv.org/abs/2601.18710",
        "pdf_url": "https://arxiv.org/pdf/2601.18710",
        "title": "Analyzing Images of Blood Cells with Quantum Machine Learning Methods: Equilibrium Propagation and Variational Quantum Circuits to Detect Acute Myeloid Leukemia",
        "authors": [
            "A. Bano",
            "L. Liebovitch"
        ],
        "comments": "5 pages, 1 figure, 2 tables",
        "subjects": "Emerging Technologies (cs.ET); Machine Learning (cs.LG); Quantum Physics (quant-ph)",
        "abstract": "This paper presents a feasibility study demonstrating that quantum machine learning (QML) algorithms achieve competitive performance on real-world medical imaging despite operating under severe constraints. We evaluate Equilibrium Propagation (EP), an energy-based learning method that does not use backpropagation (incompatible with quantum systems due to state-collapsing measurements) and Variational Quantum Circuits (VQCs) for automated detection of Acute Myeloid Leukemia (AML) from blood cell microscopy images using binary classification (2 classes: AML vs. Healthy). Key Result: Using limited subsets (50-250 samples per class) of the AML-Cytomorphology dataset (18,365 expert-annotated images), quantum methods achieve performance only 12-15% below classical CNNs despite reduced image resolution (64x64 pixels), engineered features (20D), and classical simulation via Qiskit. EP reaches 86.4% accuracy (only 12% below CNN) without backpropagation, while the 4-qubit VQC attains 83.0% accuracy with consistent data efficiency: VQC maintains stable 83% performance with only 50 samples per class, whereas CNN requires 250 samples (5x more data) to reach 98%. These results establish reproducible baselines for QML in healthcare, validating NISQ-era feasibility.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 196,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18722",
        "abs_url": "https://arxiv.org/abs/2601.18722",
        "pdf_url": "https://arxiv.org/pdf/2601.18722",
        "title": "Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning",
        "authors": [
            "Lintang Sutawika",
            "Gokul Swamy",
            "Zhiwei Steven Wu",
            "Graham Neubig"
        ],
        "comments": "Code available at this https URL",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \\texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \\textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \\textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \\texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than of the training data across the single-language, multilingual, and generalization to unseen language settings.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 197,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18730",
        "abs_url": "https://arxiv.org/abs/2601.18730",
        "pdf_url": "https://arxiv.org/pdf/2601.18730",
        "title": "Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale",
        "authors": [
            "Henry Bell",
            "Caroline Zhang",
            "Mohammed Mobasserul Haque",
            "Dhaval Potdar",
            "Samia Zaman",
            "Brandon Fain"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \\textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \\textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \\textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \\textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \\textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \\textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 198,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18744",
        "abs_url": "https://arxiv.org/abs/2601.18744",
        "pdf_url": "https://arxiv.org/pdf/2601.18744",
        "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models",
        "authors": [
            "Fangxu Yu",
            "Xingang Guo",
            "Lingzhi Yuan",
            "Haoqiang Kang",
            "Hongyu Zhao",
            "Lianhui Qin",
            "Furong Huang",
            "Bin Hu",
            "Tianyi Zhou"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 199,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18766",
        "abs_url": "https://arxiv.org/abs/2601.18766",
        "pdf_url": "https://arxiv.org/pdf/2601.18766",
        "title": "Learning to Discover: A Generalized Framework for Raga Identification without Forgetting",
        "authors": [
            "Parampreet Singh",
            "Somya Kumar",
            "Chaitanya Shailendra Nitawe",
            "Vipul Arora"
        ],
        "comments": "Accepted at NCC 2026 conference",
        "subjects": "Audio and Speech Processing (eess.AS); Machine Learning (cs.LG)",
        "abstract": "Raga identification in Indian Art Music (IAM) remains challenging due to the presence of numerous rarely performed Ragas that are not represented in available training datasets. Traditional classification models struggle in this setting, as they assume a closed set of known categories and therefore fail to recognise or meaningfully group previously unseen Ragas. Recent works have tried categorizing unseen Ragas, but they run into a problem of catastrophic forgetting, where the knowledge of previously seen Ragas is diminished. To address this problem, we adopt a unified learning framework that leverages both labeled and unlabeled audio, enabling the model to discover coherent categories corresponding to the unseen Ragas, while retaining the knowledge of previously known ones. We test our model on benchmark Raga Identification datasets and demonstrate its performance in categorizing previously seen, unseen, and all Raga classes. The proposed approach surpasses the previous NCD-based pipeline even in discovering the unseen Raga categories, offering new insights into representation learning for IAM tasks.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 200,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18788",
        "abs_url": "https://arxiv.org/abs/2601.18788",
        "pdf_url": "https://arxiv.org/pdf/2601.18788",
        "title": "Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings",
        "authors": [
            "Mumin Jia",
            "Jairo Diaz-Rodriguez"
        ],
        "comments": "arXiv admin note: substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)",
        "abstract": "Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 201,
        "date": "2026-01-27",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-27?abs=True",
        "arxiv_id": "2601.18792",
        "abs_url": "https://arxiv.org/abs/2601.18792",
        "pdf_url": "https://arxiv.org/pdf/2601.18792",
        "title": "MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data",
        "authors": [
            "Brian Liu",
            "Oiwi Parker Jones"
        ],
        "comments": "",
        "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.",
        "gemini2.5flash": "",
        "overall_idea": ""
    }
]