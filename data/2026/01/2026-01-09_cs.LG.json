[
    {
        "order": 1,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04250",
        "abs_url": "https://arxiv.org/abs/2601.04250",
        "pdf_url": "https://arxiv.org/pdf/2601.04250",
        "title": "Green MLOps: Closed-Loop, Energy-Aware Inference with NVIDIA Triton, FastAPI, and Bio-Inspired Thresholding",
        "authors": [
            "Mustapha Hamdi",
            "Mourad Jabou"
        ],
        "comments": "6 pages, 4 figures. Code available at:this https URL",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Energy efficiency is a first-order concern in AI deployment, as long-running inference can exceed training in cumulative carbon impact. We propose a bio-inspired framework that maps protein-folding energy basins to inference cost landscapes and controls execution via a decaying, closed-loop threshold. A request is admitted only when the expected utility-to-energy trade-off is favorable (high confidence/utility at low marginal energy and congestion), biasing operation toward the first acceptable local basin rather than pursuing costly global minima. We evaluate DistilBERT and ResNet-18 served through FastAPI with ONNX Runtime and NVIDIA Triton on an RTX 4000 Ada GPU. Our ablation study reveals that the bio-controller reduces processing time by 42% compared to standard open-loop execution (0.50s vs 0.29s on A100 test set), with a minimal accuracy degradation (<0.5%). Furthermore, we establish the efficiency boundaries between lightweight local serving (ORT) and managed batching (Triton). The results connect biophysical energy models to Green MLOps and offer a practical, auditable basis for closed-loop energy-aware inference in production.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 2,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04263",
        "abs_url": "https://arxiv.org/abs/2601.04263",
        "pdf_url": "https://arxiv.org/pdf/2601.04263",
        "title": "Learning to Reason: Temporal Saliency Distillation for Interpretable Knowledge Transfer",
        "authors": [
            "Nilushika Udayangani Hewa Dehigahawattage",
            "Kishor Nandakishor",
            "Marimuthu Palaniswami"
        ],
        "comments": "In Proceedings of the 27th European Conference on Artificial Intelligence (ECAI 2025), IOS Press",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Knowledge distillation has proven effective for model compression by transferring knowledge from a larger network called the teacher to a smaller network called the student. Current knowledge distillation in time series is predominantly based on logit and feature aligning techniques originally developed for computer vision tasks. These methods do not explicitly account for temporal data and fall short in two key aspects. First, the mechanisms by which the transferred knowledge helps the student model learning process remain unclear due to uninterpretability of logits and features. Second, these methods transfer only limited knowledge, primarily replicating the teacher predictive accuracy. As a result, student models often produce predictive distributions that differ significantly from those of their teachers, hindering their safe substitution for teacher models. In this work, we propose transferring interpretable knowledge by extending conventional logit transfer to convey not just the right prediction but also the right reasoning of the teacher. Specifically, we induce other useful knowledge from the teacher logits termed temporal saliency which captures the importance of each input timestep to the teacher prediction. By training the student with Temporal Saliency Distillation we encourage it to make predictions based on the same input features as the teacher. Temporal Saliency Distillation requires no additional parameters or architecture specific assumptions. We demonstrate that Temporal Saliency Distillation effectively improves the performance of baseline methods while also achieving desirable properties beyond predictive accuracy. We hope our work establishes a new paradigm for interpretable knowledge distillation in time series analysis.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 3,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04264",
        "abs_url": "https://arxiv.org/abs/2601.04264",
        "pdf_url": "https://arxiv.org/pdf/2601.04264",
        "title": "MemKD: Memory-Discrepancy Knowledge Distillation for Efficient Time Series Classification",
        "authors": [
            "Nilushika Udayangani",
            "Kishor Nandakishor",
            "Marimuthu Palaniswami"
        ],
        "comments": "In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2025), Hyderabad, India",
        "subjects": "Machine Learning (cs.LG); Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Deep learning models, particularly recurrent neural networks and their variants, such as long short-term memory, have significantly advanced time series data analysis. These models capture complex, sequential patterns in time series, enabling real-time assessments. However, their high computational complexity and large model sizes pose challenges for deployment in resource-constrained environments, such as wearable devices and edge computing platforms. Knowledge Distillation (KD) offers a solution by transferring knowledge from a large, complex model (teacher) to a smaller, more efficient model (student), thereby retaining high performance while reducing computational demands. Current KD methods, originally designed for computer vision tasks, neglect the unique temporal dependencies and memory retention characteristics of time series models. To this end, we propose a novel KD framework termed Memory-Discrepancy Knowledge Distillation (MemKD). MemKD leverages a specialized loss function to capture memory retention discrepancies between the teacher and student models across subsequences within time series data, ensuring that the student model effectively mimics the teacher model's behaviour. This approach facilitates the development of compact, high-performing recurrent neural networks suitable for real-time, time series analysis tasks. Our extensive experiments demonstrate that MemKD significantly outperforms state-of-the-art KD methods. It reduces parameter size and memory usage by approximately 500 times while maintaining comparable performance to the teacher model.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 4,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04268",
        "abs_url": "https://arxiv.org/abs/2601.04268",
        "pdf_url": "https://arxiv.org/pdf/2601.04268",
        "title": "Making Tunable Parameters State-Dependent in Weather and Climate Models with Reinforcement Learning",
        "authors": [
            "Pritthijit Nath",
            "Sebastian Schemm",
            "Henry Moss",
            "Peter Haynes",
            "Emily Shuckburgh",
            "Mark J. Webb"
        ],
        "comments": "66 pages, 22 figures",
        "subjects": "Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)",
        "abstract": "Weather and climate models rely on parametrisations to represent unresolved sub-grid processes. Traditional schemes rely on fixed coefficients that are weakly constrained and tuned offline, contributing to persistent biases that limit their ability to adapt to the underlying physics. This study presents a framework that learns components of parametrisation schemes online as a function of the evolving model state using reinforcement learning (RL) and evaluates the resulting RL-driven parameter updates across a hierarchy of idealised testbeds spanning a simple climate bias correction (SCBC), a radiative-convective equilibrium (RCE), and a zonal mean energy balance model (EBM) with both single-agent and federated multi-agent settings. Across nine RL algorithms, Truncated Quantile Critics (TQC), Deep Deterministic Policy Gradient (DDPG), and Twin Delayed DDPG (TD3) achieved the highest skill and the most stable convergence across configurations, with performance assessed against a static baseline using area-weighted RMSE, temperature profile and pressure-level diagnostics. For the EBM, single-agent RL outperformed static parameter tuning with the strongest gains in tropical and mid-latitude bands, while federated RL on multi-agent setups enabled geographically specialised control and faster convergence, with a six-agent DDPG configuration using frequent aggregation yielding the lowest area-weighted RMSE across the tropics and mid-latitudes. The learnt corrections were also physically meaningful as agents modulated EBM radiative parameters to reduce meridional biases, adjusted RCE lapse rates to match vertical temperature errors, and stabilised SCBC heating increments to limit drift. Overall, results highlight RL to deliver skilful state-dependent, and regime-aware parametrisations, offering a scalable pathway for online learning within numerical models.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 5,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04270",
        "abs_url": "https://arxiv.org/abs/2601.04270",
        "pdf_url": "https://arxiv.org/pdf/2601.04270",
        "title": "Predictable Gradient Manifolds in Deep Learning: Temporal Path-Length and Intrinsic Rank as a Complexity Regime",
        "authors": [
            "Anherutowa Calvo"
        ],
        "comments": "12 Pages. Preprint",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Deep learning optimization exhibits structure that is not captured by worst-case gradient bounds. Empirically, gradients along training trajectories are often temporally predictable and evolve within a low-dimensional subspace. In this work we formalize this observation through a measurable framework for predictable gradient manifolds. We introduce two computable quantities: a prediction-based path length that measures how well gradients can be forecast from past information, and a predictable rank that quantifies the intrinsic temporal dimension of gradient increments. We show how classical online and nonconvex optimization guarantees can be restated so that convergence and regret depend explicitly on these quantities, rather than on worst-case variation. Across convolutional networks, vision transformers, language models, and synthetic control tasks, we find that gradient trajectories are locally predictable and exhibit strong low-rank structure over time. These properties are stable across architectures and optimizers, and can be diagnosed directly from logged gradients using lightweight random projections. Our results provide a unifying lens for understanding optimization dynamics in modern deep learning, reframing standard training as operating in a low-complexity temporal regime. This perspective suggests new directions for adaptive optimizers, rank-aware tracking, and prediction-based algorithm design grounded in measurable properties of real training runs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 6,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04277",
        "abs_url": "https://arxiv.org/abs/2601.04277",
        "pdf_url": "https://arxiv.org/pdf/2601.04277",
        "title": "Unlocking the Pre-Trained Model as a Dual-Alignment Calibrator for Post-Trained LLMs",
        "authors": [
            "Beier Luo",
            "Cheng Wang",
            "Hongxin Wei",
            "Sharon Li",
            "Xuefeng Du"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Post-training improves large language models (LLMs) but often worsens confidence calibration, leading to systematic overconfidence. Recent unsupervised post-hoc methods for post-trained LMs (PoLMs) mitigate this by aligning PoLM confidence to that of well-calibrated pre-trained counterparts. However, framing calibration as static output-distribution matching overlooks the inference-time dynamics introduced by post-training. In particular, we show that calibration errors arise from two regimes: (i) confidence drift, where final confidence inflates despite largely consistent intermediate decision processes, and (ii) process drift, where intermediate inference pathways diverge. Guided by this diagnosis, we propose Dual-Align, an unsupervised post-hoc framework for dual alignment in confidence calibration. Dual-Align performs confidence alignment to correct confidence drift via final-distribution matching, and introduces process alignment to address process drift by locating the layer where trajectories diverge and realigning the stability of subsequent inference. This dual strategy learns a single temperature parameter that corrects both drift types without sacrificing post-training performance gains. Experiments show consistent improvements over baselines, reducing calibration errors and approaching a supervised oracle.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 7,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04279",
        "abs_url": "https://arxiv.org/abs/2601.04279",
        "pdf_url": "https://arxiv.org/pdf/2601.04279",
        "title": "Generation of synthetic delay time series for air transport applications",
        "authors": [
            "Pau Esteve",
            "Massimiliano Zanin"
        ],
        "comments": "18 pages, 13 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The generation of synthetic data is receiving increasing attention from the scientific community, thanks to its ability to solve problems like data scarcity and privacy, and is starting to find applications in air transport. We here tackle the problem of generating synthetic, yet realistic, time series of delays at airports, starting from large collections of operations in Europe and the US. We specifically compare three models, two of them based on state of the art Deep Learning algorithms, and one simplified Genetic Algorithm approach. We show how the latter can generate time series that are almost indistinguishable from real ones, while maintaining a high variability. We further validate the resulting time series in a problem of detecting delay propagations between airports. We finally make the synthetic data available to the scientific community.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 8,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04282",
        "abs_url": "https://arxiv.org/abs/2601.04282",
        "pdf_url": "https://arxiv.org/pdf/2601.04282",
        "title": "LEGATO: Good Identity Unlearning Is Continuous",
        "authors": [
            "Qiang Chen",
            "Chun-Wun Cheng",
            "Xiu Su",
            "Hongyan Xu",
            "Xi Lin",
            "Shan You",
            "Angelica I. Aviles-Rivero",
            "Yi Chen"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Machine unlearning has become a crucial role in enabling generative models trained on large datasets to remove sensitive, private, or copyright-protected data. However, existing machine unlearning methods face three challenges in learning to forget identity of generative models: 1) inefficient, where identity erasure requires fine-tuning all the model's parameters; 2) limited controllability, where forgetting intensity cannot be controlled and explainability is lacking; 3) catastrophic collapse, where the model's retention capability undergoes drastic degradation as forgetting progresses. Forgetting has typically been handled through discrete and unstable updates, often requiring full-model fine-tuning and leading to catastrophic collapse. In this work, we argue that identity forgetting should be modeled as a continuous trajectory, and introduce LEGATO - Learn to ForgEt Identity in GenerAtive Models via Trajectory-consistent Neural Ordinary Differential Equations. LEGATO augments pre-trained generators with fine-tunable lightweight Neural ODE adapters, enabling smooth, controllable forgetting while keeping the original model weights frozen. This formulation allows forgetting intensity to be precisely modulated via ODE step size, offering interpretability and robustness. To further ensure stability, we introduce trajectory consistency constraints that explicitly prevent catastrophic collapse during unlearning. Extensive experiments across in-domain and out-of-domain identity unlearning benchmarks show that LEGATO achieves state-of-the-art forgetting performance, avoids catastrophic collapse and reduces fine-tuned parameters.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 9,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04283",
        "abs_url": "https://arxiv.org/abs/2601.04283",
        "pdf_url": "https://arxiv.org/pdf/2601.04283",
        "title": "Mitigating Position-Shift Failures in Text-Based Modular Arithmetic via Position Curriculum and Template Diversity",
        "authors": [
            "Nikolay Yudin"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "Building on insights from the grokking literature, we study character-level Transformers trained to compute modular addition from text, and focus on robustness under input-format variation rather than only in-distribution accuracy. We identify a previously under-emphasized failure mode: models that achieve high in-distribution accuracy can fail catastrophically when the same expression is shifted to different absolute character positions (\"position shift\") or presented under out-of-distribution natural-language templates. Using a disjoint-pair split over all ordered pairs for p=97, we show that a baseline model reaches strong in-distribution performance yet collapses under position shift and template OOD. We then introduce a simple training recipe that combines (i) explicit expression boundary markers, (ii) position curriculum that broadens the range of absolute positions seen during training, (iii) diverse template mixtures, and (iv) consistency training across multiple variants per example. Across three seeds, this intervention substantially improves robustness to position shift and template OOD while maintaining high in-distribution accuracy, whereas an ALiBi-style ablation fails to learn the task under our setup. Our results suggest that steering procedural generalization under noisy supervision benefits from explicitly training invariances that are otherwise absent from the data distribution, and we provide a reproducible evaluation protocol and artifacts.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 10,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04286",
        "abs_url": "https://arxiv.org/abs/2601.04286",
        "pdf_url": "https://arxiv.org/pdf/2601.04286",
        "title": "Enhancing Robustness of Asynchronous EEG-Based Movement Prediction using Classifier Ensembles",
        "authors": [
            "Niklas Kueper",
            "Kartik Chari",
            "Elsa Andrea Kirchner"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Objective: Stroke is one of the leading causes of disabilities. One promising approach is to extend the rehabilitation with self-initiated robot-assisted movement therapy. To enable this, it is required to detect the patient's intention to move to trigger the assistance of a robotic device. This intention to move can be detected from human surface electroencephalography (EEG) signals; however, it is particularly challenging to decode when classifications are performed online and asynchronously. In this work, the effectiveness of classifier ensembles and a sliding-window postprocessing technique was investigated to enhance the robustness of such asynchronous classification. Approach: To investigate the effectiveness of classifier ensembles and a sliding-window postprocessing, two EEG datasets with 14 healthy subjects who performed self-initiated arm movements were analyzed. Offline and pseudo-online evaluations were conducted to compare ensemble combinations of the support vector machine (SVM), multilayer perceptron (MLP), and EEGNet classification models. Results: The results of the pseudo-online evaluation show that the two model ensembles significantly outperformed the best single model for the optimal number of postprocessing windows. In particular, for single models, an increased number of postprocessing windows significantly improved classification performances. Interestingly, we found no significant improvements between performances of the best single model and classifier ensembles in the offline evaluation. Significance: We demonstrated that classifier ensembles and appropriate postprocessing methods effectively enhance the asynchronous detection of movement intentions from EEG signals. In particular, the classifier ensemble approach yields greater improvements in online classification than in offline classification, and reduces false detections, i.e., early false positives.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 11,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04297",
        "abs_url": "https://arxiv.org/abs/2601.04297",
        "pdf_url": "https://arxiv.org/pdf/2601.04297",
        "title": "ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues",
        "authors": [
            "Behrad Binaei-Haghighi",
            "Nafiseh Sadat Sajadi",
            "Mehrad Liviyan",
            "Reyhane Akhavan Kharazi",
            "Fatemeh Amirkhani",
            "Behnam Bahrak"
        ],
        "comments": "12 pages, 7 figures",
        "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)",
        "abstract": "The objective assessment of human affective and psychological states presents a significant challenge, particularly through non-verbal channels. This paper introduces digital drawing as a rich and underexplored modality for affective sensing. We present a novel multimodal framework, named ArtCognition, for the automated analysis of the House-Tree-Person (HTP) test, a widely used psychological instrument. ArtCognition uniquely fuses two distinct data streams: static visual features from the final artwork, captured by computer vision models, and dynamic behavioral kinematic cues derived from the drawing process itself, such as stroke speed, pauses, and smoothness. To bridge the gap between low-level features and high-level psychological interpretation, we employ a Retrieval-Augmented Generation (RAG) architecture. This grounds the analysis in established psychological knowledge, enhancing explainability and reducing the potential for model hallucination. Our results demonstrate that the fusion of visual and behavioral kinematic cues provides a more nuanced assessment than either modality alone. We show significant correlations between the extracted multimodal features and standardized psychological metrics, validating the framework's potential as a scalable tool to support clinicians. This work contributes a new methodology for non-intrusive affective state assessment and opens new avenues for technology-assisted mental healthcare.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 12,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04299",
        "abs_url": "https://arxiv.org/abs/2601.04299",
        "pdf_url": "https://arxiv.org/pdf/2601.04299",
        "title": "Transformer-Based Multi-Modal Temporal Embeddings for Explainable Metabolic Phenotyping in Type 1 Diabetes",
        "authors": [
            "Pir Bakhsh Khokhar",
            "Carmine Gravino",
            "Fabio Palomba",
            "Sule Yildrim Yayilgan",
            "Sarang Shaikh"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)",
        "abstract": "Type 1 diabetes (T1D) is a highly metabolically heterogeneous disease that cannot be adequately characterized by conventional biomarkers such as glycated hemoglobin (HbA1c). This study proposes an explainable deep learning framework that integrates continuous glucose monitoring (CGM) data with laboratory profiles to learn multimodal temporal embeddings of individual metabolic status. Temporal dependencies across modalities are modeled using a transformer encoder, while latent metabolic phenotypes are identified via Gaussian mixture modeling. Model interpretability is achieved through transformer attention visualization and SHAP-based feature attribution. Five latent metabolic phenotypes, ranging from metabolic stability to elevated cardiometabolic risk, were identified among 577 individuals with T1D. These phenotypes exhibit distinct biochemical profiles, including differences in glycemic control, lipid metabolism, renal markers, and thyrotropin (TSH) levels. Attention analysis highlights glucose variability as a dominant temporal factor, while SHAP analysis identifies HbA1c, triglycerides, cholesterol, creatinine, and TSH as key contributors to phenotype differentiation. Phenotype membership shows statistically significant, albeit modest, associations with hypertension, myocardial infarction, and heart failure. Overall, this explainable multimodal temporal embedding framework reveals physiologically coherent metabolic subgroups in T1D and supports risk stratification beyond single biomarkers.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 13,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04301",
        "abs_url": "https://arxiv.org/abs/2601.04301",
        "pdf_url": "https://arxiv.org/pdf/2601.04301",
        "title": "Quantifying the Effect of Test Set Contamination on Generative Evaluations",
        "authors": [
            "Rylan Schaeffer",
            "Joshua Kazdan",
            "Baber Abbasi",
            "Ken Ziyu Liu",
            "Brando Miranda",
            "Ahmed Ahmed",
            "Abhay Puri",
            "Niloofar Mireshghallah",
            "Sanmi Koyejo"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "As frontier AI systems are pretrained on web-scale data, test set contamination has become a critical concern for accurately assessing their capabilities. While research has thoroughly investigated the impact of test set contamination on discriminative evaluations like multiple-choice question-answering, comparatively little research has studied the impact of test set contamination on generative evaluations. In this work, we quantitatively assess the effect of test set contamination on generative evaluations through the language model lifecycle. We pretrain language models on mixtures of web data and the MATH benchmark, sweeping model sizes and number of test set replicas contaminating the pretraining corpus; performance improves with contamination and model size. Using scaling laws, we make a surprising discovery: including even a single test set replica enables models to achieve lower loss than the irreducible error of training on the uncontaminated corpus. We then study further training: overtraining with fresh data reduces the effects of contamination, whereas supervised finetuning on the training set can either increase or decrease performance on test data, depending on the amount of pretraining contamination. Finally, at inference, we identify factors that modulate memorization: high sampling temperatures mitigate contamination effects, and longer solutions are exponentially more difficult to memorize than shorter ones, presenting a contrast with discriminative evaluations, where solutions are only a few tokens in length. By characterizing how generation and memorization interact, we highlight a new layer of complexity for trustworthy evaluation of AI systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 14,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04361",
        "abs_url": "https://arxiv.org/abs/2601.04361",
        "pdf_url": "https://arxiv.org/pdf/2601.04361",
        "title": "Causally-Aware Information Bottleneck for Domain Adaptation",
        "authors": [
            "Mohammad Ali Javidian"
        ],
        "comments": "An extended abstract version of this work was accepted for the Proceedings of the 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "We tackle a common domain adaptation setting in causal systems. In this setting, the target variable is observed in the source domain but is entirely missing in the target domain. We aim to impute the target variable in the target domain from the remaining observed variables under various shifts. We frame this as learning a compact, mechanism-stable representation. This representation preserves information relevant for predicting the target while discarding spurious variation. For linear Gaussian causal models, we derive a closed-form Gaussian Information Bottleneck (GIB) solution. This solution reduces to a canonical correlation analysis (CCA)-style projection and offers Directed Acyclic Graph (DAG)-aware options when desired. For nonlinear or non-Gaussian data, we introduce a Variational Information Bottleneck (VIB) encoder-predictor. This approach scales to high dimensions and can be trained on source data and deployed zero-shot to the target domain. Across synthetic and real datasets, our approach consistently attains accurate imputations, supporting practical use in high-dimensional causal models and furnishing a unified, lightweight toolkit for causal domain adaptation.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 15,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04362",
        "abs_url": "https://arxiv.org/abs/2601.04362",
        "pdf_url": "https://arxiv.org/pdf/2601.04362",
        "title": "Phasor Agents: Oscillatory Graphs with Three-Factor Plasticity and Sleep-Staged Learning",
        "authors": [
            "Rodja Trappe"
        ],
        "comments": "22 pages, 14 figures",
        "subjects": "Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Neurons and Cognition (q-bio.NC)",
        "abstract": "Phasor Agents are dynamical systems whose internal state is a Phasor Graph: a weighted graph of coupled Stuart-Landau oscillators. A Stuart-Landau oscillator is a minimal stable \"rhythm generator\" (the normal form near a Hopf bifurcation); each oscillator is treated as an abstract computational unit (inspired by, but not claiming to model, biological oscillatory populations). In this interpretation, oscillator phase tracks relative timing (coherence), while amplitude tracks local gain or activity. Relative phase structure serves as a representational medium; coupling weights are learned via three-factor local plasticity - eligibility traces gated by sparse global modulators and oscillation-timed write windows - without backpropagation. A central challenge in oscillatory substrates is stability: online weight updates can drive the network into unwanted regimes (e.g., global synchrony), collapsing representational diversity. We therefore separate wake tagging from offline consolidation, inspired by synaptic tagging-and-capture and sleep-stage dynamics: deep-sleep-like gated capture commits tagged changes safely, while REM-like replay reconstructs and perturbs experience for planning. A staged experiment suite validates each mechanism with ablations and falsifiers: eligibility traces preserve credit under delayed modulation; compression-progress signals pass timestamp-shuffle controls; phase-coherent retrieval reaches 4x diffusive baselines under noise; wake/sleep separation expands stable learning by 67 percent under matched weight-norm budgets; REM replay improves maze success rate by +45.5 percentage points; and a Tolman-style latent-learning signature - immediate competence and detour advantage after unrewarded exploration, consistent with an internal model - emerges from replay (Tolman, 1948). The codebase and all artifacts are open-source.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 16,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04365",
        "abs_url": "https://arxiv.org/abs/2601.04365",
        "pdf_url": "https://arxiv.org/pdf/2601.04365",
        "title": "Survival Dynamics of Neural and Programmatic Policies in Evolutionary Reinforcement Learning",
        "authors": [
            "Anton Roupassov-Ruiz",
            "Yiyang Zuo"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In evolutionary reinforcement learning tasks (ERL), agent policies are often encoded as small artificial neural networks (NERL). Such representations lack explicit modular structure, limiting behavioral interpretation. We investigate whether programmatic policies (PERL), implemented as soft, differentiable decision lists (SDDL), can match the performance of NERL. To support reproducible evaluation, we provide the first fully specified and open-source reimplementation of the classic 1992 Artificial Life (ALife) ERL testbed. We conduct a rigorous survival analysis across 4000 independent trials utilizing Kaplan-Meier curves and Restricted Mean Survival Time (RMST) metrics absent in the original study. We find a statistically significant difference in survival probability between PERL and NERL. PERL agents survive on average 201.69 steps longer than NERL agents. Moreover, SDDL agents using learning alone (no evolution) survive on average 73.67 steps longer than neural agents using both learning and evaluation. These results demonstrate that programmatic policies can exceed the survival performance of neural policies in ALife.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 17,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04366",
        "abs_url": "https://arxiv.org/abs/2601.04366",
        "pdf_url": "https://arxiv.org/pdf/2601.04366",
        "title": "Machine Learning Model for Sparse PCM Completion",
        "authors": [
            "Selcuk Koyuncu",
            "Ronak Nouri",
            "Stephen Providence"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Optimization and Control (math.OC)",
        "abstract": "In this paper, we propose a machine learning model for sparse pairwise comparison matrices (PCMs), combining classical PCM approaches with graph-based learning techniques. Numerical results are provided to demonstrate the effectiveness and scalability of the proposed method.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 18,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04392",
        "abs_url": "https://arxiv.org/abs/2601.04392",
        "pdf_url": "https://arxiv.org/pdf/2601.04392",
        "title": "Enhanced-FQL($Î»$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay",
        "authors": [
            "Mohsen Jalaeian-Farimani"
        ],
        "comments": "Submitted to ECC26 conference",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY); Optimization and Control (math.OC)",
        "abstract": "This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($\\lambda$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach employs an interpretable fuzzy rule base instead of complex neural architectures, while maintaining competitive performance through two key innovations: a fuzzified Bellman equation with eligibility traces for stable multi-step credit assignment, and a memory-efficient segment-based experience replay mechanism for enhanced sample efficiency. Theoretical analysis proves the proposed method convergence under standard assumptions. Extensive evaluations in continuous control domains demonstrate that Enhanced-FQL($\\lambda$) achieves superior sample efficiency and reduced variance compared to n-step fuzzy TD and fuzzy SARSA($\\lambda$) baselines, while maintaining substantially lower computational complexity than deep RL alternatives such as DDPG. The framework's inherent interpretability, combined with its computational efficiency and theoretical convergence guarantees, makes it particularly suitable for safety-critical applications where transparency and resource constraints are essential.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 19,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04413",
        "abs_url": "https://arxiv.org/abs/2601.04413",
        "pdf_url": "https://arxiv.org/pdf/2601.04413",
        "title": "Distribution-Guided and Constrained Quantum Machine Unlearning",
        "authors": [
            "Nausherwan Malik",
            "Zubair Khalid",
            "Muhammad Faryad"
        ],
        "comments": "8 pages",
        "subjects": "Machine Learning (cs.LG); Quantum Physics (quant-ph)",
        "abstract": "Machine unlearning aims to remove the influence of specific training data from a learned model without full retraining. While recent work has begun to explore unlearning in quantum machine learning, existing approaches largely rely on fixed, uniform target distributions and do not explicitly control the trade-off between forgetting and retained model behaviour. In this work, we propose a distribution-guided framework for class-level quantum machine unlearning that treats unlearning as a constrained optimization problem. Our method introduces a tunable target distribution derived from model similarity statistics, decoupling the suppression of forgotten-class confidence from assumptions about redistribution among retained classes. We further incorporate an anchor-based preservation constraint that explicitly maintains predictive behaviour on selected retained data, yielding a controlled optimization trajectory that limits deviation from the original model. We evaluate the approach on variational quantum classifiers trained on the Iris and Covertype datasets. Results demonstrate sharp suppression of forgotten-class confidence, minimal degradation of retained-class performance, and closer alignment with the gold retrained model baselines compared to uniform-target unlearning. These findings highlight the importance of target design and constraint-based formulations for reliable and interpretable quantum machine unlearning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 20,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04441",
        "abs_url": "https://arxiv.org/abs/2601.04441",
        "pdf_url": "https://arxiv.org/pdf/2601.04441",
        "title": "Improving and Accelerating Offline RL in Large Discrete Action Spaces with Structured Policy Initialization",
        "authors": [
            "Matthew Landers",
            "Taylor W. Killian",
            "Thomas Hartvigsen",
            "Afsaneh Doryab"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Reinforcement learning in discrete combinatorial action spaces requires searching over exponentially many joint actions to simultaneously select multiple sub-actions that form coherent combinations. Existing approaches either simplify policy learning by assuming independence across sub-actions, which often yields incoherent or invalid actions, or attempt to learn action structure and control jointly, which is slow and unstable. We introduce Structured Policy Initialization (SPIN), a two-stage framework that first pre-trains an Action Structure Model (ASM) to capture the manifold of valid actions, then freezes this representation and trains lightweight policy heads for control. On challenging discrete DM Control benchmarks, SPIN improves average return by up to 39% over the state of the art while reducing time to convergence by up to 12.8$\\times$.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 21,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04447",
        "abs_url": "https://arxiv.org/abs/2601.04447",
        "pdf_url": "https://arxiv.org/pdf/2601.04447",
        "title": "When Predictions Shape Reality: A Socio-Technical Synthesis of Performative Predictions in Machine Learning",
        "authors": [
            "Gal Fybish",
            "Teo Susnjak"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Machine learning models are increasingly used in high-stakes domains where their predictions can actively shape the environments in which they operate, a phenomenon known as performative prediction. This dynamic, in which the deployment of the model influences the very outcome it seeks to predict, can lead to unintended consequences, including feedback loops, performance issues, and significant societal risks. While the literature in the field has grown rapidly in recent years, a socio-technical synthesis that systemises the phenomenon concepts and provides practical guidance has been lacking. This Systematisation of Knowledge (SoK) addresses this gap by providing a comprehensive review of the literature on performative predictions. We provide an overview of the primary mechanisms through which performativity manifests, present a typology of associated risks, and survey the proposed solutions offered in the literature. Our primary contribution is the ``Performative Strength vs. Impact Matrix\" assessment framework. This practical tool is designed to help practitioners assess the potential influence and severity of performativity on their deployed predictive models and select the appropriate level of algorithmic or human intervention.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 22,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04449",
        "abs_url": "https://arxiv.org/abs/2601.04449",
        "pdf_url": "https://arxiv.org/pdf/2601.04449",
        "title": "Explainable Admission-Level Predictive Modeling for Prolonged Hospital Stay in Elderly Populations: Challenges in Low- and Middle-Income Countries",
        "authors": [
            "Daniel Sierra-Botero",
            "Ana Molina-Taborda",
            "Leonardo Espinosa-Leal",
            "Alexander Karpenko",
            "Alejandro Hernandez",
            "Olga Lopez-Acevedo"
        ],
        "comments": "23 pages, 6 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Prolonged length of stay (pLoS) is a significant factor associated with the risk of adverse in-hospital events. We develop and explain a predictive model for pLos using admission-level patient and hospital administrative data. The approach includes a feature selection method by selecting non-correlated features with the highest information value. The method uses features weights of evidence to select a representative within cliques from graph theory. The prognosis study analyzed the records from 120,354 hospital admissions at the Hospital Alma Mater de Antioquia between January 2017 and March 2022. After a cleaning process the dataset was split into training (67%), test (22%), and validation (11%) cohorts. A logistic regression model was trained to predict the pLoS in two classes: less than or greater than 7 days. The performance of the model was evaluated using accuracy, precision, sensitivity, specificity, and AUC-ROC metrics. The feature selection method returns nine interpretable variables, enhancing the models' transparency. In the validation cohort, the pLoS model achieved a specificity of 0.83 (95% CI, 0.82-0.84), sensitivity of 0.64 (95% CI, 0.62-0.65), accuracy of 0.76 (95% CI, 0.76-0.77), precision of 0.67 (95% CI, 0.66-0.69), and AUC-ROC of 0.82 (95% CI, 0.81-0.83). The model exhibits strong predictive performance and offers insights into the factors that influence prolonged hospital stays. This makes it a valuable tool for hospital management and for developing future intervention studies aimed at reducing pLoS.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 23,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04458",
        "abs_url": "https://arxiv.org/abs/2601.04458",
        "pdf_url": "https://arxiv.org/pdf/2601.04458",
        "title": "Using Large Language Models to Detect Socially Shared Regulation of Collaborative Learning",
        "authors": [
            "Jiayi Zhang",
            "Conrad Borchers",
            "Clayton Cohn",
            "Namrata Srivastava",
            "Caitlin Snyder",
            "Siyuan Guo",
            "Ashwin T S",
            "Naveeduddin Mohammed",
            "Haley Noh",
            "Gautam Biswas"
        ],
        "comments": "Short research paper accepted at Learning Analytics and Knowledge (LAK '26)",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "The field of learning analytics has made notable strides in automating the detection of complex learning processes in multimodal data. However, most advancements have focused on individualized problem-solving instead of collaborative, open-ended problem-solving, which may offer both affordances (richer data) and challenges (low cohesion) to behavioral prediction. Here, we extend predictive models to automatically detect socially shared regulation of learning (SSRL) behaviors in collaborative computational modeling environments using embedding-based approaches. We leverage large language models (LLMs) as summarization tools to generate task-aware representations of student dialogue aligned with system logs. These summaries, combined with text-only embeddings, context-enriched embeddings, and log-derived features, were used to train predictive models. Results show that text-only embeddings often achieve stronger performance in detecting SSRL behaviors related to enactment or group dynamics (e.g., off-task behavior or requesting assistance). In contrast, contextual and multimodal features provide complementary benefits for constructs such as planning and reflection. Overall, our findings highlight the promise of embedding-based models for extending learning analytics by enabling scalable detection of SSRL behaviors, ultimately supporting real-time feedback and adaptive scaffolding in collaborative learning environments that teachers value.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 24,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04462",
        "abs_url": "https://arxiv.org/abs/2601.04462",
        "pdf_url": "https://arxiv.org/pdf/2601.04462",
        "title": "Meta-probabilistic Modeling",
        "authors": [
            "Kevin Zhang",
            "Yixin Wang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "While probabilistic graphical models can discover latent structure in data, their effectiveness hinges on choosing well-specified models. Identifying such models is challenging in practice, often requiring iterative checking and revision through trial and error. To this end, we propose meta-probabilistic modeling (MPM), a meta-learning algorithm that learns generative model structure directly from multiple related datasets. MPM uses a hierarchical architecture where global model specifications are shared across datasets while local parameters remain dataset-specific. For learning and inference, we propose a tractable VAE-inspired surrogate objective, and optimize it through bi-level optimization: local variables are updated analytically via coordinate ascent, while global parameters are trained with gradient-based methods. We evaluate MPM on object-centric image modeling and sequential text modeling, demonstrating that it adapts generative models to data while recovering meaningful latent representations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 25,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04480",
        "abs_url": "https://arxiv.org/abs/2601.04480",
        "pdf_url": "https://arxiv.org/pdf/2601.04480",
        "title": "When Models Manipulate Manifolds: The Geometry of a Counting Task",
        "authors": [
            "Wes Gurnee",
            "Emmanuel Ameisen",
            "Isaac Kauvar",
            "Julius Tarng",
            "Adam Pearce",
            "Chris Olah",
            "Joshua Batson"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Language models can perceive visual properties of text despite receiving only sequences of tokens-we mechanistically investigate how Claude 3.5 Haiku accomplishes one such task: linebreaking in fixed-width text. We find that character counts are represented on low-dimensional curved manifolds discretized by sparse feature families, analogous to biological place cells. Accurate predictions emerge from a sequence of geometric transformations: token lengths are accumulated into character count manifolds, attention heads twist these manifolds to estimate distance to the line boundary, and the decision to break the line is enabled by arranging estimates orthogonally to create a linear decision boundary. We validate our findings through causal interventions and discover visual illusions--character sequences that hijack the counting mechanism. Our work demonstrates the rich sensory processing of early layers, the intricacy of attention algorithms, and the importance of combining feature-based and geometric views of interpretability.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 26,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04498",
        "abs_url": "https://arxiv.org/abs/2601.04498",
        "pdf_url": "https://arxiv.org/pdf/2601.04498",
        "title": "IGenBench: Benchmarking the Reliability of Text-to-Infographic Generation",
        "authors": [
            "Yinghao Tang",
            "Xueding Liu",
            "Boyuan Zhang",
            "Tingfeng Lan",
            "Yupeng Xie",
            "Jiale Lao",
            "Yiyao Wang",
            "Haoxuan Li",
            "Tingting Gao",
            "Bo Pan",
            "Luoxuan Weng",
            "Xiuqi Huang",
            "Minfeng Zhu",
            "Yingchaojie Feng",
            "Yuyu Luo",
            "Wei Chen"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Infographics are composite visual artifacts that combine data visualizations with textual and illustrative elements to communicate information. While recent text-to-image (T2I) models can generate aesthetically appealing images, their reliability in generating infographics remains unclear. Generated infographics may appear correct at first glance but contain easily overlooked issues, such as distorted data encoding or incorrect textual content. We present IGENBENCH, the first benchmark for evaluating the reliability of text-to-infographic generation, comprising 600 curated test cases spanning 30 infographic types. We design an automated evaluation framework that decomposes reliability verification into atomic yes/no questions based on a taxonomy of 10 question types. We employ multimodal large language models (MLLMs) to verify each question, yielding question-level accuracy (Q-ACC) and infographic-level accuracy (I-ACC). We comprehensively evaluate 10 state-of-the-art T2I models on IGENBENCH. Our systematic analysis reveals key insights for future model development: (i) a three-tier performance hierarchy with the top model achieving Q-ACC of 0.90 but I-ACC of only 0.49; (ii) data-related dimensions emerging as universal bottlenecks (e.g., Data Completeness: 0.21); and (iii) the challenge of achieving end-to-end correctness across all models. We release IGENBENCH at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 27,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04506",
        "abs_url": "https://arxiv.org/abs/2601.04506",
        "pdf_url": "https://arxiv.org/pdf/2601.04506",
        "title": "Surface-based Molecular Design with Multi-modal Flow Matching",
        "authors": [
            "Fang Wu",
            "Zhengyuan Zhou",
            "Shuting Jin",
            "Xiangxiang Zeng",
            "Jure Leskovec",
            "Jinbo Xu"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)",
        "abstract": "Therapeutic peptides show promise in targeting previously undruggable binding sites, with recent advancements in deep generative models enabling full-atom peptide co-design for specific protein receptors. However, the critical role of molecular surfaces in protein-protein interactions (PPIs) has been underexplored. To bridge this gap, we propose an omni-design peptides generation paradigm, called SurfFlow, a novel surface-based generative algorithm that enables comprehensive co-design of sequence, structure, and surface for peptides. SurfFlow employs a multi-modality conditional flow matching (CFM) architecture to learn distributions of surface geometries and biochemical properties, enhancing peptide binding accuracy. Evaluated on the comprehensive PepMerge benchmark, SurfFlow consistently outperforms full-atom baselines across all metrics. These results highlight the advantages of considering molecular surfaces in de novo peptide discovery and demonstrate the potential of integrating multiple protein modalities for more effective therapeutic peptide discovery.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 28,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04521",
        "abs_url": "https://arxiv.org/abs/2601.04521",
        "pdf_url": "https://arxiv.org/pdf/2601.04521",
        "title": "TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation",
        "authors": [
            "Jacob Ede Levine",
            "Yun Lyan Luo",
            "Sai Chandra Kosaraju"
        ],
        "comments": "Under Review",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical language models that generate molecules as SMILES strings are vulnerable to compounding token errors: many samples are unparseable or chemically implausible, and hard constraints meant to prevent failure can restrict exploration. To address this gap, we introduce TSSR, a Two-Stage, Swap-Reward-driven reinforcement learning (RL) framework for character-level SMILES generation. Stage one rewards local token swaps that repair syntax, promoting transitions from invalid to parseable strings. Stage two provides chemistry-aware feedback from RDKit diagnostics, rewarding reductions in valence, aromaticity, and connectivity issues. The reward decomposes into interpretable terms (swap efficiency, error reduction, distance to validity), is model agnostic, and requires no task-specific labels or hand-crafted grammars. We evaluated TSSR on the MOSES benchmark using a GRU policy trained with PPO in both pure RL (P-RL) from random initialization and fine-tuning RL (F-RL) starting from a pretrained chemical language model, assessing 10,000 generated SMILES per run. In P-RL, TSSR significantly improves syntactic validity, chemical validity, and novelty. In F-RL, TSSR preserves drug-likeness and synthesizability while increasing validity and novelty. Token-level analysis shows that syntax edits and chemistry fixes act jointly to reduce RDKit detected errors. TSSR converts a sparse terminal objective into a denser and more interpretable reward, improving both syntactic and chemical quality without reducing diversity. TSSR is dataset-agnostic and can be adapted to various reinforcement learning approaches.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 29,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04537",
        "abs_url": "https://arxiv.org/abs/2601.04537",
        "pdf_url": "https://arxiv.org/pdf/2601.04537",
        "title": "Not All Steps are Informative: On the Linearity of LLMs' RLVR Training",
        "authors": [
            "Tianle Wang",
            "Zhongyuan Wu",
            "Shenghao Jin",
            "Hao Xu",
            "Wei Chen",
            "Ning Miao"
        ],
        "comments": "pre-print",
        "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)",
        "abstract": "Reinforcement learning with verifiable rewards (RLVR) has become a central component of large language model (LLM) post-training. Unlike supervised fine-tuning (SFT), RLVR lets an LLM generate multiple candidate solutions and reinforces those that lead to a verifiably correct final answer. However, in practice, RLVR often requires thousands of training steps to reach strong performance, incurring substantial computation largely attributed to prolonged exploration. In this work, we make a surprising observation: during RLVR, LLMs evolve in a strongly linear manner. Specifically, both model weights and model output log-probabilities exhibit strong linear correlations with RL training steps. This suggests that RLVR predominantly amplifies trends that emerge early in training, rather than continuously discovering new behaviors throughout the entire optimization trajectory. Motivated by this linearity, we investigate whether future model states can be predicted from intermediate checkpoints via extrapolation, avoiding continued expensive training. We show that Weight Extrapolation produces models with performance comparable to standard RL training while requiring significantly less computation. Moreover, Logits Extrapolation consistently outperforms continued RL training on all four benchmarks by extrapolating beyond the step range where RL training remains stable.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 30,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04542",
        "abs_url": "https://arxiv.org/abs/2601.04542",
        "pdf_url": "https://arxiv.org/pdf/2601.04542",
        "title": "Timeliness-Oriented Scheduling and Resource Allocation in Multi-Region Collaborative Perception",
        "authors": [
            "Mengmeng Zhu",
            "Yuxuan Sun",
            "Yukuan Jia",
            "Wei Chen",
            "Bo Ai",
            "Sheng Zhou"
        ],
        "comments": "This work has been submitted to the IEEE for possible publication",
        "subjects": "Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC)",
        "abstract": "Collaborative perception (CP) is a critical technology in applications like autonomous driving and smart cities. It involves the sharing and fusion of information among sensors to overcome the limitations of individual perception, such as blind spots and range limitations. However, CP faces two primary challenges. First, due to the dynamic nature of the environment, the timeliness of the transmitted information is critical to perception performance. Second, with limited computational power at the sensors and constrained wireless bandwidth, the communication volume must be carefully designed to ensure feature representations are both effective and sufficient. This work studies the dynamic scheduling problem in a multi-region CP scenario, and presents a Timeliness-Aware Multi-region Prioritized (TAMP) scheduling algorithm to trade-off perception accuracy and communication resource usage. Timeliness reflects the utility of information that decays as time elapses, which is manifested by the perception performance in CP tasks. We propose an empirical penalty function that maps the joint impact of Age of Information (AoI) and communication volume to perception performance. Aiming to minimize this timeliness-oriented penalty in the long-term, and recognizing that scheduling decisions have a cumulative effect on subsequent system states, we propose the TAMP scheduling algorithm. TAMP is a Lyapunov-based optimization policy that decomposes the long-term average objective into a per-slot prioritization problem, balancing the scheduling worth against resource cost. We validate our algorithm in both intersection and corridor scenarios with the real-world Roadside Cooperative perception (RCooper) dataset. Extensive simulations demonstrate that TAMP outperforms the best-performing baseline, achieving an Average Precision (AP) improvement of up to 27% across various configurations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 31,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04550",
        "abs_url": "https://arxiv.org/abs/2601.04550",
        "pdf_url": "https://arxiv.org/pdf/2601.04550",
        "title": "GEnSHIN: Graphical Enhanced Spatio-temporal Hierarchical Inference Network for Traffic Flow Prediction",
        "authors": [
            "Zhiyan Zhou",
            "Junjie Liao",
            "Manho Zhang",
            "Yingyi Liao",
            "Ziai Wang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "With the acceleration of urbanization, intelligent transportation systems have an increasing demand for accurate traffic flow prediction. This paper proposes a novel Graph Enhanced Spatio-temporal Hierarchical Inference Network (GEnSHIN) to handle the complex spatio-temporal dependencies in traffic flow prediction. The model integrates three innovative designs: 1) An attention-enhanced Graph Convolutional Recurrent Unit (GCRU), which strengthens the modeling capability for long-term temporal dependencies by introducing Transformer modules; 2) An asymmetric dual-embedding graph generation mechanism, which leverages the real road network and data-driven latent asymmetric topology to generate graph structures that better fit the characteristics of actual traffic flow; 3) A dynamic memory bank module, which utilizes learnable traffic pattern prototypes to provide personalized traffic pattern representations for each sensor node, and introduces a lightweight graph updater during the decoding phase to adapt to dynamic changes in road network states. Extensive experiments on the public dataset METR-LA show that GEnSHIN achieves or surpasses the performance of comparative models across multiple metrics such as Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE). Notably, the model demonstrates excellent prediction stability during peak morning and evening traffic hours. Ablation experiments further validate the effectiveness of each core module and its contribution to the final performance.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 32,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04563",
        "abs_url": "https://arxiv.org/abs/2601.04563",
        "pdf_url": "https://arxiv.org/pdf/2601.04563",
        "title": "A Vision for Multisensory Intelligence: Sensing, Synergy, and Science",
        "authors": [
            "Paul Pu Liang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)",
        "abstract": "Our experience of the world is multisensory, spanning a synthesis of language, sight, sound, touch, taste, and smell. Yet, artificial intelligence has primarily advanced in digital modalities like text, vision, and audio. This paper outlines a research vision for multisensory artificial intelligence over the next decade. This new set of technologies can change how humans and AI experience and interact with one another, by connecting AI to the human senses and a rich spectrum of signals from physiological and tactile cues on the body, to physical and social signals in homes, cities, and the environment. We outline how this field must advance through three interrelated themes of sensing, science, and synergy. Firstly, research in sensing should extend how AI captures the world in richer ways beyond the digital medium. Secondly, developing a principled science for quantifying multimodal heterogeneity and interactions, developing unified modeling architectures and representations, and understanding cross-modal transfer. Finally, we present new technical challenges to learn synergy between modalities and between humans and AI, covering multisensory integration, alignment, reasoning, generation, generalization, and experience. Accompanying this vision paper are a series of projects, resources, and demos of latest advances from the Multisensory Intelligence group at the MIT Media Lab, see this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 33,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04572",
        "abs_url": "https://arxiv.org/abs/2601.04572",
        "pdf_url": "https://arxiv.org/pdf/2601.04572",
        "title": "Spatial-Temporal Feedback Diffusion Guidance for Controlled Traffic Imputation",
        "authors": [
            "Xiaowei Mao",
            "Huihu Ding",
            "Yan Lin",
            "Tingrui Wu",
            "Shengnan Guo",
            "Dazhuo Qiu",
            "Feiling Fang",
            "Jilin Hu",
            "Huaiyu Wan"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Imputing missing values in spatial-temporal traffic data is essential for intelligent transportation systems. Among advanced imputation methods, score-based diffusion models have demonstrated competitive performance. These models generate data by reversing a noising process, using observed values as conditional guidance. However, existing diffusion models typically apply a uniform guidance scale across both spatial and temporal dimensions, which is inadequate for nodes with high missing data rates. Sparse observations provide insufficient conditional guidance, causing the generative process to drift toward the learned prior distribution rather than closely following the conditional observations, resulting in suboptimal imputation performance. To address this, we propose FENCE, a spatial-temporal feedback diffusion guidance method designed to adaptively control guidance scales during imputation. First, FENCE introduces a dynamic feedback mechanism that adjusts the guidance scale based on the posterior likelihood approximations. The guidance scale is increased when generated values diverge from observations and reduced when alignment improves, preventing overcorrection. Second, because alignment to observations varies across nodes and denoising steps, a global guidance scale for all nodes is suboptimal. FENCE computes guidance scales at the cluster level by grouping nodes based on their attention scores, leveraging spatial-temporal correlations to provide more accurate guidance. Experimental results on real-world traffic datasets show that FENCE significantly enhances imputation accuracy.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 34,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04592",
        "abs_url": "https://arxiv.org/abs/2601.04592",
        "pdf_url": "https://arxiv.org/pdf/2601.04592",
        "title": "Density Matrix RNN (DM-RNN): A Quantum Information Theoretic Framework for Modeling Musical Context and Polyphony",
        "authors": [
            "Joonwon Seo",
            "Mariana Montiel"
        ],
        "comments": "Submitted to the 10th International Conference on Mathematics and Computation in Music (MCM 2026)",
        "subjects": "Machine Learning (cs.LG); Sound (cs.SD); Mathematical Physics (math-ph)",
        "abstract": "Classical Recurrent Neural Networks (RNNs) summarize musical context into a deterministic hidden state vector, imposing an information bottleneck that fails to capture the inherent ambiguity in music. We propose the Density Matrix RNN (DM-RNN), a novel theoretical architecture utilizing the Density Matrix. This allows the model to maintain a statistical ensemble of musical interpretations (a mixed state), capturing both classical probabilities and quantum coherences. We rigorously define the temporal dynamics using Quantum Channels (CPTP maps). Crucially, we detail a parameterization strategy based on the Choi-Jamiolkowski isomorphism, ensuring the learned dynamics remain physically valid (CPTP) by construction. We introduce an analytical framework using Von Neumann Entropy to quantify musical uncertainty and Quantum Mutual Information (QMI) to measure entanglement between voices. The DM-RNN provides a mathematically rigorous framework for modeling complex, ambiguous musical structures.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 35,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04616",
        "abs_url": "https://arxiv.org/abs/2601.04616",
        "pdf_url": "https://arxiv.org/pdf/2601.04616",
        "title": "DeepHalo: A Neural Choice Model with Controllable Context Effects",
        "authors": [
            "Shuhan Zhang",
            "Zhi Wang",
            "Rui Gao",
            "Shuang Li"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Modeling human decision-making is central to applications such as recommendation, preference learning, and human-AI alignment. While many classic models assume context-independent choice behavior, a large body of behavioral research shows that preferences are often influenced by the composition of the choice set itself -- a phenomenon known as the context effect or Halo effect. These effects can manifest as pairwise (first-order) or even higher-order interactions among the available alternatives. Recent models that attempt to capture such effects either focus on the featureless setting or, in the feature-based setting, rely on restrictive interaction structures or entangle interactions across all orders, which limits interpretability. In this work, we propose DeepHalo, a neural modeling framework that incorporates features while enabling explicit control over interaction order and principled interpretation of context effects. Our model enables systematic identification of interaction effects by order and serves as a universal approximator of context-dependent choice functions when specialized to a featureless setting. Experiments on synthetic and real-world datasets demonstrate strong predictive performance while providing greater transparency into the drivers of choice.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 36,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04670",
        "abs_url": "https://arxiv.org/abs/2601.04670",
        "pdf_url": "https://arxiv.org/pdf/2601.04670",
        "title": "Learning Dynamics in RL Post-Training for Language Models",
        "authors": [
            "Akiyoshi Tomihari"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL post-training, we analyze the learning dynamics of RL post-training from a perspective that has been studied in supervised learning but remains underexplored in RL. We adopt an empirical neural tangent kernel (NTK) framework and decompose the NTK into two components to characterize how RL updates propagate across training samples. Our analysis reveals that limited variability in feature representations can cause RL updates to systematically increase model confidence, providing an explanation for the commonly observed reduction in output diversity after RL post-training. Furthermore, we show that effective learning in this regime depends on rapidly shaping the classifier, which directly affects the gradient component of the NTK. Motivated by these insights, we propose classifier-first reinforcement learning (CF-RL), a simple two-stage training strategy that prioritizes classifier updates before standard RL optimization. Experimental results validate our theoretical analysis by demonstrating increased model confidence and accelerated optimization under CF-RL. Additional analysis shows that the mechanism underlying CF-RL differs from that of linear-probing-then-fine-tuning in supervised learning. Overall, our study formalizes the learning dynamics of RL post-training and motivates further analysis and improvement.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 37,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04686",
        "abs_url": "https://arxiv.org/abs/2601.04686",
        "pdf_url": "https://arxiv.org/pdf/2601.04686",
        "title": "Nightmare Dreamer: Dreaming About Unsafe States And Planning Ahead",
        "authors": [
            "Oluwatosin Oseni",
            "Shengjie Wang",
            "Jun Zhu",
            "Micah Corah"
        ],
        "comments": "RSS'25: Multi-Objective Optimization and Planning in Robotics Workshop: 5 pages, 8 figures",
        "subjects": "Machine Learning (cs.LG); Robotics (cs.RO)",
        "abstract": "Reinforcement Learning (RL) has shown remarkable success in real-world applications, particularly in robotics control. However, RL adoption remains limited due to insufficient safety guarantees. We introduce Nightmare Dreamer, a model-based Safe RL algorithm that addresses safety concerns by leveraging a learned world model to predict potential safety violations and plan actions accordingly. Nightmare Dreamer achieves nearly zero safety violations while maximizing rewards. Nightmare Dreamer outperforms model-free baselines on Safety Gymnasium tasks using only image observations, achieving nearly a 20x improvement in efficiency.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 38,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04690",
        "abs_url": "https://arxiv.org/abs/2601.04690",
        "pdf_url": "https://arxiv.org/pdf/2601.04690",
        "title": "Do LLMs Benefit from User and Item Embeddings in Recommendation Tasks?",
        "authors": [
            "Mir Rayat Imtiaz Hossain",
            "Leo Feng",
            "Leonid Sigal",
            "Mohamed Osama Ahmed"
        ],
        "comments": "Presented in Multimodal Algorithmic Reasoning Workshop at NeurIPS 2025",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Large Language Models (LLMs) have emerged as promising recommendation systems, offering novel ways to model user preferences through generative approaches. However, many existing methods often rely solely on text semantics or incorporate collaborative signals in a limited manner, typically using only user or item embeddings. These methods struggle to handle multiple item embeddings representing user history, reverting to textual semantics and neglecting richer collaborative information. In this work, we propose a simple yet effective solution that projects user and item embeddings, learned from collaborative filtering, into the LLM token space via separate lightweight projector modules. A finetuned LLM then conditions on these projected embeddings alongside textual tokens to generate recommendations. Preliminary results show that this design effectively leverages structured user-item interaction data, improves recommendation performance over text-only LLM baselines, and offers a practical path for bridging traditional recommendation systems with modern LLMs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 39,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04705",
        "abs_url": "https://arxiv.org/abs/2601.04705",
        "pdf_url": "https://arxiv.org/pdf/2601.04705",
        "title": "A zone-based training approach for last-mile routing using Graph Neural Networks and Pointer Networks",
        "authors": [
            "Ãngel Ruiz-Fas",
            "Carlos Granell",
            "JosÃ© Francisco Ramos",
            "JoaquÃ­n Huerta",
            "Sergio Trilles"
        ],
        "comments": "Accepted in SMF 2026. 8 pages, 3 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Rapid e-commerce growth has pushed last-mile delivery networks to their limits, where small routing gains translate into lower costs, faster service, and fewer emissions. Classical heuristics struggle to adapt when travel times are highly asymmetric (e.g., one-way streets, congestion). A deep learning-based approach to the last-mile routing problem is presented to generate geographical zones composed of stop sequences to minimize last-mile delivery times. The presented approach is an encoder-decoder architecture. Each route is represented as a complete directed graph whose nodes are stops and whose edge weights are asymmetric travel times. A Graph Neural Network encoder produces node embeddings that captures the spatial relationships between stops. A Pointer Network decoder then takes the embeddings and the route's start node to sequentially select the next stops, assigning a probability to each unvisited node as the next destination. Cells of a Discrete Global Grid System which contain route stops in the training data are obtained and clustered to generate geographical zones of similar size in which the process of training and inference are divided. Subsequently, a different instance of the model is trained per zone only considering the stops of the training routes which are included in that zone. This approach is evaluated using the Los Angeles routes from the 2021 Amazon Last Mile Routing Challenge. Results from general and zone-based training are compared, showing a reduction in the average predicted route length in the zone-based training compared to the general training. The performance improvement of the zone-based approach becomes more pronounced as the number of stops per route increases.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 40,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04719",
        "abs_url": "https://arxiv.org/abs/2601.04719",
        "pdf_url": "https://arxiv.org/pdf/2601.04719",
        "title": "GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models",
        "authors": [
            "Maanas Taneja",
            "Purab Shingvi"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Performance (cs.PF)",
        "abstract": "The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compression, achieving 4$\\times$ memory reduction with minimal accuracy degradation. We develop four CUDA kernel variants -- naive, tiled, coarsened, and vectorized -- and benchmark them across realistic workload sizes up to 1 billion elements. Our vectorized kernel achieves up to 1,694$\\times$ speedup over CPU baselines while maintaining reconstruction error below 0.004 and attention score error below 0.1 even for 8K-dimensional heads. These results demonstrate that INT8 quantization provides a practical approach for reducing memory pressure in LLM inference with negligible computational overhead (6--58ms) and minimal impact on downstream model behavior",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 41,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04741",
        "abs_url": "https://arxiv.org/abs/2601.04741",
        "pdf_url": "https://arxiv.org/pdf/2601.04741",
        "title": "Fast Mining and Dynamic Time-to-Event Prediction over Multi-sensor Data Streams",
        "authors": [
            "Kota Nakamura",
            "Koki Kawabata",
            "Yasuko Matsubara",
            "Yasushi Sakurai"
        ],
        "comments": "Accepted by KDD 2026",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Given real-time sensor data streams obtained from machines, how can we continuously predict when a machine failure will occur? This work aims to continuously forecast the timing of future events by analyzing multi-sensor data streams. A key characteristic of real-world data streams is their dynamic nature, where the underlying patterns evolve over time. To address this, we present TimeCast, a dynamic prediction framework designed to adapt to these changes and provide accurate, real-time predictions of future event time. Our proposed method has the following properties: (a) Dynamic: it identifies the distinct time-evolving patterns (i.e., stages) and learns individual models for each, enabling us to make adaptive predictions based on pattern shifts. (b) Practical: it finds meaningful stages that capture time-varying interdependencies between multiple sensors and improve prediction performance; (c) Scalable: our algorithm scales linearly with the input size and enables online model updates on data streams. Extensive experiments on real datasets demonstrate that TimeCast provides higher prediction accuracy than state-of-the-art methods while finding dynamic changes in data streams with a great reduction in computational time.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 42,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04751",
        "abs_url": "https://arxiv.org/abs/2601.04751",
        "pdf_url": "https://arxiv.org/pdf/2601.04751",
        "title": "Intraday spatiotemporal PV power prediction at national scale using satellite-based solar forecast models",
        "authors": [
            "Luca Lanzilao",
            "Angela Meyer"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We present a novel framework for spatiotemporal photovoltaic (PV) power forecasting and use it to evaluate the reliability, sharpness, and overall performance of seven intraday PV power nowcasting models. The model suite includes satellite-based deep learning and optical-flow approaches and physics-based numerical weather prediction models, covering both deterministic and probabilistic formulations. Forecasts are first validated against satellite-derived surface solar irradiance (SSI). Irradiance fields are then converted into PV power using station-specific machine learning models, enabling comparison with production data from 6434 PV stations across Switzerland. To our knowledge, this is the first study to investigate spatiotemporal PV forecasting at a national scale. We additionally provide the first visualizations of how mesoscale cloud systems shape national PV production on hourly and sub-hourly timescales. Our results show that satellite-based approaches outperform the Integrated Forecast System (IFS-ENS), particularly at short lead times. Among them, SolarSTEPS and SHADECast deliver the most accurate SSI and PV power predictions, with SHADECast providing the most reliable ensemble spread. The deterministic model IrradianceNet achieves the lowest root mean square error, while probabilistic forecasts of SolarSTEPS and SHADECast provide better-calibrated uncertainty. Forecast skill generally decreases with elevation. At a national scale, satellite-based models forecast the daily total PV generation with relative errors below 10% for 82% of the days in 2019-2020, demonstrating robustness and their potential for operational use.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 43,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04786",
        "abs_url": "https://arxiv.org/abs/2601.04786",
        "pdf_url": "https://arxiv.org/pdf/2601.04786",
        "title": "AgentOCR: Reimagining Agent History via Optical Self-Compression",
        "authors": [
            "Lang Feng",
            "Fuchao Yang",
            "Feng Chen",
            "Xin Cheng",
            "Haiyang Xu",
            "Zhenglin Wan",
            "Ming Yan",
            "Bo An"
        ],
        "comments": "Work in progress",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\\% of text-based agent performance while substantially reducing token consumption (>50\\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 44,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04799",
        "abs_url": "https://arxiv.org/abs/2601.04799",
        "pdf_url": "https://arxiv.org/pdf/2601.04799",
        "title": "Neural-Symbolic Integration with Evolvable Policies",
        "authors": [
            "Marios Thoma",
            "Vassilis Vassiliades",
            "Loizos Michael"
        ],
        "comments": "18 pages, 12 figures, related code available at this https URL",
        "subjects": "Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)",
        "abstract": "Neural-Symbolic (NeSy) Artificial Intelligence has emerged as a promising approach for combining the learning capabilities of neural networks with the interpretable reasoning of symbolic systems. However, existing NeSy frameworks typically require either predefined symbolic policies or policies that are differentiable, limiting their applicability when domain expertise is unavailable or when policies are inherently non-differentiable. We propose a framework that addresses this limitation by enabling the concurrent learning of both non-differentiable symbolic policies and neural network weights through an evolutionary process. Our approach casts NeSy systems as organisms in a population that evolve through mutations (both symbolic rule additions and neural weight changes), with fitness-based selection guiding convergence toward hidden target policies. The framework extends the NEUROLOG architecture to make symbolic policies trainable, adapts Valiant's Evolvability framework to the NeSy context, and employs Machine Coaching semantics for mutable symbolic representations. Neural networks are trained through abductive reasoning from the symbolic component, eliminating differentiability requirements. Through extensive experimentation, we demonstrate that NeSy systems starting with empty policies and random neural weights can successfully approximate hidden non-differentiable target policies, achieving median correct performance approaching 100%. This work represents a step toward enabling NeSy research in domains where the acquisition of symbolic knowledge from experts is challenging or infeasible.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 45,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04855",
        "abs_url": "https://arxiv.org/abs/2601.04855",
        "pdf_url": "https://arxiv.org/pdf/2601.04855",
        "title": "Rethinking GNNs and Missing Features: Challenges, Evaluation and a Robust Solution",
        "authors": [
            "Francesco Ferrini",
            "Veronica Lachi",
            "Antonio Longa",
            "Bruno Lepri",
            "Matono Akiyoshi",
            "Andrea Passerini",
            "Xin Liu",
            "Manfred Jaeger"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Handling missing node features is a key challenge for deploying Graph Neural Networks (GNNs) in real-world domains such as healthcare and sensor networks. Existing studies mostly address relatively benign scenarios, namely benchmark datasets with (a) high-dimensional but sparse node features and (b) incomplete data generated under Missing Completely At Random (MCAR) mechanisms. For (a), we theoretically prove that high sparsity substantially limits the information loss caused by missingness, making all models appear robust and preventing a meaningful comparison of their performance. To overcome this limitation, we introduce one synthetic and three real-world datasets with dense, semantically meaningful features. For (b), we move beyond MCAR and design evaluation protocols with more realistic missingness mechanisms. Moreover, we provide a theoretical background to state explicit assumptions on the missingness process and analyze their implications for different methods. Building on this analysis, we propose GNNmim, a simple yet effective baseline for node classification with incomplete feature data. Experiments show that GNNmim is competitive with respect to specialized architectures across diverse datasets and missingness regimes.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 46,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04873",
        "abs_url": "https://arxiv.org/abs/2601.04873",
        "pdf_url": "https://arxiv.org/pdf/2601.04873",
        "title": "FibreCastML: An Open Web Platform for Predicting Electrospun Nanofibre Diameter Distributions",
        "authors": [
            "Elisa Roldan",
            "Kirstie Andrews",
            "Stephen M. Richardson",
            "Reyhaneh Fatahian",
            "Glen Cooper",
            "Rasool Erfani",
            "Tasneem Sabir",
            "Neil D. Reeves"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Electrospinning is a scalable technique for producing fibrous scaffolds with tunable micro- and nanoscale architectures for applications in tissue engineering, drug delivery, and wound care. While machine learning (ML) has been used to support electrospinning process optimisation, most existing approaches predict only mean fibre diameters, neglecting the full diameter distribution that governs scaffold performance. This work presents FibreCastML, an open, distribution-aware ML framework that predicts complete fibre diameter spectra from routinely reported electrospinning parameters and provides interpretable insights into process structure relationships. A meta-dataset comprising 68538 individual fibre diameter measurements extracted from 1778 studies across 16 biomedical polymers was curated. Six standard processing parameters, namely solution concentration, applied voltage, flow rate, tip to collector distance, needle diameter, and collector rotation speed, were used to train seven ML models using nested cross validation with leave one study out external folds. Model interpretability was achieved using variable importance analysis, SHapley Additive exPlanations, correlation matrices, and three dimensional parameter maps. Non linear models consistently outperformed linear baselines, achieving coefficients of determination above 0.91 for several widely used polymers. Solution concentration emerged as the dominant global driver of fibre diameter distributions. Experimental validation across different electrospinning systems demonstrated close agreement between predicted and measured distributions. FibreCastML enables more reproducible and data driven optimisation of electrospun scaffold architectures.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 47,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04890",
        "abs_url": "https://arxiv.org/abs/2601.04890",
        "pdf_url": "https://arxiv.org/pdf/2601.04890",
        "title": "Learnable Multipliers: Freeing the Scale of Language Model Matrix Layers",
        "authors": [
            "Maksim Velikanov",
            "Ilyas Chahed",
            "Jingwei Zuo",
            "Dhia Eddine Rhaiem",
            "Younes Belkada",
            "Hakim Hacid"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Applying weight decay (WD) to matrix layers is standard practice in large-language-model pretraining. Prior work suggests that stochastic gradient noise induces a Brownian-like expansion of the weight matrices W, whose growth is counteracted by WD, leading to a WD-noise equilibrium with a certain weight norm ||W||. In this work, we view the equilibrium norm as a harmful artifact of the training procedure, and address it by introducing learnable multipliers to learn the optimal scale. First, we attach a learnable scalar multiplier to W and confirm that the WD-noise equilibrium norm is suboptimal: the learned scale adapts to data and improves performance. We then argue that individual row and column norms are similarly constrained, and free their scale by introducing learnable per-row and per-column multipliers. Our method can be viewed as a learnable, more expressive generalization of muP multipliers. It outperforms a well-tuned muP baseline, reduces the computational overhead of multiplier tuning, and surfaces practical questions such as forward-pass symmetries and the width-scaling of the learned multipliers. Finally, we validate learnable multipliers with both Adam and Muon optimizers, where it shows improvement in downstream evaluations matching the improvement of the switching from Adam to Muon.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 48,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04907",
        "abs_url": "https://arxiv.org/abs/2601.04907",
        "pdf_url": "https://arxiv.org/pdf/2601.04907",
        "title": "Distributed Online Convex Optimization with Efficient Communication: Improved Algorithm and Lower bounds",
        "authors": [
            "Sifan Yang",
            "Wenhao Yang",
            "Wei Jiang",
            "Lijun Zhang"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "We investigate distributed online convex optimization with compressed communication, where $n$ learners connected by a network collaboratively minimize a sequence of global loss functions using only local information and compressed data from neighbors. Prior work has established regret bounds of $O(\\max\\{\\omega^{-2}\\rho^{-4}n^{1/2},\\omega^{-4}\\rho^{-8}\\}n\\sqrt{T})$ and $O(\\max\\{\\omega^{-2}\\rho^{-4}n^{1/2},\\omega^{-4}\\rho^{-8}\\}n\\ln{T})$ for convex and strongly convex functions, respectively, where $\\omega\\in(0,1]$ is the compression quality factor ($\\omega=1$ means no compression) and $\\rho<1$ is the spectral gap of the communication matrix. However, these regret bounds suffer from a \\emph{quadratic} or even \\emph{quartic} dependence on $\\omega^{-1}$. Moreover, the \\emph{super-linear} dependence on $n$ is also undesirable. To overcome these limitations, we propose a novel algorithm that achieves improved regret bounds of $\\tilde{O}(\\omega^{-1/2}\\rho^{-1}n\\sqrt{T})$ and $\\tilde{O}(\\omega^{-1}\\rho^{-2}n\\ln{T})$ for convex and strongly convex functions, respectively. The primary idea is to design a \\emph{two-level blocking update framework} incorporating two novel ingredients: an online gossip strategy and an error compensation scheme, which collaborate to \\emph{achieve a better consensus} among learners. Furthermore, we establish the first lower bounds for this problem, justifying the optimality of our results with respect to both $\\omega$ and $T$. Additionally, we consider the bandit feedback scenario, and extend our method with the classic gradient estimators to enhance existing regret bounds.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 49,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04941",
        "abs_url": "https://arxiv.org/abs/2601.04941",
        "pdf_url": "https://arxiv.org/pdf/2601.04941",
        "title": "Cardinality augmented loss functions",
        "authors": [
            "Miguel O'Malley"
        ],
        "comments": "12 pages, 3 figures",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Class imbalance is a common and pernicious issue for the training of neural networks. Often, an imbalanced majority class can dominate training to skew classifier performance towards the majority outcome. To address this problem we introduce cardinality augmented loss functions, derived from cardinality-like invariants in modern mathematics literature such as magnitude and the spread. These invariants enrich the concept of cardinality by evaluating the `effective diversity' of a metric space, and as such represent a natural solution to overly homogeneous training data. In this work, we establish a methodology for applying cardinality augmented loss functions in the training of neural networks and report results on both artificially imbalanced datasets as well as a real-world imbalanced material science dataset. We observe significant performance improvement among minority classes, as well as improvement in overall performance metrics.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 50,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04954",
        "abs_url": "https://arxiv.org/abs/2601.04954",
        "pdf_url": "https://arxiv.org/pdf/2601.04954",
        "title": "Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following",
        "authors": [
            "Yirong Zeng",
            "Yufei Liu",
            "Xiao Ding",
            "Yutai Hou",
            "Yuxian Wang",
            "Haonan Song",
            "Wu Ning",
            "Dandan Tu",
            "Qixun Zhang",
            "Bibo Cai",
            "Yuxiang He",
            "Ting Liu"
        ],
        "comments": "ACL under review 13 pages, 8 figures",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\\% in performance while achieving a 58\\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 51,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05002",
        "abs_url": "https://arxiv.org/abs/2601.05002",
        "pdf_url": "https://arxiv.org/pdf/2601.05002",
        "title": "On the Hidden Objective Biases of Group-based Reinforcement Learning",
        "authors": [
            "Aleksandar Fontana",
            "Marco Simoni",
            "Giulio Rossolini",
            "Andrea Saracino",
            "Paolo Mori"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
        "abstract": "Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 52,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05028",
        "abs_url": "https://arxiv.org/abs/2601.05028",
        "pdf_url": "https://arxiv.org/pdf/2601.05028",
        "title": "Approximate equivariance via projection-based regularisation",
        "authors": [
            "Torben Berndt",
            "Jan StÃ¼hmer"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Equivariance is a powerful inductive bias in neural networks, improving generalisation and physical consistency. Recently, however, non-equivariant models have regained attention, due to their better runtime performance and imperfect symmetries that might arise in real-world applications. This has motivated the development of approximately equivariant models that strike a middle ground between respecting symmetries and fitting the data distribution. Existing approaches in this field usually apply sample-based regularisers which depend on data augmentation at training time, incurring a high sample complexity, in particular for continuous groups such as $SO(3)$. This work instead approaches approximate equivariance via a projection-based regulariser which leverages the orthogonal decomposition of linear layers into equivariant and non-equivariant components. In contrast to existing methods, this penalises non-equivariance at an operator level across the full group orbit, rather than point-wise. We present a mathematical framework for computing the non-equivariance penalty exactly and efficiently in both the spatial and spectral domain. In our experiments, our method consistently outperforms prior approximate equivariance approaches in both model performance and efficiency, achieving substantial runtime gains over sample-based regularisers.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 53,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05033",
        "abs_url": "https://arxiv.org/abs/2601.05033",
        "pdf_url": "https://arxiv.org/pdf/2601.05033",
        "title": "A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models",
        "authors": [
            "Anees Fatima",
            "Mohammad Abdus Salam"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 54,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05052",
        "abs_url": "https://arxiv.org/abs/2601.05052",
        "pdf_url": "https://arxiv.org/pdf/2601.05052",
        "title": "DeepWeightFlow: Re-Basined Flow Matching for Generating Neural Network Weights",
        "authors": [
            "Saumya Gupta",
            "Scott Biggs",
            "Moritz Laber",
            "Zohair Shafi",
            "Robin Walters",
            "Ayan Paul"
        ],
        "comments": "25 pages, 20 tables, 2 figures",
        "subjects": "Machine Learning (cs.LG); Machine Learning (stat.ML)",
        "abstract": "Building efficient and effective generative models for neural network weights has been a research focus of significant interest that faces challenges posed by the high-dimensional weight spaces of modern neural networks and their symmetries. Several prior generative models are limited to generating partial neural network weights, particularly for larger models, such as ResNet and ViT. Those that do generate complete weights struggle with generation speed or require finetuning of the generated models. In this work, we present DeepWeightFlow, a Flow Matching model that operates directly in weight space to generate diverse and high-accuracy neural network weights for a variety of architectures, neural network sizes, and data modalities. The neural networks generated by DeepWeightFlow do not require fine-tuning to perform well and can scale to large networks. We apply Git Re-Basin and TransFusion for neural network canonicalization in the context of generative weight models to account for the impact of neural network permutation symmetries and to improve generation efficiency for larger model sizes. The generated networks excel at transfer learning, and ensembles of hundreds of neural networks can be generated in minutes, far exceeding the efficiency of diffusion-based methods. DeepWeightFlow models pave the way for more efficient and scalable generation of diverse sets of neural networks.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 55,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05073",
        "abs_url": "https://arxiv.org/abs/2601.05073",
        "pdf_url": "https://arxiv.org/pdf/2601.05073",
        "title": "Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward",
        "authors": [
            "Jianlong Chen",
            "Daocheng Fu",
            "Shengze Xu",
            "Jiawei Chen",
            "Yuan Feng",
            "Yue Yang",
            "Junchi Yan",
            "Hongyuan Zha",
            "Renqiu Xia"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because \"black box\" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 56,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05082",
        "abs_url": "https://arxiv.org/abs/2601.05082",
        "pdf_url": "https://arxiv.org/pdf/2601.05082",
        "title": "Exploring Student Expectations and Confidence in Learning Analytics",
        "authors": [
            "Hayk Asatryan",
            "Basile Tousside",
            "Janis Mohr",
            "Malte Neugebauer",
            "Hildo Bijl",
            "Paul Spiegelberg",
            "Claudia Frohn-Schauf",
            "JÃ¶rg Frochte"
        ],
        "comments": "7 pages, Keywords: Learning Analytics, Survey, Data Protection, Clustering",
        "subjects": "Machine Learning (cs.LG); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)",
        "abstract": "Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 57,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05134",
        "abs_url": "https://arxiv.org/abs/2601.05134",
        "pdf_url": "https://arxiv.org/pdf/2601.05134",
        "title": "Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning",
        "authors": [
            "Polina Dolgova",
            "Sebastian U. Stich"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\\varepsilon,\\delta)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 58,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05174",
        "abs_url": "https://arxiv.org/abs/2601.05174",
        "pdf_url": "https://arxiv.org/pdf/2601.05174",
        "title": "FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts",
        "authors": [
            "Yiji Zhao",
            "Zihao Zhong",
            "Ao Wang",
            "Haomin Wen",
            "Ming Jin",
            "Yuxuan Liang",
            "Huaiyu Wan",
            "Hao Wu"
        ],
        "comments": "Accepted to KDD 2026",
        "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
        "abstract": "Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 59,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05194",
        "abs_url": "https://arxiv.org/abs/2601.05194",
        "pdf_url": "https://arxiv.org/pdf/2601.05194",
        "title": "An interpretable data-driven approach to optimizing clinical fall risk assessment",
        "authors": [
            "Fardin Ganjkhanloo",
            "Emmett Springer",
            "Erik H. Hoyer",
            "Daniel L. Young",
            "Holley Farley",
            "Kimia Ghobadi"
        ],
        "comments": "arXiv admin note: substantial text overlap with arXiv:2510.20714",
        "subjects": "Machine Learning (cs.LG)",
        "abstract": "In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 60,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05205",
        "abs_url": "https://arxiv.org/abs/2601.05205",
        "pdf_url": "https://arxiv.org/pdf/2601.05205",
        "title": "EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI",
        "authors": [
            "Zain Iqbal",
            "Lorenzo Valerio"
        ],
        "comments": "6 pages, 9 figures, 2 Tables, conference [Submitted in PerConAI-2026]",
        "subjects": "Machine Learning (cs.LG); Performance (cs.PF)",
        "abstract": "Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 61,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05245",
        "abs_url": "https://arxiv.org/abs/2601.05245",
        "pdf_url": "https://arxiv.org/pdf/2601.05245",
        "title": "Optimal Lower Bounds for Online Multicalibration",
        "authors": [
            "Natalie Collina",
            "Jiuyao Lu",
            "Georgy Noarov",
            "Aaron Roth"
        ],
        "comments": "",
        "subjects": "Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)",
        "abstract": "We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration. In the general setting where group functions can depend on both context and the learner's predictions, we prove an $\\Omega(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems. We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\\widetilde{\\Omega}(T^{2/3})$ lower bound for online multicalibration via a $\\Theta(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 62,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04202",
        "abs_url": "https://arxiv.org/abs/2601.04202",
        "pdf_url": "https://arxiv.org/pdf/2601.04202",
        "title": "TeleTables: A Benchmark for Large Language Models in Telecom Table Interpretation",
        "authors": [
            "Anas Ezzakri",
            "Nicola Piovesan",
            "Mohamed Sana",
            "Antonio De Domenico",
            "Fadhel Ayed",
            "Haozhe Zhang"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Language Models (LLMs) are increasingly explored in the telecom industry to support engineering tasks, accelerate troubleshooting, and assist in interpreting complex technical documents. However, recent studies show that LLMs perform poorly on telecom standards, particularly 3GPP specifications. We argue that a key reason is that these standards densely include tables to present essential information, yet the LLM knowledge and interpretation ability of such tables remains largely unexamined. To address this gap, we introduce TeleTables, a benchmark designed to evaluate both the implicit knowledge LLMs have about tables in technical specifications and their explicit ability to interpret them. TeleTables is built through a novel multi-stage data generation pipeline that extracts tables from 3GPP standards and uses multimodal and reasoning-oriented LLMs to generate and validate questions. The resulting dataset, which is publicly available, comprises 500 human-verified question-answer pairs, each associated with the corresponding table in multiple formats. Our evaluation shows that, smaller models (under 10B parameters) struggle both to recall 3GPP knowledge and to interpret tables, indicating the limited exposure to telecom standards in their pretraining and the insufficient inductive biases for navigating complex technical material. Larger models, on the other hand, show stronger reasoning on table interpretation. Overall, TeleTables highlights the need for domain-specialized fine-tuning to reliably interpret and reason over telecom standards.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 63,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04223",
        "abs_url": "https://arxiv.org/abs/2601.04223",
        "pdf_url": "https://arxiv.org/pdf/2601.04223",
        "title": "Beyond Interaction Effects: Two Logics for Studying Population Inequalities",
        "authors": [
            "Adel Daoud"
        ],
        "comments": "",
        "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); General Economics (econ.GN); Methodology (stat.ME)",
        "abstract": "When sociologists and other social scientist ask whether the return to college differs by race and gender, they face a choice between two fundamentally different modes of inquiry. Traditional interaction models follow deductive logic: the researcher specifies which variables moderate effects and tests these hypotheses. Machine learning methods follow inductive logic: algorithms search across vast combinatorial spaces to discover patterns of heterogeneity. This article develops a framework for navigating between these approaches. We show that the choice between deduction and induction reflects a tradeoff between interpretability and flexibility, and we demonstrate through simulation when each approach excels. Our framework is particularly relevant for inequality research, where understanding how treatment effects vary across intersecting social subpopulation is substantively central.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 64,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04226",
        "abs_url": "https://arxiv.org/abs/2601.04226",
        "pdf_url": "https://arxiv.org/pdf/2601.04226",
        "title": "Automated Reproducibility Has a Problem Statement Problem",
        "authors": [
            "Thijs Snelleman",
            "Peter Lundestad Lawrence",
            "Holger H. Hoos",
            "Odd Erik Gundersen"
        ],
        "comments": "Accepted at RAI Workshop @ AAAI 2026",
        "subjects": "Computers and Society (cs.CY); Machine Learning (cs.LG); Software Engineering (cs.SE)",
        "abstract": "Background. Reproducibility is essential to the scientific method, but reproduction is often a laborious task. Recent works have attempted to automate this process and relieve researchers of this workload. However, due to varying definitions of reproducibility, a clear problem statement is missing. Objectives. Create a generalisable problem statement, applicable to any empirical study. We hypothesise that we can represent any empirical study using a structure based on the scientific method and that this representation can be automatically extracted from any publication, and captures the essence of the study. Methods. We apply our definition of reproducibility as a problem statement for the automatisation of reproducibility by automatically extracting the hypotheses, experiments and interpretations of 20 studies and assess the quality based on assessments by the original authors of each study. Results. We create a dataset representing the reproducibility problem, consisting of the representation of 20 studies. The majority of author feedback is positive, for all parts of the representation. In a few cases, our method failed to capture all elements of the study. We also find room for improvement at capturing specific details, such as results of experiments. Conclusions. We conclude that our formulation of the problem is able to capture the concept of reproducibility in empirical AI studies across a wide range of subfields. Authors of original publications generally agree that the produced structure is representative of their work; we believe improvements can be achieved by applying our findings to create a more structured and fine-grained output in future work.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 65,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04254",
        "abs_url": "https://arxiv.org/abs/2601.04254",
        "pdf_url": "https://arxiv.org/pdf/2601.04254",
        "title": "Scaling Trends for Multi-Hop Contextual Reasoning in Mid-Scale Language Models",
        "authors": [
            "Brady Steele",
            "Micah Katz"
        ],
        "comments": "18 pages, 6 figures, 8 tables",
        "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "We present a controlled study of multi-hop contextual reasoning in large language models, providing a clean demonstration of the task-method dissociation: rule-based pattern matching achieves 100% success on structured information retrieval but only 6.7% on tasks requiring cross-document reasoning, while LLM-based multi-agent systems show the inverse pattern, achieving up to 80% on reasoning tasks where rule-based methods fail. Using a synthetic evaluation framework with 120 trials across four models (LLaMA-3 8B, LLaMA-2 13B, Mixtral 8x7B, DeepSeek-V2 16B), we report three key findings: (1) Multi-agent amplification depends on base capability: statistically significant gains occur only for models with sufficient reasoning ability (p < 0.001 for LLaMA-3 8B, p = 0.014 for Mixtral), with improvements of up to 46.7 percentage points, while weaker models show no benefit, suggesting amplification rather than compensation; (2) Active parameters predict reasoning performance: Mixtral's performance aligns with its ~12B active parameters rather than 47B total, consistent with the hypothesis that inference-time compute drives reasoning capability in MoE architectures; (3) Architecture quality matters: LLaMA-3 8B outperforms LLaMA-2 13B despite fewer parameters, consistent with known training improvements. Our results provide controlled quantitative evidence for intuitions about multi-agent coordination and MoE scaling, while highlighting the dependence of multi-agent benefits on base model capability. We release our evaluation framework to support reproducible research on reasoning in mid-scale models.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 66,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04266",
        "abs_url": "https://arxiv.org/abs/2601.04266",
        "pdf_url": "https://arxiv.org/pdf/2601.04266",
        "title": "State Backdoor: Towards Stealthy Real-world Poisoning Attack on Vision-Language-Action Model in State Space",
        "authors": [
            "Ji Guo",
            "Wenbo Jiang",
            "Yansong Lin",
            "Yijing Liu",
            "Ruichen Zhang",
            "Guomin Lu",
            "Aiguo Chen",
            "Xinshuo Han",
            "Hongwei Li",
            "Dusit Niyato"
        ],
        "comments": "",
        "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG)",
        "abstract": "Vision-Language-Action (VLA) models are widely deployed in safety-critical embodied AI applications such as robotics. However, their complex multimodal interactions also expose new security vulnerabilities. In this paper, we investigate a backdoor threat in VLA models, where malicious inputs cause targeted misbehavior while preserving performance on clean data. Existing backdoor methods predominantly rely on inserting visible triggers into visual modality, which suffer from poor robustness and low insusceptibility in real-world settings due to environmental variability. To overcome these limitations, we introduce the State Backdoor, a novel and practical backdoor attack that leverages the robot arm's initial state as the trigger. To optimize trigger for insusceptibility and effectiveness, we design a Preference-guided Genetic Algorithm (PGA) that efficiently searches the state space for minimal yet potent triggers. Extensive experiments on five representative VLA models and five real-world tasks show that our method achieves over 90% attack success rate without affecting benign task performance, revealing an underexplored vulnerability in embodied AI systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 67,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04278",
        "abs_url": "https://arxiv.org/abs/2601.04278",
        "pdf_url": "https://arxiv.org/pdf/2601.04278",
        "title": "From Domains to Instances: Dual-Granularity Data Synthesis for LLM Unlearning",
        "authors": [
            "Xiaoyu Xu",
            "Minxin Du",
            "Zitong Li",
            "Zi Liang",
            "Zhibiao Guo",
            "Shiyu Zhang",
            "Peizhao Hu",
            "Qingqing Ye",
            "Haibo Hu"
        ],
        "comments": "16 pages",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)",
        "abstract": "Although machine unlearning is essential for removing private, harmful, or copyrighted content from LLMs, current benchmarks often fail to faithfully represent the true \"forgetting scope\" learned by the model. We formalize two distinct unlearning granularities, domain-level and instance-level, and propose BiForget, an automated framework for synthesizing high-quality forget sets. Unlike prior work relying on external generators, BiForget exploits the target model per se to elicit data that matches its internal knowledge distribution through seed-guided and adversarial prompting. Our experiments across diverse benchmarks show that it achieves a superior balance of relevance, diversity, and efficiency. Quantitatively, in the Harry Potter domain, it improves relevance by ${\\sim}20$ and diversity by ${\\sim}$0.05 while halving the total data size compared to SOTAs. Ultimately, it facilitates more robust forgetting and better utility preservation, providing a more rigorous foundation for evaluating LLM unlearning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 68,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04288",
        "abs_url": "https://arxiv.org/abs/2601.04288",
        "pdf_url": "https://arxiv.org/pdf/2601.04288",
        "title": "Human-in-the-Loop Testing of AI Agents for Air Traffic Control with a Regulated Assessment Framework",
        "authors": [
            "Ben Carvell",
            "Marc Thomas",
            "Andrew Pace",
            "Christopher Dorney",
            "George De Ath",
            "Richard Everson",
            "Nick Pepper",
            "Adam Keane",
            "Samuel Tomlinson",
            "Richard Cannon"
        ],
        "comments": "",
        "subjects": "Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multiagent Systems (cs.MA)",
        "abstract": "We present a rigorous, human-in-the-loop evaluation framework for assessing the performance of AI agents on the task of Air Traffic Control, grounded in a regulator-certified simulator-based curriculum used for training and testing real-world trainee controllers. By leveraging legally regulated assessments and involving expert human instructors in the evaluation process, our framework enables a more authentic and domain-accurate measurement of AI performance. This work addresses a critical gap in the existing literature: the frequent misalignment between academic representations of Air Traffic Control and the complexities of the actual operational environment. It also lays the foundations for effective future human-machine teaming paradigms by aligning machine performance with human assessment targets.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 69,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04291",
        "abs_url": "https://arxiv.org/abs/2601.04291",
        "pdf_url": "https://arxiv.org/pdf/2601.04291",
        "title": "Correct and Weight: A Simple Yet Effective Loss for Implicit Feedback Recommendation",
        "authors": [
            "Minglei Yin",
            "Chuanbo Hu",
            "Bin Liu",
            "Neil Zhenqiang Gong",
            "Yanfang",
            "Xin Li"
        ],
        "comments": "arXiv admin note: text overlap with arXiv:2508.05673 by other authors",
        "subjects": "Information Retrieval (cs.IR); Machine Learning (cs.LG)",
        "abstract": "Learning from implicit feedback has become the standard paradigm for modern recommender systems. However, this setting is fraught with the persistent challenge of false negatives, where unobserved user-item interactions are not necessarily indicative of negative preference. To address this issue, this paper introduces a novel and principled loss function, named Corrected and Weighted (CW) loss, that systematically corrects for the impact of false negatives within the training objective. Our approach integrates two key techniques. First, inspired by Positive-Unlabeled learning, we debias the negative sampling process by re-calibrating the assumed negative distribution. By theoretically approximating the true negative distribution (p-) using the observable general data distribution (p) and the positive interaction distribution (p^+), our method provides a more accurate estimate of the likelihood that a sampled unlabeled item is truly negative. Second, we introduce a dynamic re-weighting mechanism that modulates the importance of each negative instance based on the model's current prediction. This scheme encourages the model to enforce a larger ranking margin between positive items and confidently predicted (i.e., easy) negative items, while simultaneously down-weighting the penalty on uncertain negatives that have a higher probability of being false negatives. A key advantage of our approach is its elegance and efficiency; it requires no complex modifications to the data sampling process or significant computational overhead, making it readily applicable to a wide array of existing recommendation models. Extensive experiments conducted on four large-scale, sparse benchmark datasets demonstrate the superiority of our proposed loss. The results show that our method consistently and significantly outperforms a suite of state-of-the-art loss functions across multiple ranking-oriented metrics.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 70,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04377",
        "abs_url": "https://arxiv.org/abs/2601.04377",
        "pdf_url": "https://arxiv.org/pdf/2601.04377",
        "title": "Disco-RAG: Discourse-Aware Retrieval-Augmented Generation",
        "authors": [
            "Dongqi Liu",
            "Hang Ding",
            "Qiming Feng",
            "Jian Li",
            "Xurong Xie",
            "Zhucun Xue",
            "Chengjie Wang",
            "Jiangning Zhang",
            "Yabiao Wang"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Retrieval-Augmented Generation (RAG) has emerged as an important means of enhancing the performance of large language models (LLMs) in knowledge-intensive tasks. However, most existing RAG strategies treat retrieved passages in a flat and unstructured way, which prevents the model from capturing structural cues and constrains its ability to synthesize knowledge from dispersed evidence across documents. To overcome these limitations, we propose Disco-RAG, a discourse-aware framework that explicitly injects discourse signals into the generation process. Our method constructs intra-chunk discourse trees to capture local hierarchies and builds inter-chunk rhetorical graphs to model cross-passage coherence. These structures are jointly integrated into a planning blueprint that conditions the generation. Experiments on question answering and long-document summarization benchmarks show the efficacy of our approach. Disco-RAG achieves state-of-the-art results on the benchmarks without fine-tuning. These findings underscore the important role of discourse structure in advancing RAG systems.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 71,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04401",
        "abs_url": "https://arxiv.org/abs/2601.04401",
        "pdf_url": "https://arxiv.org/pdf/2601.04401",
        "title": "Transformer-based Multi-agent Reinforcement Learning for Separation Assurance in Structured and Unstructured Airspaces",
        "authors": [
            "Arsyi Aziz",
            "Peng Wei"
        ],
        "comments": "9 pages, 4 figures, 4 tables. Presented at SESAR Innovation Days 2025",
        "subjects": "Robotics (cs.RO); Machine Learning (cs.LG); Multiagent Systems (cs.MA)",
        "abstract": "Conventional optimization-based metering depends on strict adherence to precomputed schedules, which limits the flexibility required for the stochastic operations of Advanced Air Mobility (AAM). In contrast, multi-agent reinforcement learning (MARL) offers a decentralized, adaptive framework that can better handle uncertainty, required for safe aircraft separation assurance. Despite this advantage, current MARL approaches often overfit to specific airspace structures, limiting their adaptability to new configurations. To improve generalization, we recast the MARL problem in a relative polar state space and train a transformer encoder model across diverse traffic patterns and intersection angles. The learned model provides speed advisories to resolve conflicts while maintaining aircraft near their desired cruising speeds. In our experiments, we evaluated encoder depths of 1, 2, and 3 layers in both structured and unstructured airspaces, and found that a single encoder configuration outperformed deeper variants, yielding near-zero near mid-air collision rates and shorter loss-of-separation infringements than the deeper configurations. Additionally, we showed that the same configuration outperforms a baseline model designed purely with attention. Together, our results suggest that the newly formulated state representation, novel design of neural network architecture, and proposed training strategy provide an adaptable and scalable decentralized solution for aircraft separation assurance in both structured and unstructured airspaces.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 72,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04423",
        "abs_url": "https://arxiv.org/abs/2601.04423",
        "pdf_url": "https://arxiv.org/pdf/2601.04423",
        "title": "Learning Multinomial Logits in $O(n \\log n)$ time",
        "authors": [
            "Flavio Chierichetti",
            "Mirko Giacchini",
            "Ravi Kumar",
            "Silvio Lattanzi",
            "Alessandro Panconesi",
            "Erasmo Tani",
            "Andrew Tomkins"
        ],
        "comments": "",
        "subjects": "Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML)",
        "abstract": "A Multinomial Logit (MNL) model is composed of a finite universe of items $[n]=\\{1,..., n\\}$, each assigned a positive weight. A query specifies an admissible subset -- called a slate -- and the model chooses one item from that slate with probability proportional to its weight. This query model is also known as the Plackett-Luce model or conditional sampling oracle in the literature. Although MNLs have been studied extensively, a basic computational question remains open: given query access to slates, how efficiently can we learn weights so that, for every slate, the induced choice distribution is within total variation distance $\\varepsilon$ of the ground truth? This question is central to MNL learning and has direct implications for modern recommender system interfaces. We provide two algorithms for this task, one with adaptive queries and one with non-adaptive queries. Each algorithm outputs an MNL $M'$ that induces, for each slate $S$, a distribution $M'_S$ on $S$ that is within $\\varepsilon$ total variation distance of the true distribution. Our adaptive algorithm makes $O\\left(\\frac{n}{\\varepsilon^{3}}\\log n\\right)$ queries, while our non-adaptive algorithm makes $O\\left(\\frac{n^{2}}{\\varepsilon^{3}}\\log n \\log\\frac{n}{\\varepsilon}\\right)$ queries. Both algorithms query only slates of size two and run in time proportional to their query complexity. We complement these upper bounds with lower bounds of $\\Omega\\left(\\frac{n}{\\varepsilon^{2}}\\log n\\right)$ for adaptive queries and $\\Omega\\left(\\frac{n^{2}}{\\varepsilon^{2}}\\log n\\right)$ for non-adaptive queries, thus proving that our adaptive algorithm is optimal in its dependence on the support size $n$, while the non-adaptive one is tight within a $\\log n$ factor.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 73,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04443",
        "abs_url": "https://arxiv.org/abs/2601.04443",
        "pdf_url": "https://arxiv.org/pdf/2601.04443",
        "title": "Large Language Models for Detecting Cyberattacks on Smart Grid Protective Relays",
        "authors": [
            "Ahmad Mohammad Saber",
            "Saeed Jafari",
            "Zhengmao Ouyang",
            "Paul Budnarain",
            "Amr Youssef",
            "Deepa Kundur"
        ],
        "comments": "",
        "subjects": "Cryptography and Security (cs.CR); Machine Learning (cs.LG); Signal Processing (eess.SP)",
        "abstract": "This paper presents a large language model (LLM)-based framework for detecting cyberattacks on transformer current differential relays (TCDRs), which, if undetected, may trigger false tripping of critical transformers. The proposed approach adapts and fine-tunes compact LLMs such as DistilBERT to distinguish cyberattacks from actual faults using textualized multidimensional TCDR current measurements recorded before and after tripping. Our results demonstrate that DistilBERT detects 97.6% of cyberattacks without compromising TCDR dependability and achieves inference latency below 6 ms on a commercial workstation. Additional evaluations confirm the framework's robustness under combined time-synchronization and false-data-injection attacks, resilience to measurement noise, and stability across prompt formulation variants. Furthermore, GPT-2 and DistilBERT+LoRA achieve comparable performance, highlighting the potential of LLMs for enhancing smart grid cybersecurity. We provide the full dataset used in this study for reproducibility.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 74,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04455",
        "abs_url": "https://arxiv.org/abs/2601.04455",
        "pdf_url": "https://arxiv.org/pdf/2601.04455",
        "title": "Re-Rankers as Relevance Judges",
        "authors": [
            "Chuan Meng",
            "Jiqun Liu",
            "Mohammad Aliannejadi",
            "Fengran Mo",
            "Jeff Dalton",
            "Maarten de Rijke"
        ],
        "comments": "",
        "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Using large language models (LLMs) to predict relevance judgments has shown promising results. Most studies treat this task as a distinct research line, e.g., focusing on prompt design for predicting relevance labels given a query and passage. However, predicting relevance judgments is essentially a form of relevance prediction, a problem extensively studied in tasks such as re-ranking. Despite this potential overlap, little research has explored reusing or adapting established re-ranking methods to predict relevance judgments, leading to potential resource waste and redundant development. To bridge this gap, we reproduce re-rankers in a re-ranker-as-relevance-judge setup. We design two adaptation strategies: (i) using binary tokens (e.g., \"true\" and \"false\") generated by a re-ranker as direct judgments, and (ii) converting continuous re-ranking scores into binary labels via thresholding. We perform extensive experiments on TREC-DL 2019 to 2023 with 8 re-rankers from 3 families, ranging from 220M to 32B, and analyse the evaluation bias exhibited by re-ranker-based judges. Results show that re-ranker-based relevance judges, under both strategies, can outperform UMBRELA, a state-of-the-art LLM-based relevance judge, in around 40% to 50% of the cases; they also exhibit strong self-preference towards their own and same-family re-rankers, as well as cross-family bias.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 75,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04469",
        "abs_url": "https://arxiv.org/abs/2601.04469",
        "pdf_url": "https://arxiv.org/pdf/2601.04469",
        "title": "SampoNLP: A Self-Referential Toolkit for Morphological Analysis of Subword Tokenizers",
        "authors": [
            "Iaroslav Chelombitko",
            "Ekaterina Chelombitko",
            "Aleksey Komissarov"
        ],
        "comments": "Accepted to the 10th International Workshop on Computational Linguistics for Uralic Languages (IWCLUL 2025), pp. 57-67",
        "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)",
        "abstract": "The quality of subword tokenization is critical for Large Language Models, yet evaluating tokenizers for morphologically rich Uralic languages is hampered by the lack of clean morpheme lexicons. We introduce SampoNLP, a corpus-free toolkit for morphological lexicon creation using MDL-inspired Self-Referential Atomicity Scoring, which filters composite forms through internal structural cues - suited for low-resource settings. Using the high-purity lexicons generated by SampoNLP for Finnish, Hungarian, and Estonian, we conduct a systematic evaluation of BPE tokenizers across a range of vocabulary sizes (8k-256k). We propose a unified metric, the Integrated Performance Score (IPS), to navigate the trade-off between morpheme coverage and over-splitting. By analyzing the IPS curves, we identify the \"elbow points\" of diminishing returns and provide the first empirically grounded recommendations for optimal vocabulary sizes (k) in these languages. Our study not only offers practical guidance but also quantitatively demonstrates the limitations of standard BPE for highly agglutinative languages. The SampoNLP library and all generated resources are made publicly available: this https URL",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 76,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04473",
        "abs_url": "https://arxiv.org/abs/2601.04473",
        "pdf_url": "https://arxiv.org/pdf/2601.04473",
        "title": "Convergence Rates for Learning Pseudo-Differential Operators",
        "authors": [
            "Jiaheng Chen",
            "Daniel Sanz-Alonso"
        ],
        "comments": "72 pages, 1 figure",
        "subjects": "Statistics Theory (math.ST); Machine Learning (cs.LG); Numerical Analysis (math.NA); Machine Learning (stat.ML)",
        "abstract": "This paper establishes convergence rates for learning elliptic pseudo-differential operators, a fundamental operator class in partial differential equations and mathematical physics. In a wavelet-Galerkin framework, we formulate learning over this class as a structured infinite-dimensional regression problem with multiscale sparsity. Building on this structure, we propose a sparse, data- and computation-efficient estimator, which leverages a novel matrix compression scheme tailored to the learning task and a nested-support strategy to balance approximation and estimation errors. In addition to obtaining convergence rates for the estimator, we show that the learned operator induces an efficient and stable Galerkin solver whose numerical error matches its statistical accuracy. Our results therefore contribute to bringing together operator learning, data-driven solvers, and wavelet methods in scientific computing.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 77,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04478",
        "abs_url": "https://arxiv.org/abs/2601.04478",
        "pdf_url": "https://arxiv.org/pdf/2601.04478",
        "title": "Prediction of Cellular Malignancy Using Electrical Impedance Signatures and Supervised Machine Learning",
        "authors": [
            "Shadeeb Hossain"
        ],
        "comments": "",
        "subjects": "Signal Processing (eess.SP); Machine Learning (cs.LG)",
        "abstract": "Bioelectrical properties of cells such as relative permittivity, conductivity, and characteristic time constants vary significantly between healthy and malignant cells across different frequencies. These distinctions provide a promising foundation for diagnostic and classification applications. This study systematically reviewed 33 scholarly articles to compile datasets of quantitative bioelectric parameters and evaluated their utility in predictive modeling. Three supervised machine learning algorithms- Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbor (KNN) were implemented and tuned using key hyperparameters to assess classification performance. Model effectiveness was evaluated using accuracy and F1 score as performance metrics. Results demonstrate that Random Forest achieved the highest predictive accuracy of ~ 90% when configured with a maximum depth of 4 and 100 estimators. These findings highlight the potential of integrating bioelectrical property analysis with machine learning for improved diagnostic decision-making. Similarly, for KNN and SVM, the F1 score peaked at approximately 78% and 76.5%, respectively. Future work will explore incorporating additional discriminative features, leveraging stimulated datasets, and optimizing hyperparameter through advanced search strategies. Ultimately, hardware prototype with embedded micro-electrodes and real-time control systems could pave the path for practical diagnostic tools capable of in-situ cell classification.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 78,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04501",
        "abs_url": "https://arxiv.org/abs/2601.04501",
        "pdf_url": "https://arxiv.org/pdf/2601.04501",
        "title": "The Minary Primitive of Computational Autopoiesis",
        "authors": [
            "Daniel Connor",
            "Colin Defant"
        ],
        "comments": "21 pages, 2 figures",
        "subjects": "Dynamical Systems (math.DS); Machine Learning (cs.LG); Probability (math.PR)",
        "abstract": "We introduce Minary, a computational framework designed as a candidate for the first formally provable autopoietic primitive. Minary represents interacting probabilistic events as multi-dimensional vectors and combines them via linear superposition rather than multiplicative scalar operations, thereby preserving uncertainty and enabling constructive and destructive interference in the range $[-1,1]$. A fixed set of ``perspectives'' evaluates ``semantic dimensions'' according to hidden competencies, and their interactions drive two discrete-time stochastic processes. We model this system as an iterated random affine map and use the theory of iterated random functions to prove that it converges in distribution to a unique stationary law; we moreover obtain an explicit closed form for the limiting expectation in terms of row, column, and global averages of the competency matrix. We then derive exact formulas for the mean and variance of the normalized consensus conditioned on the activation of a given semantic dimension, revealing how consensus depends on competency structure rather than raw input signals. Finally, we argue that Minary is organizationally closed yet operationally open in the sense of Maturana and Varela, and we discuss implications for building self-maintaining, distributed, and parallelizable computational systems that house a uniquely subjective notion of identity.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 79,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04511",
        "abs_url": "https://arxiv.org/abs/2601.04511",
        "pdf_url": "https://arxiv.org/pdf/2601.04511",
        "title": "Multiagent Reinforcement Learning with Neighbor Action Estimation",
        "authors": [
            "Zhenglong Luo",
            "Zhiyong Chen",
            "Aoxiang Liu"
        ],
        "comments": "",
        "subjects": "Robotics (cs.RO); Machine Learning (cs.LG)",
        "abstract": "Multiagent reinforcement learning, as a prominent intelligent paradigm, enables collaborative decision-making within complex systems. However, existing approaches often rely on explicit action exchange between agents to evaluate action value functions, which is frequently impractical in real-world engineering environments due to communication constraints, latency, energy consumption, and reliability requirements. From an artificial intelligence perspective, this paper proposes an enhanced multiagent reinforcement learning framework that employs action estimation neural networks to infer agent behaviors. By integrating a lightweight action estimation module, each agent infers neighboring agents' behaviors using only locally observable information, enabling collaborative policy learning without explicit action sharing. This approach is fully compatible with standard TD3 algorithms and scalable to larger multiagent systems. At the engineering application level, this framework has been implemented and validated in dual-arm robotic manipulation tasks: two robotic arms collaboratively lift objects. Experimental results demonstrate that this approach significantly enhances the robustness and deployment feasibility of real-world robotic systems while reducing dependence on information infrastructure. Overall, this research advances the development of decentralized multiagent artificial intelligence systems while enabling AI to operate effectively in dynamic, information-constrained real-world environments.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 80,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04517",
        "abs_url": "https://arxiv.org/abs/2601.04517",
        "pdf_url": "https://arxiv.org/pdf/2601.04517",
        "title": "Bridging Distance and Spectral Positional Encodings via Anchor-Based Diffusion Geometry Approximation",
        "authors": [
            "Zimo Yan",
            "Zheng Xie",
            "Runfan Duan",
            "Chang Liu",
            "Wumei Du"
        ],
        "comments": "",
        "subjects": "Information Theory (cs.IT); Machine Learning (cs.LG)",
        "abstract": "Molecular graph learning benefits from positional signals that capture both local neighborhoods and global topology. Two widely used families are spectral encodings derived from Laplacian or diffusion operators and anchor-based distance encodings built from shortest-path information, yet their precise relationship is poorly understood. We interpret distance encodings as a low-rank surrogate of diffusion geometry and derive an explicit trilateration map that reconstructs truncated diffusion coordinates from transformed anchor distances and anchor spectral positions, with pointwise and Frobenius-gap guarantees on random regular graphs. On DrugBank molecular graphs using a shared GNP-based DDI prediction backbone, a distance-driven NystrÃ¶m scheme closely recovers diffusion geometry, and both Laplacian and distance encodings substantially outperform a no-encoding baseline.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 81,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04539",
        "abs_url": "https://arxiv.org/abs/2601.04539",
        "pdf_url": "https://arxiv.org/pdf/2601.04539",
        "title": "Paradoxical noise preference in RNNs",
        "authors": [
            "Noah Eckstein",
            "Manoj Srinivasan"
        ],
        "comments": "15 pages, 6 figures",
        "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "In recurrent neural networks (RNNs) used to model biological neural networks, noise is typically introduced during training to emulate biological variability and regularize learning. The expectation is that removing the noise at test time should preserve or improve performance. Contrary to this intuition, we find that continuous-time recurrent neural networks (CTRNNs) often perform best at a nonzero noise level, specifically, the same level used during training. This noise preference typically arises when noise is injected inside the neural activation function; networks trained with noise injected outside the activation function perform best with zero noise. Through analyses of simple function approximation, maze navigation, and single neuron regulator tasks, we show that the phenomenon stems from noise-induced shifts of fixed points (stationary distributions) in the underlying stochastic dynamics of the RNNs. These fixed point shifts are noise-level dependent and bias the network outputs when the noise is removed, degrading performance. Analytical and numerical results show that the bias arises when neural states operate near activation function nonlinearities, where noise is asymmetrically attenuated, and that performance optimization incentivizes operation near these nonlinearities. Thus, networks can overfit to the stochastic training environment itself rather than just to the input-output data. The phenomenon is distinct from stochastic resonance, wherein nonzero noise enhances signal processing. Our findings reveal that training noise can become an integral part of the computation learned by recurrent networks, with implications for understanding neural population dynamics and for the design of robust artificial RNNs.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 82,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04577",
        "abs_url": "https://arxiv.org/abs/2601.04577",
        "pdf_url": "https://arxiv.org/pdf/2601.04577",
        "title": "Sci-Reasoning: A Dataset Decoding AI Innovation Patterns",
        "authors": [
            "Jiachen Liu",
            "Maestro Harmon",
            "Zechen Zhang"
        ],
        "comments": "22 pages, 9 figures",
        "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "While AI innovation accelerates rapidly, the intellectual process behind breakthroughs -- how researchers identify gaps, synthesize prior work, and generate insights -- remains poorly understood. The lack of structured data on scientific reasoning hinders systematic analysis and development of AI research agents. We introduce Sci-Reasoning, the first dataset capturing the intellectual synthesis behind high-quality AI research. Using community-validated quality signals and an LLM-accelerated, human-verified pipeline, we trace Oral and Spotlight papers across NeurIPS, ICML, and ICLR (2023-2025) to its key predecessors, articulating specific reasoning links in a structured format. Our analysis identifies 15 distinct thinking patterns, with three dominant strategies accounting for 52.7%: Gap-Driven Reframing (24.2%), Cross-Domain Synthesis (18.0%), and Representation Shift (10.5%). The most powerful innovation recipes combine multiple patterns: Gap-Driven Reframing + Representation Shift, Cross-Domain Synthesis + Representation Shift, and Gap-Driven Reframing + Cross-Domain Synthesis. This dataset enables quantitative studies of scientific progress and provides structured reasoning trajectories for training the next generation AI research agents.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 83,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04606",
        "abs_url": "https://arxiv.org/abs/2601.04606",
        "pdf_url": "https://arxiv.org/pdf/2601.04606",
        "title": "Crystal Generation using the Fully Differentiable Pipeline and Latent Space Optimization",
        "authors": [
            "Osman Goni Ridwan",
            "Gilles Frapper",
            "Hongfei Xue",
            "Qiang Zhu"
        ],
        "comments": "",
        "subjects": "Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Atomic and Molecular Clusters (physics.atm-clus)",
        "abstract": "We present a materials generation framework that couples a symmetry-conditioned variational autoencoder (CVAE) with a differentiable SO(3) power spectrum objective to steer candidates toward a specified local environment under the crystallographic constraints. In particular, we implement a fully differentiable pipeline that performs batch-wise optimization on both direct and latent crystallographic representations. Using the GPU acceleration, the implementation achieves about fivefold speed compared to our previous CPU workflow, while yielding comparable outcomes. In addition, we introduce the optimization strategy that alternatively performs optimization on the direct and latent crystal representations. This dual-level relaxation approach can effectively overcome local barrier defined by different objective gradients, thus increasing the success rate of generating complex structures satisfying the targe local environments. This framework can be extended to systems consisting of multi-components and multi-environments, providing a scalable route to generate material structures with the target local environment.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 84,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04641",
        "abs_url": "https://arxiv.org/abs/2601.04641",
        "pdf_url": "https://arxiv.org/pdf/2601.04641",
        "title": "DP-MGTD: Privacy-Preserving Machine-Generated Text Detection via Adaptive Differentially Private Entity Sanitization",
        "authors": [
            "Lionel Z. Wang",
            "Yusheng Zhao",
            "Jiabin Luo",
            "Xinfeng Li",
            "Lixu Wang",
            "Yinan Peng",
            "Haoyang Li",
            "XiaoFeng Wang",
            "Wei Dong"
        ],
        "comments": "12 pages, 1 figure, 1 tables",
        "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "The deployment of Machine-Generated Text (MGT) detection systems necessitates processing sensitive user data, creating a fundamental conflict between authorship verification and privacy preservation. Standard anonymization techniques often disrupt linguistic fluency, while rigorous Differential Privacy (DP) mechanisms typically degrade the statistical signals required for accurate detection. To resolve this dilemma, we propose \\textbf{DP-MGTD}, a framework incorporating an Adaptive Differentially Private Entity Sanitization algorithm. Our approach utilizes a two-stage mechanism that performs noisy frequency estimation and dynamically calibrates privacy budgets, applying Laplace and Exponential mechanisms to numerical and textual entities respectively. Crucially, we identify a counter-intuitive phenomenon where the application of DP noise amplifies the distinguishability between human and machine text by exposing distinct sensitivity patterns to perturbation. Extensive experiments on the MGTBench-2.0 dataset show that our method achieves near-perfect detection accuracy, significantly outperforming non-private baselines while satisfying strict privacy guarantees.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 85,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04648",
        "abs_url": "https://arxiv.org/abs/2601.04648",
        "pdf_url": "https://arxiv.org/pdf/2601.04648",
        "title": "Mechanism Design for Federated Learning with Non-Monotonic Network Effects",
        "authors": [
            "Xiang Li",
            "Bing Luo",
            "Jianwei Huang",
            "Yuan Luo"
        ],
        "comments": "Journal extension of Mobihoc conference version, under review of IEEE TMC",
        "subjects": "Computer Science and Game Theory (cs.GT); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)",
        "abstract": "Mechanism design is pivotal to federated learning (FL) for maximizing social welfare by coordinating self-interested clients. Existing mechanisms, however, often overlook the network effects of client participation and the diverse model performance requirements (i.e., generalization error) across applications, leading to suboptimal incentives and social welfare, or even inapplicability in real deployments. To address this gap, we explore incentive mechanism design for FL with network effects and application-specific requirements of model performance. We develop a theoretical model to quantify the impact of network effects on heterogeneous client participation, revealing the non-monotonic nature of such effects. Based on these insights, we propose a Model Trading and Sharing (MoTS) framework, which enables clients to obtain FL models through either participation or purchase. To further address clients' strategic behaviors, we design a Social Welfare maximization with Application-aware and Network effects (SWAN) mechanism, exploiting model customer payments for incentivization. Experimental results on a hardware prototype demonstrate that our SWAN mechanism outperforms existing FL mechanisms, improving social welfare by up to $352.42\\%$ and reducing extra incentive costs by $93.07\\%$.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 86,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04698",
        "abs_url": "https://arxiv.org/abs/2601.04698",
        "pdf_url": "https://arxiv.org/pdf/2601.04698",
        "title": "TourPlanner: A Competitive Consensus Framework with Constraint-Gated Reinforcement Learning for Travel Planning",
        "authors": [
            "Yinuo Wang",
            "Mining Tan",
            "Wenxiang Jiao",
            "Xiaoxi Li",
            "Hao Wang",
            "Xuanyu Zhang",
            "Yuan Lu",
            "Weiming Dong"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Travel planning is a sophisticated decision-making process that requires synthesizing multifaceted information to construct itineraries. However, existing travel planning approaches face several challenges: (1) Pruning candidate points of interest (POIs) while maintaining a high recall rate; (2) A single reasoning path restricts the exploration capability within the feasible solution space for travel planning; (3) Simultaneously optimizing hard constraints and soft constraints remains a significant difficulty. To address these challenges, we propose TourPlanner, a comprehensive framework featuring multi-path reasoning and constraint-gated reinforcement learning. Specifically, we first introduce a Personalized Recall and Spatial Optimization (PReSO) workflow to construct spatially-aware candidate POIs' set. Subsequently, we propose Competitive consensus Chain-of-Thought (CCoT), a multi-path reasoning paradigm that improves the ability of exploring the feasible solution space. To further refine the plan, we integrate a sigmoid-based gating mechanism into the reinforcement learning stage, which dynamically prioritizes soft-constraint satisfaction only after hard constraints are met. Experimental results on travel planning benchmarks demonstrate that TourPlanner achieves state-of-the-art performance, significantly surpassing existing methods in both feasibility and user-preference alignment.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 87,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04710",
        "abs_url": "https://arxiv.org/abs/2601.04710",
        "pdf_url": "https://arxiv.org/pdf/2601.04710",
        "title": "Prior-Informed Zeroth-Order Optimization with Adaptive Direction Alignment for Memory-Efficient LLM Fine-Tuning",
        "authors": [
            "Feihu Jin",
            "Shipeng Cen",
            "Ying Tan"
        ],
        "comments": "12pages, 6figures",
        "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)",
        "abstract": "Fine-tuning large language models (LLMs) has achieved remarkable success across various NLP tasks, but the substantial memory overhead during backpropagation remains a critical bottleneck, especially as model scales grow. Zeroth-order (ZO) optimization alleviates this issue by estimating gradients through forward passes and Gaussian sampling, avoiding the need for backpropagation. However, conventional ZO methods suffer from high variance in gradient estimation due to their reliance on random perturbations, leading to slow convergence and suboptimal performance. We propose a simple plug-and-play method that incorporates prior-informed perturbations to refine gradient estimation. Our method dynamically computes a guiding vector from Gaussian samples, which directs perturbations toward more informative directions, significantly accelerating convergence compared to standard ZO approaches. We further investigate a greedy perturbation strategy to explore the impact of prior knowledge on gradient estimation. Theoretically, we prove that our gradient estimator achieves stronger alignment with the true gradient direction, enhancing optimization efficiency. Extensive experiments across LLMs of varying scales and architectures demonstrate that our proposed method could seamlessly integrate into existing optimization methods, delivering faster convergence and superior performance. Notably, on the OPT-13B model, our method outperforms traditional ZO optimization across all 11 benchmark tasks and surpasses gradient-based baselines on 9 out of 11 tasks, establishing a robust balance between efficiency and accuracy.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 88,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04765",
        "abs_url": "https://arxiv.org/abs/2601.04765",
        "pdf_url": "https://arxiv.org/pdf/2601.04765",
        "title": "Differential syntactic and semantic encoding in LLMs",
        "authors": [
            "Santiago Acevedo",
            "Alessandro Laio",
            "Marco Baroni"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)",
        "abstract": "We study how syntactic and semantic information is encoded in inner layer representations of Large Language Models (LLMs), focusing on the very large DeepSeek-V3. We find that, by averaging hidden-representation vectors of sentences sharing syntactic structure or meaning, we obtain vectors that capture a significant proportion of the syntactic and semantic information contained in the representations. In particular, subtracting these syntactic and semantic ``centroids'' from sentence vectors strongly affects their similarity with syntactically and semantically matched sentences, respectively, suggesting that syntax and semantics are, at least partially, linearly encoded. We also find that the cross-layer encoding profiles of syntax and semantics are different, and that the two signals can to some extent be decoupled, suggesting differential encoding of these two types of linguistic information in LLM representations.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 89,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04801",
        "abs_url": "https://arxiv.org/abs/2601.04801",
        "pdf_url": "https://arxiv.org/pdf/2601.04801",
        "title": "MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration",
        "authors": [
            "Lei Xu",
            "Shanshan Wang",
            "Chenglong Xiao"
        ],
        "comments": "",
        "subjects": "Hardware Architecture (cs.AR); Machine Learning (cs.LG)",
        "abstract": "High-Level Synthesis (HLS) design space exploration (DSE) seeks Pareto-optimal designs within expansive pragma configuration spaces. To accelerate HLS DSE, graph neural networks (GNNs) are commonly employed as surrogates for HLS tools to predict quality of results (QoR) metrics, while multi-objective optimization algorithms expedite the exploration. However, GNN-based prediction methods may not fully capture the rich semantic features inherent in behavioral descriptions, and conventional multi-objective optimization algorithms often do not explicitly account for the domain-specific knowledge regarding how pragma directives influence QoR. To address these limitations, this paper proposes the MPM-LLM4DSE framework, which incorporates a multimodal prediction model (MPM) that simultaneously fuses features from behavioral descriptions and control and data flow graphs. Furthermore, the framework employs a large language model (LLM) as an optimizer, accompanied by a tailored prompt engineering methodology. This methodology incorporates pragma impact analysis on QoR to guide the LLM in generating high-quality configurations (LLM4DSE). Experimental results demonstrate that our multimodal predictive model significantly outperforms state-of-the-art work ProgSG by up to 10.25$\\times$. Furthermore, in DSE tasks, the proposed LLM4DSE achieves an average performance gain of 39.90\\% over prior methods, validating the effectiveness of our prompting methodology. Code and models are available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 90,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04808",
        "abs_url": "https://arxiv.org/abs/2601.04808",
        "pdf_url": "https://arxiv.org/pdf/2601.04808",
        "title": "Comparison of Maximum Likelihood Classification Before and After Applying Weierstrass Transform",
        "authors": [
            "Muhammad Shoaib",
            "Zaka Ur Rehman",
            "Muhammad Qasim"
        ],
        "comments": "",
        "subjects": "Applications (stat.AP); Machine Learning (cs.LG); Probability (math.PR)",
        "abstract": "The aim of this paper is to use Maximum Likelihood (ML) Classification on multispectral data by means of qualitative and quantitative approaches. Maximum Likelihood is a supervised classification algorithm which is based on the Classical Bayes theorem. It makes use of a discriminant function to assign pixel to the class with the highest likelihood. Class means vector and covariance matrix are the key inputs to the function and can be estimated from training pixels of a particular class. As Maximum Likelihood need some assumptions before it has to be applied on the data. In this paper we will compare the results of Maximum Likelihood Classification (ML) before apply the Weierstrass Transform and apply Weierstrass Transform and will see the difference between the accuracy on training pixels of high resolution Quickbird satellite image. Principle Component analysis (PCA) is also used for dimension reduction and also used to check the variation in bands. The results shows that the separation between mean of the classes in the decision space is to be the main factor that leads to the high classification accuracy of Maximum Likelihood (ML) after using Weierstrass Transform than without using it.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 91,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04854",
        "abs_url": "https://arxiv.org/abs/2601.04854",
        "pdf_url": "https://arxiv.org/pdf/2601.04854",
        "title": "Token Maturation: Autoregressive Language Generation via Continuous Token Dynamics",
        "authors": [
            "Oshri Naparstek"
        ],
        "comments": "In preperation to ICML 2026",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Autoregressive language models are conventionally defined over discrete token sequences, committing to a specific token at every generation step. This early discretization forces uncertainty to be resolved through token-level sampling, often leading to instability, repetition, and sensitivity to decoding heuristics. In this work, we introduce a continuous autoregressive formulation of language generation in which tokens are represented as continuous vectors that \\emph{mature} over multiple update steps before being discretized. Rather than sampling tokens, the model evolves continuous token representations through a deterministic dynamical process, committing to a discrete token only when the representation has sufficiently converged. Discrete text is recovered via hard decoding, while uncertainty is maintained and resolved in the continuous space. We show that this maturation process alone is sufficient to produce coherent and diverse text using deterministic decoding (argmax), without reliance on token-level sampling, diffusion-style denoising, or auxiliary stabilization mechanisms. Additional perturbations, such as stochastic dynamics or history smoothing, can be incorporated naturally but are not required for the model to function. To our knowledge, this is the first autoregressive language model that generates text by evolving continuous token representations to convergence prior to discretization, enabling stable generation without token-level sampling.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 92,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04867",
        "abs_url": "https://arxiv.org/abs/2601.04867",
        "pdf_url": "https://arxiv.org/pdf/2601.04867",
        "title": "Gradient-based Optimisation of Modulation Effects",
        "authors": [
            "Alistair Carson",
            "Alec Wright",
            "Stefan Bilbao"
        ],
        "comments": "Submitted to J. Audio Eng. Soc. Dec. 2025",
        "subjects": "Audio and Speech Processing (eess.AS); Machine Learning (cs.LG); Sound (cs.SD)",
        "abstract": "Modulation effects such as phasers, flangers and chorus effects are heavily used in conjunction with the electric guitar. Machine learning based emulation of analog modulation units has been investigated in recent years, but most methods have either been limited to one class of effect or suffer from a high computational cost or latency compared to canonical digital implementations. Here, we build on previous work and present a framework for modelling flanger, chorus and phaser effects based on differentiable digital signal processing. The model is trained in the time-frequency domain, but at inference operates in the time-domain, requiring zero latency. We investigate the challenges associated with gradient-based optimisation of such effects, and show that low-frequency weighting of loss functions avoids convergence to local minima when learning delay times. We show that when trained against analog effects units, sound output from the model is in some cases perceptually indistinguishable from the reference, but challenges still remain for effects with long delay times and feedback.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 93,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04885",
        "abs_url": "https://arxiv.org/abs/2601.04885",
        "pdf_url": "https://arxiv.org/pdf/2601.04885",
        "title": "CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters",
        "authors": [
            "Ao Sun",
            "Xiaoyu Wang",
            "Zhe Tan",
            "Yu Li",
            "Jiachen Zhu",
            "Shu Su",
            "Yuheng Jia"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \\textbf{Mean Collapse}, converging to a generic average that fails to represent diverse groups. We attribute this to \\textbf{Cultural Sparsity}, where gradient interference prevents dense parameters from spanning distinct cultural modes. To resolve this, we propose \\textbf{\\textsc{CuMA}} (\\textbf{Cu}ltural \\textbf{M}ixture of \\textbf{A}dapters), a framework that frames alignment as a \\textbf{conditional capacity separation} problem. By incorporating demographic-aware routing, \\textsc{CuMA} internalizes a \\textit{Latent Cultural Topology} to explicitly disentangle conflicting gradients into specialized expert subspaces. Extensive evaluations on WorldValuesBench, Community Alignment, and PRISM demonstrate that \\textsc{CuMA} achieves state-of-the-art performance, significantly outperforming both dense baselines and semantic-only MoEs. Crucially, our analysis confirms that \\textsc{CuMA} effectively mitigates mean collapse, preserving cultural diversity. Our code is available at this https URL.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 94,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.04897",
        "abs_url": "https://arxiv.org/abs/2601.04897",
        "pdf_url": "https://arxiv.org/pdf/2601.04897",
        "title": "V-FAT: Benchmarking Visual Fidelity Against Text-bias",
        "authors": [
            "Ziteng Wang",
            "Yujie He",
            "Guanliang Li",
            "Siqi Yang",
            "Jiaqi Xiong",
            "Songxiang Liu"
        ],
        "comments": "12 pages, 6 figures",
        "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)",
        "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated impressive performance on standard visual reasoning benchmarks. However, there is growing concern that these models rely excessively on linguistic shortcuts rather than genuine visual grounding, a phenomenon we term Text Bias. In this paper, we investigate the fundamental tension between visual perception and linguistic priors. We decouple the sources of this bias into two dimensions: Internal Corpus Bias, stemming from statistical correlations in pretraining, and External Instruction Bias, arising from the alignment-induced tendency toward sycophancy. To quantify this effect, we introduce V-FAT (Visual Fidelity Against Text-bias), a diagnostic benchmark comprising 4,026 VQA instances across six semantic domains. V-FAT employs a Three-Level Evaluation Framework that systematically increases the conflict between visual evidence and textual information: (L1) internal bias from atypical images, (L2) external bias from misleading instructions, and (L3) synergistic bias where both coincide. We introduce the Visual Robustness Score (VRS), a metric designed to penalize \"lucky\" linguistic guesses and reward true visual fidelity. Our evaluation of 12 frontier MLLMs reveals that while models excel in existing benchmarks, they experience significant visual collapse under high linguistic dominance.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 95,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05011",
        "abs_url": "https://arxiv.org/abs/2601.05011",
        "pdf_url": "https://arxiv.org/pdf/2601.05011",
        "title": "Leveraging Prediction Entropy for Automatic Prompt Weighting in Zero-Shot Audio-Language Classification",
        "authors": [
            "Karim El Khoury",
            "Maxime Zanella",
            "Tiffanie Godelaine",
            "Christophe De Vleeschouwer",
            "Benoit Macq"
        ],
        "comments": "",
        "subjects": "Sound (cs.SD); Machine Learning (cs.LG)",
        "abstract": "Audio-language models have recently demonstrated strong zero-shot capabilities by leveraging natural-language supervision to classify audio events without labeled training data. Yet, their performance is highly sensitive to the wording of text prompts, with small variations leading to large fluctuations in accuracy. Prior work has mitigated this issue through prompt learning or prompt ensembling. However, these strategies either require annotated data or fail to account for the fact that some prompts may negatively impact performance. In this work, we present an entropy-guided prompt weighting approach that aims to find a robust combination of prompt contributions to maximize prediction confidence. To this end, we formulate a tailored objective function that minimizes prediction entropy to yield new prompt weights, utilizing low-entropy as a proxy for high confidence. Our approach can be applied to individual samples or a batch of audio samples, requiring no additional labels and incurring negligible computational overhead. Experiments on five audio classification datasets covering environmental, urban, and vocal sounds, demonstrate consistent gains compared to classical prompt ensembling methods in a zero-shot setting, with accuracy improvements 5-times larger across the whole benchmark.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 96,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05047",
        "abs_url": "https://arxiv.org/abs/2601.05047",
        "pdf_url": "https://arxiv.org/pdf/2601.05047",
        "title": "Challenges and Research Directions for Large Language Model Inference Hardware",
        "authors": [
            "Xiaoyu Ma",
            "David Patterson"
        ],
        "comments": "Accepted for publication by IEEE Computer, 2026",
        "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 97,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05062",
        "abs_url": "https://arxiv.org/abs/2601.05062",
        "pdf_url": "https://arxiv.org/pdf/2601.05062",
        "title": "Compositional Steering of Large Language Models with Steering Tokens",
        "authors": [
            "Gorjan Radevski",
            "Kiril Gashteovski",
            "Giwon Hong",
            "Carolin Lawrence",
            "Goran GlavaÅ¡"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Deploying LLMs in real-world applications requires controllable output that satisfies multiple desiderata at the same time. While existing work extensively addresses LLM steering for a single behavior, \\textit{compositional steering} -- i.e., steering LLMs simultaneously towards multiple behaviors -- remains an underexplored problem. In this work, we propose \\emph{compositional steering tokens} for multi-behavior steering. We first embed individual behaviors, expressed as natural language instructions, into dedicated tokens via self-distillation. Contrary to most prior work, which operates in the activation space, our behavior steers live in the space of input tokens, enabling more effective zero-shot composition. We then train a dedicated \\textit{composition token} on pairs of behaviors and show that it successfully captures the notion of composition: it generalizes well to \\textit{unseen} compositions, including those with unseen behaviors as well as those with an unseen \\textit{number} of behaviors. Our experiments across different LLM architectures show that steering tokens lead to superior multi-behavior control compared to competing approaches (instructions, activation steering, and LoRA merging). Moreover, we show that steering tokens complement natural language instructions, with their combination resulting in further gains.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 98,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05091",
        "abs_url": "https://arxiv.org/abs/2601.05091",
        "pdf_url": "https://arxiv.org/pdf/2601.05091",
        "title": "Code-Mix Sentiment Analysis on Hinglish Tweets",
        "authors": [
            "Aashi Garg",
            "Aneshya Das",
            "Arshi Arya",
            "Anushka Goyal",
            "Aditi"
        ],
        "comments": "Accepted at the 9th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2025), Fukuoka, Japan",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish--a hybrid of Hindi and English--used widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 99,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05137",
        "abs_url": "https://arxiv.org/abs/2601.05137",
        "pdf_url": "https://arxiv.org/pdf/2601.05137",
        "title": "Neural Algorithmic Reasoning for Approximate $k$-Coloring with Recursive Warm Starts",
        "authors": [
            "Knut Vanderbush",
            "Melanie Weber"
        ],
        "comments": "33 pages, 10 figures",
        "subjects": "Combinatorics (math.CO); Machine Learning (cs.LG)",
        "abstract": "Node coloring is the task of assigning colors to the nodes of a graph such that no two adjacent nodes have the same color, while using as few colors as possible. It is the most widely studied instance of graph coloring and of central importance in graph theory; major results include the Four Color Theorem and work on the Hadwiger-Nelson Problem. As an abstraction of classical combinatorial optimization tasks, such as scheduling and resource allocation, it is also rich in practical applications. Here, we focus on a relaxed version, approximate $k$-coloring, which is the task of assigning at most $k$ colors to the nodes of a graph such that the number of edges whose vertices have the same color is approximately minimized. While classical approaches leverage mathematical programming or SAT solvers, recent studies have explored the use of machine learning. We follow this route and explore the use of graph neural networks (GNNs) for node coloring. We first present an optimized differentiable algorithm that improves a prior approach by Schuetz et al. with orthogonal node feature initialization and a loss function that penalizes conflicting edges more heavily when their endpoints have higher degree; the latter inspired by the classical result that a graph is $k$-colorable if and only if its $k$-core is $k$-colorable. Next, we introduce a lightweight greedy local search algorithm and show that it may be improved by recursively computing a $(k-1)$-coloring to use as a warm start. We then show that applying such recursive warm starts to the GNN approach leads to further improvements. Numerical experiments on a range of different graph structures show that while the local search algorithms perform best on small inputs, the GNN exhibits superior performance at scale. The recursive warm start may be of independent interest beyond graph coloring for local search methods for combinatorial optimization.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 100,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05151",
        "abs_url": "https://arxiv.org/abs/2601.05151",
        "pdf_url": "https://arxiv.org/pdf/2601.05151",
        "title": "ROOFS: RObust biOmarker Feature Selection",
        "authors": [
            "Anastasiia Bakhmach",
            "Paul DufossÃ©",
            "Andrea Vaglio",
            "Florence Monville",
            "Laurent Greillier",
            "Fabrice BarlÃ©si",
            "SÃ©bastien Benzekry"
        ],
        "comments": "",
        "subjects": "Machine Learning (stat.ML); Machine Learning (cs.LG)",
        "abstract": "Feature selection (FS) is essential for biomarker discovery and in the analysis of biomedical datasets. However, challenges such as high-dimensional feature space, low sample size, multicollinearity, and missing values make FS non-trivial. Moreover, FS performances vary across datasets and predictive tasks. We propose roofs, a Python package available at this https URL, designed to help researchers in the choice of FS method adapted to their problem. Roofs benchmarks multiple FS methods on the user's data and generates reports that summarize a comprehensive set of evaluation metrics, including downstream predictive performance estimated using optimism correction, stability, reliability of individual features, and true positive and false positive rates assessed on semi-synthetic data with a simulated outcome. We demonstrate the utility of roofs on data from the PIONeeR clinical trial, aimed at identifying predictors of resistance to anti-PD-(L)1 immunotherapy in lung cancer. The PIONeeR dataset contained 374 multi-source blood and tumor biomarkers from 435 patients. A reduced subset of 214 features was obtained through iterative variance inflation factor pre-filtering. Of the 34 FS methods gathered in roofs, we evaluated 23 in combination with 11 classifiers (253 models in total) and identified a filter based on the union of Benjamini-Hochberg false discovery rate-adjusted p-values from t-test and logistic regression as the optimal approach, outperforming other methods including the widely used LASSO. We conclude that comprehensive benchmarking with roofs has the potential to improve the robustness and reproducibility of FS discoveries and increase the translational value of clinical models.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 101,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05157",
        "abs_url": "https://arxiv.org/abs/2601.05157",
        "pdf_url": "https://arxiv.org/pdf/2601.05157",
        "title": "Learning Mixture Models via Efficient High-dimensional Sparse Fourier Transforms",
        "authors": [
            "Alkis Kalavasis",
            "Pravesh K. Kothari",
            "Shuchen Li",
            "Manolis Zampetakis"
        ],
        "comments": "",
        "subjects": "Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Machine Learning (stat.ML)",
        "abstract": "In this work, we give a ${\\rm poly}(d,k)$ time and sample algorithm for efficiently learning the parameters of a mixture of $k$ spherical distributions in $d$ dimensions. Unlike all previous methods, our techniques apply to heavy-tailed distributions and include examples that do not even have finite covariances. Our method succeeds whenever the cluster distributions have a characteristic function with sufficiently heavy tails. Such distributions include the Laplace distribution but crucially exclude Gaussians. All previous methods for learning mixture models relied implicitly or explicitly on the low-degree moments. Even for the case of Laplace distributions, we prove that any such algorithm must use super-polynomially many samples. Our method thus adds to the short list of techniques that bypass the limitations of the method of moments. Somewhat surprisingly, our algorithm does not require any minimum separation between the cluster means. This is in stark contrast to spherical Gaussian mixtures where a minimum $\\ell_2$-separation is provably necessary even information-theoretically [Regev and Vijayaraghavan '17]. Our methods compose well with existing techniques and allow obtaining ''best of both worlds\" guarantees for mixtures where every component either has a heavy-tailed characteristic function or has a sub-Gaussian tail with a light-tailed characteristic function. Our algorithm is based on a new approach to learning mixture models via efficient high-dimensional sparse Fourier transforms. We believe that this method will find more applications to statistical estimation. As an example, we give an algorithm for consistent robust mean estimation against noise-oblivious adversaries, a model practically motivated by the literature on multiple hypothesis testing. It was formally proposed in a recent Master's thesis by one of the authors, and has already inspired follow-up works.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 102,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05167",
        "abs_url": "https://arxiv.org/abs/2601.05167",
        "pdf_url": "https://arxiv.org/pdf/2601.05167",
        "title": "RelayLLM: Efficient Reasoning via Collaborative Decoding",
        "authors": [
            "Chengsong Huang",
            "Tong Zheng",
            "Langlin Huang",
            "Jinyuan Li",
            "Haolin Liu",
            "Jiaxin Huang"
        ],
        "comments": "",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 103,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05202",
        "abs_url": "https://arxiv.org/abs/2601.05202",
        "pdf_url": "https://arxiv.org/pdf/2601.05202",
        "title": "Stock Market Price Prediction using Neural Prophet with Deep Neural Network",
        "authors": [
            "Navin Chhibber",
            "Suneel Khemka",
            "Navneet Kumar Tyagi",
            "Rohit Tewari",
            "Bireswar Banerjee",
            "Piyush Ranjan"
        ],
        "comments": "",
        "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "Stock market price prediction is a significant interdisciplinary research domain that depends at the intersection of finance, statistics, and economics. Forecasting Accurately predicting stock prices has always been a focal point for various researchers. However, existing statistical approaches for time-series prediction often fail to effectively forecast the probability range of future stock prices. Hence, to solve this problem, the Neural Prophet with a Deep Neural Network (NP-DNN) is proposed to predict stock market prices. The preprocessing technique used in this research is Z-score normalization, which normalizes stock price data by removing scale differences, making patterns easier to detect. Missing value imputation fills gaps in historical data, enhancing the models use of complete information for more accurate predictions. The Multi-Layer Perceptron (MLP) learns complex nonlinear relationships among stock market prices and extracts hidden patterns from the input data, thereby creating meaningful feature representations for better prediction accuracy. The proposed NP-DNN model achieved an accuracy of 99.21% compared with other approaches using the Fused Large Language Model. Keywords: deep neural network, forecasting stock prices, multi-layer perceptron, neural prophet, stock market price prediction.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 104,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05219",
        "abs_url": "https://arxiv.org/abs/2601.05219",
        "pdf_url": "https://arxiv.org/pdf/2601.05219",
        "title": "CAOS: Conformal Aggregation of One-Shot Predictors",
        "authors": [
            "Maja Waldron"
        ],
        "comments": "",
        "subjects": "Machine Learning (stat.ML); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "One-shot prediction enables rapid adaptation of pretrained foundation models to new tasks using only one labeled example, but lacks principled uncertainty quantification. While conformal prediction provides finite-sample coverage guarantees, standard split conformal methods are inefficient in the one-shot setting due to data splitting and reliance on a single predictor. We propose Conformal Aggregation of One-Shot Predictors (CAOS), a conformal framework that adaptively aggregates multiple one-shot predictors and uses a leave-one-out calibration scheme to fully exploit scarce labeled data. Despite violating classical exchangeability assumptions, we prove that CAOS achieves valid marginal coverage using a monotonicity-based argument. Experiments on one-shot facial landmarking and RAFT text classification tasks show that CAOS produces substantially smaller prediction sets than split conformal baselines while maintaining reliable coverage.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 105,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05227",
        "abs_url": "https://arxiv.org/abs/2601.05227",
        "pdf_url": "https://arxiv.org/pdf/2601.05227",
        "title": "Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data",
        "authors": [
            "James Rice"
        ],
        "comments": "20 pages, 6330 words",
        "subjects": "Machine Learning (stat.ML); Machine Learning (cs.LG); Econometrics (econ.EM); Statistics Theory (math.ST)",
        "abstract": "I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an ItÃ´ SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and generalizing classical time series models to handle irregular sampling and complex dynamic structure. A central theoretical contribution is the co-parameterization of the adjoint state with a dedicated neural network, forming a coupled forward-backward system that captures not only latent evolution but also gradient dynamics. I introduce a pathwise-regularized adjoint loss and analyze variance-reduced gradient flows through the lens of stochastic calculus, offering new tools for improving training stability in deep latent SDEs. My paper unifies and extends variational inference, continuous-time generative modeling, and control-theoretic optimization, providing a rigorous foundation for future developments in stochastic probabilistic machine learning.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 106,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05232",
        "abs_url": "https://arxiv.org/abs/2601.05232",
        "pdf_url": "https://arxiv.org/pdf/2601.05232",
        "title": "Measuring and Fostering Peace through Machine Learning and Artificial Intelligence",
        "authors": [
            "P. Gilda",
            "P. Dungarwal",
            "A. Thongkham",
            "E. T. Ajayi",
            "S. Choudhary",
            "T. M. Terol",
            "C. Lam",
            "J. P. Araujo",
            "M. McFadyen-Mungalln",
            "L. S. Liebovitch",
            "P. T. Coleman",
            "H. West",
            "K. Sieck",
            "S. Carter"
        ],
        "comments": "6 pages, 4 figures",
        "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)",
        "abstract": "We used machine learning and artificial intelligence: 1) to measure levels of peace in countries from news and social media and 2) to develop on-line tools that promote peace by helping users better understand their own media diet. For news media, we used neural networks to measure levels of peace from text embeddings of on-line news sources. The model, trained on one news media dataset also showed high accuracy when used to analyze a different news dataset. For social media, such as YouTube, we developed other models to measure levels of social dimensions important in peace using word level (GoEmotions) and context level (Large Language Model) methods. To promote peace, we note that 71% of people 20-40 years old daily view most of their news through short videos on social media. Content creators of these videos are biased towards creating videos with emotional activation, making you angry to engage you, to increase clicks. We developed and tested a Chrome extension, MirrorMirror, which provides real-time feedback to YouTube viewers about the peacefulness of the media they are watching. Our long term goal is for MirrorMirror to evolve into an open-source tool for content creators, journalists, researchers, platforms, and individual users to better understand the tone of their media creation and consumption and its effects on viewers. Moving beyond simple engagement metrics, we hope to encourage more respectful, nuanced, and informative communication.",
        "gemini2.5flash": "",
        "overall_idea": ""
    },
    {
        "order": 107,
        "date": "2026-01-09",
        "date_url": "https://arxiv.org/catchup/cs.LG/2026-01-09?abs=True",
        "arxiv_id": "2601.05242",
        "abs_url": "https://arxiv.org/abs/2601.05242",
        "pdf_url": "https://arxiv.org/pdf/2601.05242",
        "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization",
        "authors": [
            "Shih-Yang Liu",
            "Xin Dong",
            "Ximing Lu",
            "Shizhe Diao",
            "Peter Belcak",
            "Mingjie Liu",
            "Min-Hung Chen",
            "Hongxu Yin",
            "Yu-Chiang Frank Wang",
            "Kwang-Ting Cheng",
            "Yejin Choi",
            "Jan Kautz",
            "Pavlo Molchanov"
        ],
        "comments": "NVIDIA-Tech Report",
        "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
        "abstract": "As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.",
        "gemini2.5flash": "",
        "overall_idea": ""
    }
]